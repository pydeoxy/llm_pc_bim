{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import loralib as lora\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import JaccardIndex\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.typing import WITH_TORCH_CLUSTER\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "from pyg_pointnet2 import PyGPointNet2NoColorLoRa\n",
    "from pc_dataset import H5PCDataset\n",
    "\n",
    "\n",
    "if not WITH_TORCH_CLUSTER:\n",
    "    quit(\"This example requires 'torch-cluster'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out colors\n",
    "class SelectLast3Features:\n",
    "    def __call__(self, data):\n",
    "        # If data.x is defined, select only its last 3 features.\n",
    "        if data.x is not None:\n",
    "            data.x = data.x[:, -3:]\n",
    "        return data\n",
    "\n",
    "# transform and pre_transform\n",
    "transform = T.Compose([\n",
    "    T.RandomJitter(0.01),\n",
    "    T.RandomRotate(15, axis=0),\n",
    "    T.RandomRotate(15, axis=1),\n",
    "    T.RandomRotate(15, axis=2),\n",
    "    SelectLast3Features()\n",
    "])\n",
    "\n",
    "full_dataset = H5PCDataset(file_path='../docs/sim_pc_dataset.h5', transform=transform)\n",
    "\n",
    "# Define split sizes (e.g., 80% training and 20% validation)\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "# Randomly split the dataset\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4096, 3], y=[4096], pos=[4096, 3])\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])\n",
    "print(train_dataset.dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "num_workers=0\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PyGPointNet2NoColorLoRa(num_classes=13).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PyGPointNet2NoColorLoRa(num_classes=13).to(device)\n",
    "model.load_state_dict(torch.load(\"checkpoints/pointnet2_s3dis_colorless_seg_x3_45_checkpoint.pth\", map_location=device), strict=False)  # Load pretrained weights\n",
    "\n",
    "# Freeze all parameters except LoRA\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze LoRA parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if \"lora_\" in name:  # LoRA parameters have \"lora_A\" or \"lora_B\" in their names\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyGPointNet2NoColorLoRa(\n",
       "  (sa1_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=Sequential(\n",
       "      (0): Linear(in_features=6, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=128, bias=True)\n",
       "    ), global_nn=None)\n",
       "  )\n",
       "  (sa2_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=Sequential(\n",
       "      (0): Linear(in_features=131, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=256, bias=True)\n",
       "    ), global_nn=None)\n",
       "  )\n",
       "  (sa3_module): GlobalSAModule(\n",
       "    (nn): Sequential(\n",
       "      (0): Linear(in_features=259, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fp3_module): FPModule(\n",
       "    (nn): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fp2_module): FPModule(\n",
       "    (nn): Sequential(\n",
       "      (0): Linear(in_features=384, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fp1_module): FPModule(\n",
       "    (nn): Sequential(\n",
       "      (0): Linear(in_features=131, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=13, bias=True)\n",
       "  )\n",
       "  (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin3): Linear(in_features=128, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: ['sa1_module.conv.local_nn.0.lora_A', 'sa1_module.conv.local_nn.0.lora_B', 'sa1_module.conv.local_nn.2.lora_A', 'sa1_module.conv.local_nn.2.lora_B', 'sa1_module.conv.local_nn.4.lora_A', 'sa1_module.conv.local_nn.4.lora_B', 'sa2_module.conv.local_nn.0.lora_A', 'sa2_module.conv.local_nn.0.lora_B', 'sa2_module.conv.local_nn.2.lora_A', 'sa2_module.conv.local_nn.2.lora_B', 'sa2_module.conv.local_nn.4.lora_A', 'sa2_module.conv.local_nn.4.lora_B', 'sa3_module.nn.0.lora_A', 'sa3_module.nn.0.lora_B', 'sa3_module.nn.2.lora_A', 'sa3_module.nn.2.lora_B', 'sa3_module.nn.4.lora_A', 'sa3_module.nn.4.lora_B', 'fp3_module.nn.0.lora_A', 'fp3_module.nn.0.lora_B', 'fp3_module.nn.2.lora_A', 'fp3_module.nn.2.lora_B', 'fp2_module.nn.0.lora_A', 'fp2_module.nn.0.lora_B', 'fp2_module.nn.2.lora_A', 'fp2_module.nn.2.lora_B', 'fp1_module.nn.0.lora_A', 'fp1_module.nn.0.lora_B', 'fp1_module.nn.2.lora_A', 'fp1_module.nn.2.lora_B', 'fp1_module.nn.4.lora_A', 'fp1_module.nn.4.lora_B', 'mlp.0.lora_A', 'mlp.0.lora_B', 'mlp.3.lora_A', 'mlp.3.lora_B', 'mlp.6.lora_A', 'mlp.6.lora_B', 'lin1.lora_A', 'lin1.lora_B', 'lin2.lora_A', 'lin2.lora_B', 'lin3.lora_A', 'lin3.lora_B']\n"
     ]
    }
   ],
   "source": [
    "# Verify trainable parameters\n",
    "trainable_params = [name for name, p in model.named_parameters() if p.requires_grad]\n",
    "print(\"Trainable parameters:\", trainable_params)\n",
    "\n",
    "# After freezing the base model and enabling LoRA:\n",
    "optimizer = torch.optim.Adam(\n",
    "    [p for p in model.parameters() if p.requires_grad],  # Manual LoRA params\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = correct_nodes = total_nodes = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out.view(-1, 13), data.y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct_nodes += out.argmax(dim=1).eq(data.y).sum().item()\n",
    "        total_nodes += data.num_nodes\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'[{i+1}/{len(train_loader)}] Loss: {total_loss / 10:.4f} '\n",
    "                  f'Train Acc: {correct_nodes / total_nodes:.4f}')\n",
    "            total_loss = correct_nodes = total_nodes = 0\n",
    "    # If there are remaining batches that were not printed (i.e., i+1 not divisible by 10)\n",
    "    if total_nodes > 0:\n",
    "        num_remaining = (i + 1) % 10  # Number of batches in the leftover segment\n",
    "        print(f'[{i+1}/{len(train_loader)}] Loss: {total_loss / num_remaining:.4f} '\n",
    "              f'Train Acc: {correct_nodes / total_nodes:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    jaccard = JaccardIndex(num_classes=loader.dataset.dataset.num_classes, task=\"multiclass\").to(device)\n",
    "    \n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        outs = model(data)\n",
    "        preds = outs.argmax(dim=-1)\n",
    "        jaccard.update(preds, data.y)\n",
    "    \n",
    "    return jaccard.compute().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/7] Loss: 2.5402 Train Acc: 0.0728\n",
      "Epoch: 01, Test IoU: 0.0054\n",
      "[7/7] Loss: 2.5244 Train Acc: 0.1614\n",
      "Epoch: 02, Test IoU: 0.0393\n",
      "[7/7] Loss: 2.4909 Train Acc: 0.3302\n",
      "Epoch: 03, Test IoU: 0.0393\n",
      "[7/7] Loss: 2.4235 Train Acc: 0.3876\n",
      "Epoch: 04, Test IoU: 0.0393\n",
      "[7/7] Loss: 2.2363 Train Acc: 0.3902\n",
      "Epoch: 05, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.8473 Train Acc: 0.3914\n",
      "Epoch: 06, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.8038 Train Acc: 0.3870\n",
      "Epoch: 07, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.7454 Train Acc: 0.3503\n",
      "Epoch: 08, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.7332 Train Acc: 0.3261\n",
      "Epoch: 09, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.6532 Train Acc: 0.3479\n",
      "Epoch: 10, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.6404 Train Acc: 0.3800\n",
      "Epoch: 11, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.6674 Train Acc: 0.3845\n",
      "Epoch: 12, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.6904 Train Acc: 0.3805\n",
      "Epoch: 13, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.6617 Train Acc: 0.3729\n",
      "Epoch: 14, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.6064 Train Acc: 0.3692\n",
      "Epoch: 15, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.6412 Train Acc: 0.3791\n",
      "Epoch: 16, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.5968 Train Acc: 0.3823\n",
      "Epoch: 17, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.6355 Train Acc: 0.3732\n",
      "Epoch: 18, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.6827 Train Acc: 0.3628\n",
      "Epoch: 19, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.5926 Train Acc: 0.3714\n",
      "Epoch: 20, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.5412 Train Acc: 0.3684\n",
      "Epoch: 21, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.6055 Train Acc: 0.3473\n",
      "Epoch: 22, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.5845 Train Acc: 0.3556\n",
      "Epoch: 23, Test IoU: 0.0393\n",
      "[7/7] Loss: 1.5555 Train Acc: 0.3499\n",
      "Epoch: 24, Test IoU: 0.0554\n",
      "[7/7] Loss: 1.5855 Train Acc: 0.3391\n",
      "Epoch: 25, Test IoU: 0.0395\n",
      "[7/7] Loss: 1.6491 Train Acc: 0.3086\n",
      "Epoch: 26, Test IoU: 0.0159\n",
      "[7/7] Loss: 1.5763 Train Acc: 0.3116\n",
      "Epoch: 27, Test IoU: 0.0438\n",
      "[7/7] Loss: 1.6242 Train Acc: 0.3554\n",
      "Epoch: 28, Test IoU: 0.0886\n",
      "[7/7] Loss: 1.5920 Train Acc: 0.3719\n",
      "Epoch: 29, Test IoU: 0.0611\n",
      "[7/7] Loss: 1.5920 Train Acc: 0.3540\n",
      "Epoch: 30, Test IoU: 0.0506\n",
      "[7/7] Loss: 1.5272 Train Acc: 0.3582\n",
      "Epoch: 31, Test IoU: 0.0375\n",
      "[7/7] Loss: 1.4380 Train Acc: 0.3333\n",
      "Epoch: 32, Test IoU: 0.0159\n",
      "[7/7] Loss: 1.5387 Train Acc: 0.3001\n",
      "Epoch: 33, Test IoU: 0.0159\n",
      "[7/7] Loss: 1.5842 Train Acc: 0.3332\n",
      "Epoch: 34, Test IoU: 0.0583\n",
      "[7/7] Loss: 1.4863 Train Acc: 0.3884\n",
      "Epoch: 35, Test IoU: 0.0531\n",
      "[7/7] Loss: 1.5027 Train Acc: 0.3277\n",
      "Epoch: 36, Test IoU: 0.0188\n",
      "[7/7] Loss: 1.5467 Train Acc: 0.3779\n",
      "Epoch: 37, Test IoU: 0.0497\n",
      "[7/7] Loss: 1.5201 Train Acc: 0.3495\n",
      "Epoch: 38, Test IoU: 0.0229\n",
      "[7/7] Loss: 1.5216 Train Acc: 0.3477\n",
      "Epoch: 39, Test IoU: 0.0210\n",
      "[7/7] Loss: 1.4907 Train Acc: 0.3480\n",
      "Epoch: 40, Test IoU: 0.0407\n",
      "[7/7] Loss: 1.4458 Train Acc: 0.3759\n",
      "Epoch: 41, Test IoU: 0.0464\n",
      "[7/7] Loss: 1.5664 Train Acc: 0.3777\n",
      "Epoch: 42, Test IoU: 0.0658\n",
      "[7/7] Loss: 1.4917 Train Acc: 0.4058\n",
      "Epoch: 43, Test IoU: 0.0848\n",
      "[7/7] Loss: 1.4938 Train Acc: 0.4498\n",
      "Epoch: 44, Test IoU: 0.0756\n",
      "[7/7] Loss: 1.5262 Train Acc: 0.4251\n",
      "Epoch: 45, Test IoU: 0.0710\n",
      "Epoch: 45, Test IoU: 0.0710, Time: 14.02s\n",
      "Training time: 9.90m\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "import time\n",
    "begin_time = time.perf_counter()\n",
    "for epoch in range(1, 46):\n",
    "    start_time = time.perf_counter()\n",
    "    train()\n",
    "    iou = test(test_loader)\n",
    "    epoch_time = time.perf_counter() - start_time\n",
    "    print(f'Epoch: {epoch:02d}, Test IoU: {iou:.4f}')\n",
    "print(f'Epoch: {epoch:02d}, Test IoU: {iou:.4f}, Time: {epoch_time:.2f}s')\n",
    "total_time = time.perf_counter() - begin_time\n",
    "print(f'Training time: {(total_time)/60:.2f}m')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lora.lora_state_dict(model), \"checkpoints/smartlab_lora_weights_x3_45_20250416.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

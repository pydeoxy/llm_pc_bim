{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is only for using in the CSC environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projappl/project_2013104/pengyan1/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/PUHTI_TYKKY_FRQGCcR/miniconda/envs/env1/lib/python310.zip',\n",
       " '/PUHTI_TYKKY_FRQGCcR/miniconda/envs/env1/lib/python3.10',\n",
       " '/PUHTI_TYKKY_FRQGCcR/miniconda/envs/env1/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/PUHTI_TYKKY_FRQGCcR/miniconda/envs/env1/lib/python3.10/site-packages',\n",
       " '/projappl/project_2013104/pengyan1/venv/lib/python3.10/site-packages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "folder_path = os.path.abspath(\"/projappl/project_2013104/pengyan1/venv/lib/python3.10/site-packages\")\n",
    "if folder_path not in sys.path:\n",
    "    sys.path.append(folder_path)\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MLP, PointNetConv, fps, global_max_pool, radius\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MLP, knn_interpolate\n",
    "from torch_geometric.typing import WITH_TORCH_CLUSTER\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "if not WITH_TORCH_CLUSTER:\n",
    "    quit(\"This example requires 'torch-cluster'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAModule(torch.nn.Module):\n",
    "    def __init__(self, ratio, r, nn):\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "        self.r = r\n",
    "        self.conv = PointNetConv(nn, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        idx = fps(pos, batch, ratio=self.ratio)\n",
    "        row, col = radius(pos, pos[idx], self.r, batch, batch[idx],\n",
    "                          max_num_neighbors=64)\n",
    "        edge_index = torch.stack([col, row], dim=0)\n",
    "        x_dst = None if x is None else x[idx]\n",
    "        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n",
    "        pos, batch = pos[idx], batch[idx]\n",
    "        return x, pos, batch\n",
    "\n",
    "\n",
    "class GlobalSAModule(torch.nn.Module):\n",
    "    def __init__(self, nn):\n",
    "        super().__init__()\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        x = self.nn(torch.cat([x, pos], dim=1))\n",
    "        x = global_max_pool(x, batch)\n",
    "        pos = pos.new_zeros((x.size(0), 3))\n",
    "        batch = torch.arange(x.size(0), device=batch.device)\n",
    "        return x, pos, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPModule(torch.nn.Module):\n",
    "    def __init__(self, k, nn):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch, x_skip, pos_skip, batch_skip):\n",
    "        x = knn_interpolate(x, pos, pos_skip, batch, batch_skip, k=self.k)\n",
    "        if x_skip is not None:\n",
    "            x = torch.cat([x, x_skip], dim=1)\n",
    "        x = self.nn(x)\n",
    "        return x, pos_skip, batch_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input channels account for both `pos` and node features.\n",
    "        self.sa1_module = SAModule(0.2, 0.2, MLP([3 + 6, 64, 64, 128])) # 3 (pos) + 6 (x)\n",
    "        self.sa2_module = SAModule(0.25, 0.4, MLP([128 + 3, 128, 128, 256]))\n",
    "        self.sa3_module = GlobalSAModule(MLP([256 + 3, 256, 512, 1024]))\n",
    "\n",
    "        self.fp3_module = FPModule(1, MLP([1024 + 256, 256, 256]))\n",
    "        self.fp2_module = FPModule(3, MLP([256 + 128, 256, 128]))\n",
    "        self.fp1_module = FPModule(3, MLP([128 + 6, 128, 128, 128]))\n",
    "\n",
    "        self.mlp = MLP([128, 128, 128, num_classes], dropout=0.5, norm=None)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(128, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 128)\n",
    "        self.lin3 = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        sa0_out = (data.x, data.pos, data.batch)\n",
    "        sa1_out = self.sa1_module(*sa0_out)\n",
    "        sa2_out = self.sa2_module(*sa1_out)\n",
    "        sa3_out = self.sa3_module(*sa2_out)\n",
    "\n",
    "        fp3_out = self.fp3_module(*sa3_out, *sa2_out)\n",
    "        fp2_out = self.fp2_module(*fp3_out, *sa1_out)\n",
    "        x, _, _ = self.fp1_module(*fp2_out, *sa0_out)\n",
    "\n",
    "        return self.mlp(x).log_softmax(dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = Net(num_classes=13).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint dictionary\n",
    "checkpoint = torch.load('/scratch/project_2013104/checkpoints/pointnet2_s3dis_transform_seg_x6_45_checkpoint.pth', map_location=device)\n",
    "# Extract the model state dictionary\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "# print(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (sa1_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=MLP(9, 64, 64, 128), global_nn=None)\n",
       "  )\n",
       "  (sa2_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=MLP(131, 128, 128, 256), global_nn=None)\n",
       "  )\n",
       "  (sa3_module): GlobalSAModule(\n",
       "    (nn): MLP(259, 256, 512, 1024)\n",
       "  )\n",
       "  (fp3_module): FPModule(\n",
       "    (nn): MLP(1280, 256, 256)\n",
       "  )\n",
       "  (fp2_module): FPModule(\n",
       "    (nn): MLP(384, 256, 128)\n",
       "  )\n",
       "  (fp1_module): FPModule(\n",
       "    (nn): MLP(134, 128, 128, 128)\n",
       "  )\n",
       "  (mlp): MLP(128, 128, 128, 13)\n",
       "  (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin3): Linear(in_features=128, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pcd files\n",
    "#pcd_path = \"/scratch/project_2013104/Smartlab-2024-04-05_10-58-26_colour_cleaned.pcd\"\n",
    "pcd_path = \"/scratch/project_2013104/datasets/SmartLab_2024_E57_Single_5mm.pcd\"\n",
    "#pcd_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/SmartLab_2024_E57_Single_5mm.ply\"\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35966772\n",
      "35966772\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(pcd.points))\n",
    "print(len(pcd.colors))\n",
    "print(len(pcd.normals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_points_corner(points):\n",
    "    # Step 1: Shift points so that the minimum x, y, z becomes the origin.\n",
    "    min_vals = np.min(points, axis=0)\n",
    "    shifted_points = points - min_vals  # Now the lower bound is (0,0,0)\n",
    "    \n",
    "    # Step 2: Compute the scaling factors from the shifted points.\n",
    "    # The maximum after shifting represents the range in each dimension.\n",
    "    max_vals = np.max(shifted_points, axis=0)\n",
    "    scale = max_vals.copy()\n",
    "    \n",
    "    # Avoid division by zero if any dimension is flat.\n",
    "    scale[scale == 0] = 1\n",
    "    \n",
    "    # Normalize the shifted points to the [0, 1] interval.\n",
    "    normalized_points = shifted_points / scale\n",
    "\n",
    "    return normalized_points\n",
    "\n",
    "normalized = normalize_points_corner(np.array(pcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates and colors from the point cloud\n",
    "pcd_points = torch.tensor(np.array(pcd.points), dtype=torch.float32)  \n",
    "pcd_colors = torch.tensor(np.array(pcd.colors), dtype=torch.float32)\n",
    "pcd_normalized = torch.tensor(normalized, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate coordinates and colors to form the input features\n",
    "x = torch.cat([pcd_colors, pcd_normalized], dim=1) # 6 (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data object with x (6 features) and pos (coordinates)\n",
    "data = Data(x=x, pos=pcd_points)\n",
    "\n",
    "#pre_transform = T.NormalizeScale()\n",
    "#data = pre_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have only one point cloud\n",
    "dataset = [data]  # List of Data objects\n",
    "\n",
    "# Create a DataLoader (batch_size can be adjusted as needed)\n",
    "custom_loader = DataLoader(dataset, batch_size=64, shuffle=False,\n",
    "                         num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    for data in custom_loader:\n",
    "        data = data.to(device)\n",
    "        predictions = model(data)\n",
    "        labels = predictions.argmax(dim=-1)\n",
    "        # Process the labels as needed\n",
    "        #labels_arr = labels.cpu().numpy()\n",
    "        # Count occurrences of labels\n",
    "        unique_labels, label_counts = torch.unique(labels, return_counts=True)\n",
    "        # Combine and print\n",
    "        #result_labels = np.array(list(zip(unique_labels, label_counts)))\n",
    "        print(\"Label counts:\")\n",
    "        for label, count in zip(unique_labels, label_counts):\n",
    "            print(f\"Label {label.item()}: {count.item()}\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Total inference time: {end_time - start_time:.4f} seconds\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the number of classes in your model's predictions\n",
    "num_classes = 13  # Adjust based on your number of classes\n",
    "\n",
    "\n",
    "# Define a fixed color map for 13 labels\n",
    "color_map = np.array([\n",
    "    [1.0, 0.0, 0.0],  # Label 0: Red,  'ceiling'\n",
    "    [0.0, 1.0, 0.0],  # Label 1: Green, 'floor'\n",
    "    [0.0, 0.0, 1.0],  # Label 2: Blue,  'wall'\n",
    "    [1.0, 1.0, 0.0],  # Label 3: Yellow, 'beam'\n",
    "    [1.0, 0.0, 1.0],  # Label 4: Magenta, 'column'\n",
    "    [0.0, 1.0, 1.0],  # Label 5: Cyan, 'window'\n",
    "    [0.5, 0.5, 0.5],  # Label 6: Gray, 'door'\n",
    "    [1.0, 0.5, 0.0],  # Label 7: Orange, 'chair'\n",
    "    [0.5, 0.0, 1.0],  # Label 8: Purple, 'table'\n",
    "    [0.5, 1.0, 0.5],  # Label 9: Light Green, 'bookcase'\n",
    "    [0.5, 0.5, 1.0],  # Label 10: Light Blue, 'sofa'\n",
    "    [1.0, 0.5, 0.5],  # Label 11: Pink, 'board'\n",
    "    [0.0, 0.0, 0.0]   # Label 12: Black, 'clutter'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `labels` is the tensor containing predicted labels for each point\n",
    "predicted_colors = color_map[labels.cpu().numpy()]  # Shape: [num_points, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(predicted_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `pcd` is your Open3D point cloud object\n",
    "pcd.colors = o3d.utility.Vector3dVector(predicted_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the point cloud with colored labels\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the point cloud to a file\n",
    "save_path = '/scratch/project_2013104/labelled/Smartlab_aalto_label_pointnet2_x6_ori_20250414.ply'\n",
    "o3d.io.write_point_cloud(save_path, downpcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

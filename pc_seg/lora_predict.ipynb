{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pyg_pointnet2 import PyGPointNet2NoColor,PyGPointNet2NoColorLoRa\n",
    "import loralib as lora\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MLP\n",
    "from torch_geometric.loader import DataLoader\n",
    "import time\n",
    "from pc_label_map import color_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_path = \"checkpoints/pointnet2_s3dis_colorless_seg_x3_45_checkpoint.pth\"\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PyGPointNet2NoColor(num_classes=13).to(device)\n",
    "\n",
    "checkpoint = torch.load(pretrained_path, map_location=device)\n",
    "# Extract the model state dictionary\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "model.load_state_dict(model_state_dict, strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters:\n",
      "['sa1_module.conv.local_nn.lins.0.weight',\n",
      " 'sa1_module.conv.local_nn.lins.0.bias',\n",
      " 'sa1_module.conv.local_nn.lins.1.weight',\n",
      " 'sa1_module.conv.local_nn.lins.1.bias',\n",
      " 'sa1_module.conv.local_nn.lins.2.weight',\n",
      " 'sa1_module.conv.local_nn.lins.2.bias',\n",
      " 'sa1_module.conv.local_nn.norms.0.module.weight',\n",
      " 'sa1_module.conv.local_nn.norms.0.module.bias',\n",
      " 'sa1_module.conv.local_nn.norms.1.module.weight',\n",
      " 'sa1_module.conv.local_nn.norms.1.module.bias',\n",
      " 'sa2_module.conv.local_nn.lins.0.weight',\n",
      " 'sa2_module.conv.local_nn.lins.0.bias',\n",
      " 'sa2_module.conv.local_nn.lins.1.weight',\n",
      " 'sa2_module.conv.local_nn.lins.1.bias',\n",
      " 'sa2_module.conv.local_nn.lins.2.weight',\n",
      " 'sa2_module.conv.local_nn.lins.2.bias',\n",
      " 'sa2_module.conv.local_nn.norms.0.module.weight',\n",
      " 'sa2_module.conv.local_nn.norms.0.module.bias',\n",
      " 'sa2_module.conv.local_nn.norms.1.module.weight',\n",
      " 'sa2_module.conv.local_nn.norms.1.module.bias',\n",
      " 'sa3_module.nn.lins.0.weight',\n",
      " 'sa3_module.nn.lins.0.bias',\n",
      " 'sa3_module.nn.lins.1.weight',\n",
      " 'sa3_module.nn.lins.1.bias',\n",
      " 'sa3_module.nn.lins.2.weight',\n",
      " 'sa3_module.nn.lins.2.bias',\n",
      " 'sa3_module.nn.norms.0.module.weight',\n",
      " 'sa3_module.nn.norms.0.module.bias',\n",
      " 'sa3_module.nn.norms.1.module.weight',\n",
      " 'sa3_module.nn.norms.1.module.bias',\n",
      " 'fp3_module.nn.lins.0.weight',\n",
      " 'fp3_module.nn.lins.0.bias',\n",
      " 'fp3_module.nn.lins.1.weight',\n",
      " 'fp3_module.nn.lins.1.bias',\n",
      " 'fp3_module.nn.norms.0.module.weight',\n",
      " 'fp3_module.nn.norms.0.module.bias',\n",
      " 'fp2_module.nn.lins.0.weight',\n",
      " 'fp2_module.nn.lins.0.bias',\n",
      " 'fp2_module.nn.lins.1.weight',\n",
      " 'fp2_module.nn.lins.1.bias',\n",
      " 'fp2_module.nn.norms.0.module.weight',\n",
      " 'fp2_module.nn.norms.0.module.bias',\n",
      " 'fp1_module.nn.lins.0.weight',\n",
      " 'fp1_module.nn.lins.0.bias',\n",
      " 'fp1_module.nn.lins.1.weight',\n",
      " 'fp1_module.nn.lins.1.bias',\n",
      " 'fp1_module.nn.lins.2.weight',\n",
      " 'fp1_module.nn.lins.2.bias',\n",
      " 'fp1_module.nn.norms.0.module.weight',\n",
      " 'fp1_module.nn.norms.0.module.bias',\n",
      " 'fp1_module.nn.norms.1.module.weight',\n",
      " 'fp1_module.nn.norms.1.module.bias',\n",
      " 'mlp.lins.0.weight',\n",
      " 'mlp.lins.0.bias',\n",
      " 'mlp.lins.1.weight',\n",
      " 'mlp.lins.1.bias',\n",
      " 'mlp.lins.2.weight',\n",
      " 'mlp.lins.2.bias',\n",
      " 'lin1.weight',\n",
      " 'lin1.bias',\n",
      " 'lin2.weight',\n",
      " 'lin2.bias',\n",
      " 'lin3.weight',\n",
      " 'lin3.bias']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# Verify trainable parameters\n",
    "trainable_params = [name for name, p in model.named_parameters() if p.requires_grad]\n",
    "print(\"Trainable parameters:\")\n",
    "from pprint import pprint\n",
    "pprint(trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lora(module, r=8, alpha=16, verbose=False):\n",
    "    \"\"\"\n",
    "    Recursively replaces ALL Linear layers with LoRA-enabled layers.\n",
    "    \"\"\"\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Linear):\n",
    "            # Replace this Linear layer with LoRA\n",
    "            lora_layer = lora.Linear(\n",
    "                in_features=child.in_features,\n",
    "                out_features=child.out_features,\n",
    "                r=r,\n",
    "                lora_alpha=alpha\n",
    "            )\n",
    "            \n",
    "            # Copy original weights and biases\n",
    "            lora_layer.weight.data = child.weight.data.clone()\n",
    "            if child.bias is not None:\n",
    "                lora_layer.bias.data = child.bias.data.clone()\n",
    "            \n",
    "            # Replace the layer\n",
    "            setattr(module, name, lora_layer)\n",
    "            if verbose:\n",
    "                print(f\"Replaced {name} with LoRA\")\n",
    "        elif isinstance(child, nn.Sequential):\n",
    "            # Handle Sequential containers (e.g., MLP layers)\n",
    "            for idx, layer in enumerate(child):\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    # Replace Linear layers inside Sequential\n",
    "                    lora_layer = lora.Linear(\n",
    "                        in_features=layer.in_features,\n",
    "                        out_features=layer.out_features,\n",
    "                        r=r,\n",
    "                        lora_alpha=alpha\n",
    "                    )\n",
    "                    lora_layer.weight.data = layer.weight.data.clone()\n",
    "                    if layer.bias is not None:\n",
    "                        lora_layer.bias.data = layer.bias.data.clone()\n",
    "                    child[idx] = lora_layer\n",
    "                    if verbose:\n",
    "                        print(f\"Replaced {name}[{idx}] with LoRA\")\n",
    "        else:\n",
    "            # Recursively apply to nested submodules\n",
    "            apply_lora(child, r, alpha, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced lin1 with LoRA\n",
      "Replaced lin2 with LoRA\n",
      "Replaced lin3 with LoRA\n"
     ]
    }
   ],
   "source": [
    "apply_lora(model, r=8, alpha=16, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all parameters except LoRA\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"lora_\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sa1_module.conv.local_nn.0.lora_A': tensor([[ 5.4894e-02, -2.8997e-04, -1.4048e-02, -3.3403e-02, -1.5397e-03,\n",
      "         -1.1788e-02],\n",
      "        [ 3.7251e-03, -9.5820e-02,  1.2957e-01,  2.5225e-05, -1.4629e-01,\n",
      "         -2.3117e-04],\n",
      "        [ 4.7222e-04,  1.5084e-01,  6.5376e-02, -1.4393e-04, -4.2496e-02,\n",
      "          5.5161e-02],\n",
      "        [ 5.5782e-02, -1.4246e-01, -1.3983e-03, -1.3725e-01,  3.1118e-04,\n",
      "          5.2559e-03],\n",
      "        [-6.0855e-02, -3.4108e-03,  2.9261e-03,  5.8918e-03, -4.5127e-04,\n",
      "         -7.6645e-02],\n",
      "        [ 6.8475e-02,  1.1021e-01, -5.0716e-02,  1.0705e-02, -6.5239e-03,\n",
      "          1.9899e-02],\n",
      "        [-2.1532e-02,  1.4441e-03,  1.1813e-03,  3.0167e-02, -3.1405e-05,\n",
      "         -1.1100e-02],\n",
      "        [ 1.3597e-01, -5.8878e-03, -1.1180e-01, -9.1477e-05,  3.1938e-02,\n",
      "         -1.0609e-02]], device='cuda:0'), 'sa1_module.conv.local_nn.0.lora_B': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-4.8101e-04, -2.0168e-03, -7.2580e-03,  4.2437e-03,  1.6267e-03,\n",
      "         -4.7831e-03,  3.2327e-04,  1.4506e-03],\n",
      "        [-2.7312e-04,  1.0313e-03, -8.5060e-04, -3.5231e-04, -5.4277e-05,\n",
      "          7.1406e-04, -7.7991e-05, -7.2269e-04],\n",
      "        [-6.7507e-07, -2.2811e-06,  1.9826e-06,  4.1785e-07,  1.2565e-06,\n",
      "          9.4141e-07,  2.4011e-07, -2.3085e-06],\n",
      "        [ 2.8130e-04,  2.1396e-04, -3.4562e-03, -8.3596e-06,  5.5791e-04,\n",
      "         -4.7750e-04, -6.7073e-05, -1.2429e-03],\n",
      "        [ 1.7653e-04, -1.2148e-03, -3.4926e-03,  8.1063e-04,  1.0878e-03,\n",
      "         -1.8370e-03,  2.5275e-05,  1.0115e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.2267e-04,  3.1354e-04, -7.4495e-04, -2.0550e-05,  3.3115e-04,\n",
      "         -7.7805e-04,  1.0959e-04, -2.7659e-04],\n",
      "        [ 5.9741e-04,  1.8574e-03,  4.5619e-03, -1.5850e-03, -1.4736e-03,\n",
      "          2.6110e-03, -2.0565e-04, -6.2786e-04],\n",
      "        [ 1.3169e-03, -4.1386e-04, -6.5468e-03,  6.3819e-03,  1.3831e-04,\n",
      "         -3.0986e-03, -6.3556e-04,  3.9861e-03],\n",
      "        [-1.0987e-03,  3.9352e-03,  1.8488e-03,  7.7364e-05, -2.8321e-05,\n",
      "         -2.6849e-03,  6.3292e-06, -4.4945e-03],\n",
      "        [-6.3075e-04,  3.5190e-04, -8.6957e-03,  6.7053e-03,  2.0075e-03,\n",
      "         -6.0328e-03,  2.6706e-04,  1.9959e-03],\n",
      "        [ 1.4652e-04, -1.4074e-03, -3.2375e-03,  1.6851e-03,  5.0835e-04,\n",
      "         -6.8557e-04, -1.6742e-04,  1.6752e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.5404e-04, -2.7577e-03, -1.2062e-03, -1.4208e-03,  1.6826e-03,\n",
      "         -1.4252e-03, -6.1393e-05, -2.3581e-03],\n",
      "        [ 1.2767e-05,  1.6239e-04,  1.8600e-04,  2.3716e-04, -3.6124e-05,\n",
      "          9.9568e-05, -3.9530e-07, -1.5157e-04],\n",
      "        [ 4.2882e-05, -2.4437e-03, -1.5651e-03,  1.3322e-03,  8.1727e-04,\n",
      "         -8.7144e-05, -4.6248e-04, -4.0613e-04],\n",
      "        [ 7.6966e-04, -1.0487e-03,  2.5551e-03, -2.9865e-03, -6.0069e-04,\n",
      "          3.0757e-03, -3.7715e-04, -5.8638e-04],\n",
      "        [ 2.0055e-04, -1.6648e-05,  1.4798e-04,  1.3507e-04, -2.1382e-04,\n",
      "          4.0453e-04,  8.3482e-05,  4.5563e-04],\n",
      "        [ 1.4493e-04,  1.2640e-03,  2.0413e-03,  5.4555e-04, -1.4940e-03,\n",
      "          2.6553e-04,  4.0232e-05,  2.1125e-03],\n",
      "        [-9.3634e-06, -1.2741e-03, -6.1772e-03,  4.3785e-03,  1.0198e-03,\n",
      "         -2.7896e-03,  2.8675e-04,  3.6493e-03],\n",
      "        [ 5.4879e-04,  4.5207e-04,  2.7867e-03,  1.7369e-03, -2.1124e-03,\n",
      "          1.1711e-03, -2.4275e-04,  2.9233e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-8.6537e-04,  1.0593e-03,  3.5051e-05,  9.2871e-04,  3.3379e-04,\n",
      "         -1.1771e-04,  5.3782e-04, -6.5205e-04],\n",
      "        [-6.7294e-04,  2.6517e-03,  2.9349e-03, -1.1554e-03,  6.0210e-04,\n",
      "          2.3418e-04,  3.1226e-04, -2.9266e-03],\n",
      "        [ 8.2779e-04, -1.2275e-03, -1.1929e-03,  1.6375e-03, -8.1413e-04,\n",
      "          1.1450e-03, -1.7808e-04,  3.6640e-03],\n",
      "        [ 3.2318e-06,  3.6536e-03,  1.2193e-02, -9.0635e-03, -1.6778e-03,\n",
      "          6.1680e-03,  1.0975e-04, -4.4857e-03],\n",
      "        [-2.3598e-03,  7.7805e-04, -5.0042e-03,  3.9166e-04,  3.0333e-03,\n",
      "         -5.0463e-03,  1.0367e-03, -3.4375e-03],\n",
      "        [-1.2373e-03, -2.0277e-03,  2.6530e-03, -1.7866e-03,  1.2585e-03,\n",
      "          9.1192e-04,  6.5974e-04, -1.0403e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-9.9384e-04,  8.2383e-04,  4.4656e-04, -1.3798e-03,  1.6081e-03,\n",
      "         -1.4956e-03,  5.1865e-04, -3.2133e-03],\n",
      "        [ 1.8531e-06,  4.4316e-06,  5.4118e-06,  7.1995e-07, -2.2559e-06,\n",
      "         -1.6305e-05, -9.0981e-07,  6.2691e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 6.0969e-07,  2.9201e-05, -6.2286e-05,  7.7368e-05,  9.6261e-07,\n",
      "         -6.3098e-05,  1.3539e-07, -2.1521e-06],\n",
      "        [-5.6720e-04,  1.6434e-03, -1.1725e-02,  6.3444e-03,  7.0032e-04,\n",
      "         -5.7667e-03,  1.9210e-04,  2.8311e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.3535e-04,  6.6773e-04, -2.1893e-03,  7.4028e-04,  1.1030e-03,\n",
      "         -1.1038e-03,  4.7645e-04, -6.5675e-04],\n",
      "        [-4.2199e-04, -3.6199e-03, -4.6260e-04, -3.6224e-04,  1.6442e-04,\n",
      "         -3.0649e-04,  1.8148e-04,  8.9721e-04],\n",
      "        [ 7.6050e-04, -1.9498e-04,  1.1205e-03, -5.6647e-04, -2.0834e-05,\n",
      "          1.7207e-03,  1.3255e-05,  4.3680e-04],\n",
      "        [-2.8068e-03,  6.7375e-03,  2.8867e-03,  4.1267e-04,  8.6122e-04,\n",
      "         -3.0860e-03,  1.0347e-03, -4.7017e-03],\n",
      "        [ 7.2525e-04, -1.7479e-03, -9.0264e-03,  5.0565e-03,  3.9139e-04,\n",
      "         -3.6500e-03, -4.9455e-04,  3.7775e-03],\n",
      "        [-9.9441e-04, -2.3949e-03,  4.8028e-03, -4.1736e-03,  1.7801e-03,\n",
      "          8.9103e-04,  4.7218e-04, -3.5871e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.1492e-03,  3.0828e-03,  7.0120e-05,  4.8769e-03, -4.0460e-03,\n",
      "          2.4329e-03, -1.5592e-03,  6.8217e-03],\n",
      "        [ 2.6140e-03,  3.2327e-04,  1.2956e-03,  3.2046e-03, -2.5153e-03,\n",
      "          4.4772e-04, -1.5712e-03,  4.9464e-03],\n",
      "        [ 1.6382e-03,  5.4631e-03,  4.0069e-03,  3.6760e-04, -3.5462e-03,\n",
      "          1.6637e-03, -1.1464e-03, -1.3459e-04],\n",
      "        [-2.4510e-05, -1.6465e-03,  4.0652e-04, -2.4940e-04, -1.3719e-03,\n",
      "          2.5992e-03,  1.7335e-05,  1.6987e-03],\n",
      "        [ 2.3546e-04, -4.0797e-03,  3.7090e-05, -9.0483e-04, -4.6144e-04,\n",
      "          7.8290e-04, -5.7670e-04,  2.0243e-03],\n",
      "        [ 1.7293e-03, -3.6405e-04,  2.0917e-02, -1.5348e-02, -2.7539e-03,\n",
      "          1.0996e-02, -7.6833e-04, -3.9467e-03],\n",
      "        [-5.0935e-04, -9.8850e-05, -7.4343e-04, -2.4901e-04,  3.2543e-04,\n",
      "         -2.2606e-04,  3.4866e-04, -1.8571e-04],\n",
      "        [ 3.7377e-05,  5.0596e-04,  4.7620e-04, -5.4268e-05,  5.3938e-05,\n",
      "         -2.8612e-05, -9.4953e-06, -5.7333e-04],\n",
      "        [ 5.8718e-04,  2.1194e-03,  9.2092e-03,  5.3111e-04, -2.1242e-03,\n",
      "          4.1679e-03,  2.3811e-04,  3.7107e-04],\n",
      "        [ 1.4277e-03,  1.2564e-03,  5.2485e-03, -4.1083e-03, -1.9761e-03,\n",
      "          3.9478e-03, -5.4962e-04, -8.9704e-05],\n",
      "        [-2.9285e-04,  1.2691e-03,  5.4169e-04, -3.9544e-04,  8.3068e-04,\n",
      "          3.5677e-04,  4.7656e-05, -5.6164e-05],\n",
      "        [ 3.3952e-04,  1.4843e-04,  1.3518e-03,  1.0783e-04,  2.5975e-04,\n",
      "          7.3896e-04, -2.9180e-04,  3.8746e-04],\n",
      "        [ 1.0962e-03,  3.8765e-03,  8.1417e-03, -3.6001e-03, -1.5256e-03,\n",
      "          1.9580e-03, -1.1301e-03, -5.3610e-03],\n",
      "        [ 1.7882e-04,  7.9842e-04,  4.2101e-03, -3.7497e-03,  1.6503e-04,\n",
      "          1.9064e-03,  1.0829e-04, -2.4985e-03],\n",
      "        [ 6.5462e-04,  1.3332e-03,  1.7082e-03, -4.2517e-04, -6.6929e-04,\n",
      "          9.6539e-04, -3.8588e-04,  2.1709e-04],\n",
      "        [-1.0497e-03, -3.4081e-05,  7.6867e-03, -7.8656e-03,  1.4955e-03,\n",
      "          3.3593e-03,  6.1005e-04, -4.8265e-03],\n",
      "        [-7.4151e-04,  1.3702e-03, -7.3750e-03,  4.8400e-03,  1.7729e-03,\n",
      "         -5.3979e-03,  1.5086e-04, -2.2368e-04],\n",
      "        [-2.3744e-04,  2.3751e-04, -4.6555e-04,  1.8489e-04,  4.3852e-04,\n",
      "          5.1228e-04,  4.6529e-04, -1.1271e-04],\n",
      "        [ 8.5320e-04,  1.9694e-03,  1.4642e-02, -8.1323e-03, -2.5761e-03,\n",
      "          6.7283e-03, -4.9391e-04, -4.2801e-03]], device='cuda:0'), 'sa1_module.conv.local_nn.2.lora_A': tensor([[-1.1420e-04, -3.0353e-04,  5.4728e-05,  1.5909e-06, -7.3740e-04,\n",
      "         -2.2208e-05, -3.6580e-09, -2.6655e-06, -1.6243e-04,  2.6378e-04,\n",
      "         -3.3274e-04, -1.0559e-03,  6.5525e-06,  3.2327e-04, -6.0386e-04,\n",
      "         -3.9255e-05,  3.3300e-06, -1.0683e-04,  2.4952e-04,  9.9842e-05,\n",
      "         -3.3311e-04,  2.1015e-04,  2.3593e-10, -2.1994e-06, -1.7821e-04,\n",
      "         -8.9152e-05, -4.1530e-04, -6.3302e-04, -3.0918e-05,  1.1377e-10,\n",
      "         -1.4403e-04, -1.1523e-03,  3.4727e-08, -9.7858e-07,  1.7765e-08,\n",
      "         -2.5253e-05,  2.7209e-05, -8.5241e-04, -6.6874e-04, -2.5323e-04,\n",
      "         -4.1285e-04, -1.1749e-03, -5.2328e-04, -1.1529e-05, -2.4209e-09,\n",
      "          2.5735e-04, -4.6409e-04, -8.9465e-06, -3.8771e-04, -5.8152e-05,\n",
      "         -1.6752e-04,  1.5866e-06, -5.3393e-07,  7.5697e-05, -1.7609e-04,\n",
      "          4.4589e-07,  3.5812e-07,  2.3172e-05, -7.9910e-04, -6.5451e-05,\n",
      "         -1.1503e-03, -2.4990e-04,  6.1856e-06, -3.1611e-04],\n",
      "        [-9.7919e-10,  5.4879e-05,  1.1772e-08, -4.1892e-09,  1.2355e-04,\n",
      "          4.0042e-05,  2.4376e-09, -1.4136e-07,  5.5091e-05,  4.5387e-04,\n",
      "          1.3958e-05, -1.3830e-04, -1.9721e-04,  2.7828e-10,  7.9487e-05,\n",
      "          3.2244e-08, -1.9828e-04,  9.1769e-05, -3.0738e-05, -8.5713e-06,\n",
      "          2.7314e-05,  6.6686e-05, -2.4982e-05, -5.0396e-08,  1.7378e-04,\n",
      "          3.2864e-05,  2.6388e-04,  6.0135e-05,  1.9333e-04,  1.2119e-08,\n",
      "         -2.6702e-07,  1.4504e-04,  9.7392e-07,  1.0720e-09, -3.1782e-08,\n",
      "          8.5320e-06,  3.9281e-08,  6.6017e-04,  1.1252e-04,  1.1971e-04,\n",
      "         -2.1217e-04,  7.6469e-05,  6.4116e-04, -1.4788e-09, -4.4999e-09,\n",
      "          1.8780e-04,  3.9894e-04,  1.0945e-05,  4.2106e-05,  3.5303e-04,\n",
      "          3.2241e-05,  4.2764e-07,  3.1391e-07, -2.5776e-06,  7.9339e-05,\n",
      "          4.4599e-07, -1.2689e-04,  4.0431e-06,  7.2986e-04,  2.8344e-06,\n",
      "          7.7141e-04,  4.6323e-05,  7.6891e-07,  2.0009e-04],\n",
      "        [-2.8900e-09,  1.1326e-05, -5.2320e-05,  7.0484e-06,  2.3434e-04,\n",
      "          1.6765e-04,  8.3819e-09, -7.7023e-07, -2.4994e-04, -1.6229e-04,\n",
      "          1.5495e-04,  1.2129e-04, -1.7030e-06, -2.4332e-04,  1.9674e-05,\n",
      "          2.5862e-08,  7.0888e-05,  9.9383e-05,  1.9518e-04,  1.0131e-04,\n",
      "         -2.8745e-05,  3.4088e-05, -1.7130e-09,  1.6831e-07,  2.6617e-04,\n",
      "         -4.1320e-04, -1.8212e-04, -1.7258e-04,  5.0430e-04, -8.9061e-10,\n",
      "         -6.8590e-08,  3.5710e-04,  9.2954e-06, -1.0414e-08, -2.0885e-08,\n",
      "          3.8785e-05,  8.2116e-10, -7.9433e-04, -3.7468e-04, -5.7191e-06,\n",
      "         -6.5411e-05, -5.8144e-04,  4.9202e-04, -2.5039e-09,  4.4168e-10,\n",
      "          7.0018e-05, -2.0135e-04,  5.2731e-06, -1.9306e-04,  1.6174e-05,\n",
      "         -1.0413e-04, -2.5689e-04,  1.0197e-05,  2.6567e-05,  1.2705e-04,\n",
      "         -1.0211e-08,  2.0106e-05,  1.1209e-05, -2.5592e-04, -1.3184e-06,\n",
      "         -7.4103e-04, -1.4231e-04,  7.9959e-06,  2.1924e-04],\n",
      "        [ 1.1558e-09,  5.7606e-06,  1.7940e-07,  1.4058e-11,  5.3795e-05,\n",
      "          5.2799e-06, -2.0467e-08, -7.1379e-07,  9.9257e-06,  4.8790e-05,\n",
      "         -1.2023e-05,  2.3077e-04,  7.6735e-06,  3.7949e-09,  8.8023e-05,\n",
      "          1.5086e-07,  1.0614e-06,  1.5345e-05, -3.8052e-07,  3.6115e-05,\n",
      "          4.8220e-05,  1.0553e-04,  1.3753e-07, -2.0737e-08,  1.5773e-04,\n",
      "          1.0587e-05,  1.0486e-05,  1.0703e-04,  1.3310e-04,  8.0614e-10,\n",
      "         -3.6687e-08,  7.7394e-05, -1.3749e-09,  3.7863e-09, -1.9525e-09,\n",
      "         -4.3754e-07, -5.6615e-07, -8.8304e-05,  8.2508e-05, -2.1000e-04,\n",
      "          4.0075e-06,  3.2505e-05,  9.6862e-05, -3.2173e-11, -8.2803e-11,\n",
      "          6.1638e-05,  3.6366e-06,  2.4387e-05,  2.4144e-05,  5.3495e-05,\n",
      "          3.2049e-05, -1.9319e-07,  2.1220e-07,  6.5288e-05,  4.1643e-05,\n",
      "         -5.8267e-08, -4.2959e-07,  8.1948e-05, -4.7867e-04,  2.9260e-06,\n",
      "          1.1965e-04,  1.4684e-05,  1.1052e-06,  7.0765e-05],\n",
      "        [-5.7464e-05, -5.4299e-06,  2.3779e-04,  8.0992e-07,  2.8405e-06,\n",
      "          1.6842e-06,  4.2304e-08,  1.6961e-07,  7.4544e-06,  9.2421e-06,\n",
      "          6.5469e-06,  3.4811e-06,  1.1104e-07, -1.1819e-06,  6.7669e-07,\n",
      "         -1.3632e-04,  1.0443e-06, -4.9034e-06,  1.7629e-07, -6.3588e-07,\n",
      "          5.6001e-08,  1.2506e-06, -6.2346e-08, -8.4802e-08,  7.2155e-06,\n",
      "         -2.3693e-04,  7.2319e-06, -1.3186e-06,  9.9890e-06, -1.3038e-08,\n",
      "         -1.1281e-09,  4.7592e-06, -6.6181e-10,  4.4958e-10,  6.5436e-07,\n",
      "         -1.7946e-06,  1.1661e-11,  9.4627e-06, -6.6610e-06,  3.6063e-06,\n",
      "          1.3151e-06,  4.3759e-06,  1.3943e-05, -1.0175e-07,  3.9885e-06,\n",
      "         -4.7937e-06,  7.7058e-06, -4.8493e-05, -1.8303e-05, -4.0287e-05,\n",
      "          6.7835e-06, -1.7078e-07,  3.3293e-04,  1.7524e-06, -4.9018e-05,\n",
      "          1.3073e-08,  3.4759e-04,  2.0974e-04,  1.3393e-05, -5.7440e-07,\n",
      "          1.1085e-05,  1.0140e-05, -3.2157e-05,  1.0157e-05],\n",
      "        [ 2.3226e-07,  3.5494e-04,  2.7942e-04,  1.6553e-08, -4.0469e-04,\n",
      "          2.9332e-06,  9.7245e-07, -1.4969e-06,  5.0029e-05, -1.7667e-04,\n",
      "         -6.0158e-05, -6.5575e-05, -3.3095e-04,  1.3183e-07, -9.4872e-05,\n",
      "         -6.2342e-08, -1.1525e-06,  2.4468e-05,  3.0200e-07,  2.1639e-04,\n",
      "         -5.3078e-05, -8.2779e-05,  6.2312e-07, -2.3984e-08,  2.7273e-04,\n",
      "          2.8647e-05,  4.3960e-04, -7.2503e-05, -2.8321e-05,  6.1902e-10,\n",
      "          2.2525e-08,  8.0483e-05,  4.3495e-10, -2.1092e-10, -3.7013e-08,\n",
      "          3.3143e-06,  3.4384e-12, -8.1539e-05, -4.1755e-04,  4.3413e-05,\n",
      "          4.8446e-05,  2.7248e-04,  4.1767e-05, -6.7888e-10,  3.6239e-09,\n",
      "         -2.3444e-04, -2.1988e-04, -1.0687e-05,  1.5005e-05, -7.8489e-06,\n",
      "         -2.1461e-05,  2.8853e-04, -3.5933e-07, -5.6661e-05, -1.7544e-05,\n",
      "         -1.3904e-06, -6.7160e-07,  2.0566e-05,  4.9471e-05, -8.0421e-05,\n",
      "          1.9281e-05,  5.9803e-05, -1.4102e-06,  2.1885e-05],\n",
      "        [-2.4659e-09,  7.7486e-05, -3.1312e-06,  1.3922e-07,  1.1106e-03,\n",
      "         -5.1367e-06, -2.8983e-10, -8.4551e-05,  1.3516e-04,  5.5592e-04,\n",
      "          1.2625e-03,  5.9834e-04,  1.4391e-05, -5.8482e-06,  2.1383e-04,\n",
      "          2.7246e-05,  5.0701e-05,  4.8710e-04, -1.9259e-06, -1.4433e-04,\n",
      "          7.8159e-05,  2.4524e-04,  6.4402e-09, -1.7989e-04,  8.3624e-04,\n",
      "          3.1659e-04,  2.8453e-03, -2.5007e-04,  1.0134e-03, -5.9174e-09,\n",
      "          4.7286e-09,  4.1756e-04, -7.4465e-09, -2.6905e-09,  5.1317e-09,\n",
      "          3.5281e-05,  4.0457e-08,  1.6532e-03,  1.6597e-03,  4.0669e-04,\n",
      "          1.4247e-04,  2.5113e-03,  2.6599e-03,  1.7296e-08, -1.8827e-06,\n",
      "          1.4127e-04,  2.4725e-04,  3.6756e-05,  5.9767e-04,  3.4223e-04,\n",
      "          8.1187e-05, -3.5492e-06, -1.8051e-07,  3.5543e-06,  7.5079e-04,\n",
      "          7.4291e-06, -8.7458e-07, -1.5525e-05,  6.7246e-04,  1.3313e-04,\n",
      "          9.0228e-04,  3.5078e-04,  3.1536e-06,  6.0379e-04],\n",
      "        [-1.0455e-05, -2.6333e-05,  8.8886e-08, -4.8597e-07,  3.6620e-05,\n",
      "          2.5369e-06,  2.0177e-05,  3.4207e-04, -6.8425e-05, -6.8408e-06,\n",
      "         -3.3036e-06,  1.2380e-05,  8.6801e-07, -9.0227e-10,  3.1808e-05,\n",
      "         -4.6336e-08,  1.3209e-06,  1.6895e-04, -1.9320e-06,  1.4152e-05,\n",
      "          2.5460e-05,  4.3700e-05,  7.9346e-07,  3.3704e-08, -4.4355e-05,\n",
      "         -2.5113e-05, -1.6896e-05,  1.2771e-05,  4.0639e-05, -1.4060e-08,\n",
      "          4.4743e-09,  4.2427e-06, -3.0524e-10, -2.4500e-10,  1.3208e-09,\n",
      "         -2.3309e-07,  1.3850e-07,  2.4870e-05,  4.3964e-05, -2.2041e-05,\n",
      "          3.8128e-06, -3.4431e-05,  7.3475e-06,  1.0055e-04,  3.0474e-09,\n",
      "          2.2705e-05, -2.6413e-05,  1.7917e-05, -1.4030e-06,  1.7171e-05,\n",
      "          1.4310e-05, -1.4036e-07,  1.4434e-07,  2.5364e-05, -3.3362e-05,\n",
      "          4.8618e-07, -3.8298e-08,  1.8643e-06, -1.8466e-05,  1.0465e-06,\n",
      "         -9.5138e-06, -1.1753e-04,  1.0467e-06, -3.2564e-04]], device='cuda:0'), 'sa1_module.conv.local_nn.2.lora_B': tensor([[-4.8733e-10, -3.3998e-10, -8.4509e-10, -2.2431e-09,  1.4880e-09,\n",
      "         -4.1139e-09,  1.3512e-09,  3.4792e-09],\n",
      "        [ 1.0752e-03, -3.8352e-04,  4.2537e-04,  5.6117e-05,  1.9788e-05,\n",
      "          5.2151e-06, -1.0702e-03,  6.0563e-06],\n",
      "        [-2.5956e-06, -5.4969e-07,  2.2456e-06, -1.6262e-07, -4.2692e-07,\n",
      "         -8.1605e-07,  2.3681e-06,  1.9721e-08],\n",
      "        [-2.4372e-04,  1.3836e-04, -9.1065e-04,  2.5689e-05, -2.8904e-06,\n",
      "         -2.0632e-05,  1.1953e-03,  1.1629e-05],\n",
      "        [-3.4843e-05,  9.5181e-05, -8.3954e-05,  2.0452e-05,  3.0333e-06,\n",
      "         -6.0714e-06,  7.2971e-04,  2.6985e-06],\n",
      "        [-3.1368e-05,  1.2569e-05,  1.0910e-05,  1.4204e-06,  2.2367e-06,\n",
      "          8.9640e-06,  1.5484e-04, -2.7288e-06],\n",
      "        [-3.1288e-04,  1.1628e-04,  1.9513e-04,  1.9204e-06,  1.0876e-06,\n",
      "          1.9279e-05,  6.0752e-04, -3.3575e-05],\n",
      "        [ 3.8494e-06,  2.0877e-05, -4.2671e-06, -2.7925e-06,  4.3572e-08,\n",
      "          2.8639e-07,  4.4183e-05, -3.9762e-07],\n",
      "        [ 1.3855e-03, -5.7724e-04,  6.1571e-04, -3.5531e-05,  7.1549e-06,\n",
      "         -2.2557e-05, -1.2219e-03,  3.9455e-05],\n",
      "        [-4.4376e-04,  1.4981e-04, -8.4618e-04, -1.2745e-05, -5.9464e-06,\n",
      "          1.0045e-05, -6.7089e-04, -1.5429e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.1788e-05, -2.4351e-05,  1.8641e-04,  1.8642e-05,  2.9452e-06,\n",
      "         -1.6750e-06,  4.1349e-05, -2.6553e-06],\n",
      "        [ 1.6994e-03, -5.5902e-04,  5.5150e-04, -5.3892e-05, -1.5862e-06,\n",
      "         -1.5968e-05,  9.7129e-04,  1.0653e-04],\n",
      "        [ 1.9574e-04, -5.9676e-05, -8.8811e-05,  1.0417e-05, -1.4715e-05,\n",
      "         -9.0649e-06, -4.2000e-05,  9.0438e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.7323e-04, -8.9438e-06,  3.5156e-04,  7.9823e-06, -3.4710e-06,\n",
      "         -4.8972e-05, -1.7479e-03,  4.8416e-05],\n",
      "        [ 1.2601e-06,  4.6802e-07,  5.0037e-06, -4.4756e-07, -1.2697e-08,\n",
      "         -2.8185e-07,  1.4267e-05,  4.1939e-07],\n",
      "        [-2.5211e-04,  9.4431e-05, -7.3945e-04, -9.3764e-06,  1.0346e-05,\n",
      "          8.9398e-06,  2.8838e-04, -3.6627e-06],\n",
      "        [ 3.8099e-04, -1.3564e-04,  8.2401e-04, -2.6836e-05, -9.2073e-06,\n",
      "          1.3321e-05,  1.9627e-04,  9.0438e-06],\n",
      "        [ 1.0814e-03, -3.4818e-04,  1.1053e-04, -4.9959e-05, -1.7451e-05,\n",
      "         -9.8871e-05, -4.5571e-03,  8.9843e-05],\n",
      "        [-5.0569e-05,  1.1994e-04,  5.5733e-04,  2.9847e-05, -1.0271e-06,\n",
      "         -5.4742e-05,  4.1683e-04,  1.9396e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 8.4972e-04, -3.0341e-04,  4.9303e-04, -1.4366e-05,  9.9417e-06,\n",
      "          4.8428e-05, -1.8473e-03,  2.6392e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.2746e-04, -2.1162e-05, -2.7403e-04, -1.3939e-05, -5.0934e-06,\n",
      "         -1.2976e-05, -1.3707e-04,  2.7901e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.1265e-03, -2.2196e-04,  5.9031e-05, -1.5301e-06, -4.8325e-06,\n",
      "         -9.3076e-05, -2.6185e-03,  7.3907e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.1286e-04, -8.9197e-05,  4.3087e-04,  4.1916e-05,  1.5582e-06,\n",
      "         -2.9214e-05, -9.2103e-06,  2.3063e-05],\n",
      "        [-1.8174e-03,  1.6960e-03, -8.2179e-04,  8.3681e-05,  2.1667e-05,\n",
      "         -3.1244e-05,  3.0975e-03, -6.3254e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.4562e-05,  1.6799e-04,  3.4191e-04, -8.7172e-05, -5.6805e-06,\n",
      "         -2.9382e-05, -1.0970e-04,  7.1568e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.7402e-03,  3.7652e-04, -1.1485e-03,  3.9963e-05, -1.2585e-06,\n",
      "         -2.0503e-05, -7.2280e-04, -5.3046e-05],\n",
      "        [-4.6704e-04,  1.1777e-04,  1.2584e-04, -2.6409e-06, -3.6930e-07,\n",
      "         -1.1431e-05,  1.1057e-03,  6.8305e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.8935e-05, -9.4522e-07, -1.9750e-04,  5.7823e-05,  4.2708e-06,\n",
      "         -1.9377e-05, -2.8908e-04, -2.2721e-06],\n",
      "        [-1.4106e-04,  2.6152e-06, -3.7169e-04,  1.7458e-05,  2.2921e-06,\n",
      "          5.9489e-06, -6.4487e-05, -2.6941e-06],\n",
      "        [ 4.9378e-04, -3.1812e-04,  4.8923e-04,  2.2241e-05, -2.4291e-06,\n",
      "          1.8774e-05,  1.7031e-04,  1.2040e-05],\n",
      "        [-1.5382e-03,  4.4588e-04, -1.0066e-03,  2.9049e-05,  3.4567e-06,\n",
      "         -2.1157e-05,  1.3600e-03, -7.0842e-05],\n",
      "        [-8.7635e-05, -7.9899e-05, -3.9208e-04,  4.9548e-06,  8.6537e-07,\n",
      "         -1.3988e-05, -6.0778e-04,  1.9459e-07],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.5924e-04,  1.3610e-04, -7.9106e-05,  6.2066e-06,  1.8472e-06,\n",
      "         -1.6076e-05,  3.9601e-04,  1.7661e-05],\n",
      "        [ 4.9276e-04, -1.3200e-04, -2.2202e-04, -9.0984e-06,  1.6911e-06,\n",
      "          4.2709e-06,  4.5471e-04,  1.8834e-05],\n",
      "        [-4.0461e-04,  1.3255e-04,  7.0200e-05, -1.9503e-05,  1.0773e-05,\n",
      "          4.2835e-05,  1.3381e-04, -2.8651e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.2319e-05, -5.5218e-06, -8.5956e-05, -8.1199e-06, -5.3883e-07,\n",
      "         -9.4993e-06, -3.6934e-05,  4.3733e-06],\n",
      "        [ 2.1943e-04, -2.4679e-04, -1.9208e-04,  9.7524e-05, -5.6711e-06,\n",
      "         -5.2885e-05, -2.2304e-03,  9.0422e-05],\n",
      "        [-9.3940e-04,  5.7264e-04,  4.7771e-04,  3.2864e-05, -3.6146e-06,\n",
      "         -7.3839e-05,  2.3526e-03, -8.8683e-08],\n",
      "        [-7.7720e-04,  2.0786e-04, -1.0188e-03, -7.6618e-05, -7.5167e-06,\n",
      "          3.5706e-05, -2.4294e-04, -2.7812e-05],\n",
      "        [-5.2510e-04,  2.1177e-04,  2.9090e-04, -2.6073e-05,  5.9735e-06,\n",
      "          1.2868e-05,  4.7947e-04, -2.7763e-05],\n",
      "        [-8.3444e-04,  5.3842e-04,  2.4242e-04,  7.9718e-06, -7.2040e-06,\n",
      "         -4.0032e-05,  7.5589e-04, -4.6444e-06],\n",
      "        [ 1.0802e-05,  3.7696e-06,  7.5113e-06, -2.8441e-06,  6.8640e-07,\n",
      "         -2.2961e-06,  5.6787e-05,  2.1831e-06],\n",
      "        [-5.2504e-04,  2.5180e-04, -9.0631e-05, -1.9942e-05, -5.4961e-06,\n",
      "          2.9771e-05, -1.8344e-04, -2.7886e-05],\n",
      "        [ 3.3985e-04, -6.8885e-05,  1.0274e-04, -5.2062e-05,  9.5532e-07,\n",
      "          7.8280e-06, -1.1454e-03,  1.6781e-05],\n",
      "        [-2.1295e-03,  6.0109e-04, -1.0665e-03,  2.2421e-05,  3.4970e-06,\n",
      "          6.2930e-05,  1.9767e-03, -3.4388e-04],\n",
      "        [ 1.7666e-04, -8.7944e-06,  3.9230e-04,  3.8910e-05,  4.1600e-06,\n",
      "         -1.3176e-06, -5.4653e-04, -9.4503e-06],\n",
      "        [ 6.5980e-04, -9.5660e-05, -1.4927e-04,  3.5432e-05,  1.5002e-06,\n",
      "         -1.5851e-04, -3.2276e-03, -4.1352e-05],\n",
      "        [-4.6470e-05,  4.6931e-05, -8.8663e-05,  5.3556e-07, -3.9696e-07,\n",
      "          2.8351e-06,  2.7649e-04,  3.7674e-06],\n",
      "        [-5.4731e-04,  2.2980e-04,  2.8822e-04,  2.0171e-05,  7.9848e-06,\n",
      "          8.1583e-06,  1.7249e-04, -1.4019e-05]], device='cuda:0'), 'sa1_module.conv.local_nn.4.lora_A': tensor([[ 1.6559e-09, -6.9756e-05, -3.9059e-10, -1.1821e-04,  2.9927e-04,\n",
      "          9.0529e-07, -6.5519e-05,  8.1318e-08, -2.7621e-05, -2.2774e-05,\n",
      "         -4.9408e-10, -2.1402e-04, -2.5006e-05, -4.6765e-06,  1.3405e-08,\n",
      "          1.1562e-05,  3.4034e-04, -2.6934e-05, -3.3434e-05,  4.2890e-06,\n",
      "         -2.3487e-04,  1.0328e-10,  3.3553e-08, -3.7984e-05, -1.6271e-09,\n",
      "          2.9094e-04, -5.8389e-06, -2.5704e-05,  4.3427e-09, -7.2211e-05,\n",
      "          3.1896e-05, -2.0534e-04,  3.0272e-09,  1.0279e-05,  9.1574e-10,\n",
      "          5.5556e-05, -2.3180e-06, -1.2786e-07,  8.8961e-09, -2.7929e-05,\n",
      "         -7.8660e-05,  2.2678e-04, -3.1144e-05, -1.8729e-06, -8.2340e-10,\n",
      "          2.8734e-09,  9.1375e-07, -2.0663e-05,  4.5502e-05,  1.2364e-08,\n",
      "          1.6404e-04,  1.0870e-05, -1.7573e-04,  1.4462e-05, -6.3035e-05,\n",
      "         -6.6660e-05, -3.1105e-04, -5.1020e-06, -2.9957e-04, -1.4008e-04,\n",
      "         -3.9936e-06,  7.4345e-06, -6.5707e-08,  4.9349e-04],\n",
      "        [ 6.6211e-10, -3.5208e-04,  1.6218e-08, -1.0768e-03, -6.7829e-05,\n",
      "          1.3108e-05, -1.5741e-04,  2.5735e-06, -1.3084e-03, -2.1761e-04,\n",
      "         -3.0035e-10, -2.5081e-04, -1.1206e-03, -4.2465e-05,  1.4549e-09,\n",
      "         -2.8405e-05, -3.1465e-09,  2.7569e-04, -1.5812e-05,  4.4184e-05,\n",
      "         -3.0138e-04, -2.7876e-07, -7.3827e-11, -1.2808e-03, -1.2770e-09,\n",
      "         -6.8350e-04, -4.6313e-09, -6.6735e-04,  2.8525e-04, -2.5095e-04,\n",
      "          1.9966e-04,  3.8055e-04, -1.6536e-08,  7.7942e-04, -8.0753e-07,\n",
      "         -1.1040e-04,  1.6107e-05,  8.5118e-09, -1.5430e-08, -3.2337e-06,\n",
      "         -8.0277e-04, -1.2347e-03, -1.6886e-04, -5.0433e-05, -9.2074e-10,\n",
      "         -1.7888e-11, -3.1871e-04, -3.2686e-04, -5.4110e-04,  6.8749e-10,\n",
      "          3.9018e-06, -2.6871e-05, -8.5726e-04,  6.3280e-04,  1.4833e-04,\n",
      "         -3.9430e-04, -2.6541e-04,  1.7947e-05, -4.8125e-04, -3.2172e-04,\n",
      "          9.5836e-05, -4.4162e-05,  2.0718e-07,  3.6394e-04],\n",
      "        [-1.3628e-09, -2.7452e-06, -7.3157e-08, -4.0777e-06, -9.2670e-07,\n",
      "         -8.2399e-07,  7.6187e-06,  4.9998e-08,  1.0276e-06,  6.1822e-06,\n",
      "          7.9986e-10,  1.3298e-06,  2.5957e-06,  1.7935e-07,  2.5150e-04,\n",
      "          8.3435e-07, -5.1001e-06,  5.1411e-05, -4.9461e-05,  4.7785e-07,\n",
      "          1.3079e-06, -1.7257e-08,  4.2420e-10, -2.3819e-04, -3.0415e-07,\n",
      "          6.5601e-08, -9.7379e-07,  1.2426e-05,  1.7383e-09,  5.0276e-05,\n",
      "          5.6133e-06,  9.0214e-05,  3.1818e-08, -1.8226e-04, -5.1731e-06,\n",
      "          8.8124e-06, -1.4499e-05, -6.2267e-10, -5.6257e-09, -2.1451e-06,\n",
      "         -8.2067e-06, -4.3505e-06,  5.2150e-06, -3.1196e-07,  8.3987e-05,\n",
      "         -2.2773e-09,  2.6409e-07, -2.6250e-06,  2.8582e-06, -9.7284e-05,\n",
      "          5.4760e-08, -5.5363e-07, -6.4067e-06,  1.2844e-05,  2.3707e-05,\n",
      "         -6.0884e-06,  4.5129e-09, -1.1330e-06,  3.3545e-04, -8.0137e-06,\n",
      "          1.3140e-06,  7.3149e-07, -7.4718e-09,  1.1016e-05],\n",
      "        [ 1.0162e-10, -6.1902e-04,  2.4216e-06, -1.8385e-03, -1.4272e-05,\n",
      "          8.1723e-06, -6.2578e-05,  1.7421e-04, -1.3265e-04, -2.4260e-04,\n",
      "          1.2828e-05, -6.3908e-05, -5.1615e-04, -2.4168e-04, -2.4168e-07,\n",
      "         -1.7012e-05, -8.3760e-07,  2.7197e-04, -4.1846e-05,  9.4904e-05,\n",
      "         -3.4840e-04, -5.7974e-10,  1.1927e-07, -2.0050e-03,  1.8028e-04,\n",
      "         -6.5072e-04,  1.7705e-09, -1.5791e-04,  8.5848e-05, -1.6714e-03,\n",
      "          2.1217e-04, -4.9077e-10, -3.0708e-09,  3.2208e-07, -3.6239e-08,\n",
      "          2.2610e-04,  3.0155e-05, -6.0486e-10, -4.6420e-10, -1.0052e-04,\n",
      "         -7.1608e-04, -6.6782e-04,  4.4631e-05, -1.1976e-04,  2.6225e-09,\n",
      "          8.2759e-08, -1.0468e-04, -6.6094e-04, -5.2576e-04,  8.6596e-05,\n",
      "         -1.3178e-04, -2.5713e-05, -1.0061e-03,  6.7747e-04, -1.8673e-04,\n",
      "         -4.9956e-04,  1.3173e-04,  3.7109e-05,  2.6653e-04, -6.3917e-04,\n",
      "          9.7977e-05, -7.5581e-05, -2.8372e-06, -4.3698e-05],\n",
      "        [-4.1779e-09,  6.1004e-05,  5.4421e-09, -2.7789e-05, -1.3886e-06,\n",
      "         -1.2923e-07, -6.1230e-06, -9.1660e-08,  1.7991e-06, -8.7196e-06,\n",
      "          1.0815e-08,  3.5903e-06, -2.4112e-05,  2.8807e-06,  3.2678e-09,\n",
      "         -5.1325e-06,  2.2571e-05, -3.6229e-05, -2.3922e-06, -4.6933e-06,\n",
      "         -2.9304e-05, -8.0427e-07,  8.6640e-07,  1.1121e-04, -7.4225e-07,\n",
      "          5.1048e-05,  9.6765e-09, -5.6418e-06, -2.4721e-08, -1.8601e-05,\n",
      "         -3.4131e-05, -3.0075e-09,  1.9126e-04, -1.7463e-06,  1.2962e-07,\n",
      "         -2.0500e-05, -2.4523e-04, -1.7158e-08,  2.2985e-09,  9.0274e-06,\n",
      "         -6.3341e-05,  2.5390e-04, -4.8772e-06,  1.1597e-06, -1.8934e-04,\n",
      "         -1.4426e-08, -2.4485e-06,  2.8555e-05, -8.0697e-05, -2.4888e-07,\n",
      "         -2.6508e-08, -1.7829e-06, -4.2088e-05, -2.0718e-05, -4.2423e-05,\n",
      "         -6.8521e-06, -4.4349e-07,  5.0989e-07,  2.1244e-07,  6.8392e-05,\n",
      "         -1.2591e-06,  1.6297e-06, -2.0647e-07, -5.8023e-05],\n",
      "        [-5.3926e-09,  2.7170e-04, -6.7689e-09, -7.3415e-05,  5.6393e-05,\n",
      "         -7.2539e-07,  8.9587e-05, -5.5228e-07,  3.6644e-06, -1.1671e-04,\n",
      "         -9.7313e-07, -1.4350e-04, -1.1296e-05, -1.7305e-06, -1.3414e-10,\n",
      "         -9.7196e-07, -1.1992e-07, -1.1114e-04, -3.5865e-05,  5.0905e-06,\n",
      "         -7.0681e-05, -6.5204e-10, -1.2538e-05,  1.1686e-05,  4.0401e-07,\n",
      "         -7.8815e-05,  9.8772e-07,  4.7844e-05,  1.9269e-04,  3.1015e-05,\n",
      "         -4.6993e-06,  5.7418e-05, -2.3878e-04, -1.1631e-06,  8.1195e-07,\n",
      "         -9.5303e-05,  3.6188e-07,  4.7166e-09, -1.1034e-10,  9.2315e-06,\n",
      "         -2.6763e-05, -3.3194e-05, -4.5247e-05, -2.3785e-06, -5.4539e-05,\n",
      "          1.6114e-05,  3.6885e-07, -1.7421e-06, -7.7724e-05, -3.8734e-08,\n",
      "         -9.5975e-08,  8.9022e-07, -7.8723e-05, -8.6884e-05, -1.4311e-05,\n",
      "         -1.5741e-04,  5.8529e-08,  1.7194e-07,  2.3445e-05, -1.3464e-05,\n",
      "         -4.7709e-06,  2.9913e-04,  8.1170e-08, -2.7553e-05],\n",
      "        [-1.0494e-07, -3.2637e-06, -4.0048e-06, -1.2138e-04, -3.8355e-04,\n",
      "          6.6471e-05,  3.8143e-04, -1.1114e-07,  2.6680e-06,  7.6225e-06,\n",
      "          1.3610e-07, -1.9986e-05, -4.4840e-05,  1.9288e-07, -4.6536e-09,\n",
      "          1.9708e-06, -1.5234e-05,  1.0160e-05,  4.0798e-06,  3.1536e-07,\n",
      "         -4.0654e-05, -2.1495e-10, -7.9810e-09, -3.8980e-04, -1.7512e-08,\n",
      "         -4.4874e-04,  1.3082e-10,  5.2514e-06, -3.4887e-08, -9.7956e-06,\n",
      "         -1.3844e-05,  4.0476e-10, -9.9315e-09,  4.4548e-06, -8.2498e-10,\n",
      "         -4.1487e-05,  6.8497e-07, -3.6124e-10, -9.9171e-10, -8.0664e-06,\n",
      "          4.6722e-04, -2.3207e-05,  7.4872e-06, -9.7647e-07,  6.2480e-06,\n",
      "          5.5219e-07, -6.9554e-07, -3.7292e-05, -3.7478e-05, -1.3504e-10,\n",
      "          1.1575e-07,  5.9572e-07, -3.9709e-05,  4.2028e-06,  1.0000e-04,\n",
      "         -4.0694e-05, -6.0988e-08,  6.9790e-07,  5.5420e-06, -2.2293e-05,\n",
      "          2.5816e-06,  3.7166e-06, -8.5175e-08, -1.4801e-05],\n",
      "        [ 1.2435e-09, -3.5767e-05, -3.5078e-09,  5.5488e-05, -3.1394e-04,\n",
      "         -2.1087e-07,  5.0010e-05, -4.2094e-07,  3.7807e-05, -1.2229e-04,\n",
      "          5.7934e-10,  2.0510e-05,  5.0412e-05,  8.3271e-06, -1.6639e-08,\n",
      "          2.5717e-07,  7.3807e-09, -1.9894e-06, -9.7701e-05,  7.0174e-07,\n",
      "         -3.3913e-06,  3.8010e-08, -6.9408e-08,  8.0663e-05, -1.1059e-09,\n",
      "          4.5042e-05,  5.0943e-05,  1.3811e-05,  8.2678e-07,  3.3355e-06,\n",
      "         -2.6982e-05, -1.4345e-08, -5.2789e-08, -4.7783e-05, -1.4163e-09,\n",
      "          4.3137e-05,  4.4718e-06,  2.6931e-07, -1.6296e-04,  5.4075e-05,\n",
      "          4.7735e-05,  7.5150e-05,  1.6330e-05, -5.5482e-05, -3.4097e-04,\n",
      "          2.8344e-08,  2.4765e-06, -2.8037e-04,  2.5356e-05, -7.8126e-07,\n",
      "         -2.9024e-07,  1.7119e-06,  7.1163e-05,  2.3422e-05,  2.8441e-05,\n",
      "          1.4385e-05,  3.7629e-04,  1.9521e-06,  1.3447e-05,  1.2902e-05,\n",
      "          2.1253e-05, -1.0325e-05,  3.2973e-04,  4.4129e-05]], device='cuda:0'), 'sa1_module.conv.local_nn.4.lora_B': tensor([[-5.8771e-06, -5.7103e-04,  8.4894e-07,  ...,  2.2550e-05,\n",
      "          2.1490e-06,  4.8131e-05],\n",
      "        [ 5.1626e-05, -5.9166e-04, -4.6462e-06,  ...,  2.4461e-04,\n",
      "          6.0095e-05, -4.3328e-04],\n",
      "        [ 4.7527e-06,  3.9051e-04, -4.8961e-07,  ..., -2.5777e-05,\n",
      "          2.8958e-06, -6.6367e-05],\n",
      "        ...,\n",
      "        [ 3.0429e-05, -8.7269e-05, -2.2219e-07,  ..., -2.3023e-05,\n",
      "          8.7043e-06, -9.9029e-05],\n",
      "        [-8.2981e-06, -2.4021e-04, -3.5796e-07,  ..., -1.7816e-05,\n",
      "         -5.1290e-06, -5.8303e-05],\n",
      "        [-1.0593e-05, -2.5844e-05, -1.8562e-06,  ...,  5.3942e-05,\n",
      "         -1.2889e-07, -4.8695e-05]], device='cuda:0'), 'sa2_module.conv.local_nn.0.lora_A': tensor([[-1.2195e-09, -8.3858e-09,  9.0643e-09,  ..., -1.6922e-09,\n",
      "          3.0658e-09, -1.3818e-07],\n",
      "        [-1.0272e-07,  4.1212e-09, -4.2586e-08,  ..., -2.4657e-10,\n",
      "         -5.7310e-09, -4.5558e-09],\n",
      "        [ 7.2143e-10,  7.8615e-08, -3.2238e-09,  ..., -3.2466e-10,\n",
      "         -5.4241e-09, -1.3044e-07],\n",
      "        ...,\n",
      "        [-5.3681e-09,  1.5170e-09, -1.3794e-07,  ...,  3.6985e-09,\n",
      "          1.9261e-09,  2.1736e-09],\n",
      "        [-1.2384e-08,  5.4010e-10, -2.0266e-10,  ...,  5.6228e-09,\n",
      "          1.0018e-08, -2.5350e-09],\n",
      "        [ 3.4237e-09,  1.6967e-10, -1.0416e-07,  ..., -6.1959e-08,\n",
      "         -1.3918e-07, -2.3975e-09]], device='cuda:0'), 'sa2_module.conv.local_nn.0.lora_B': tensor([[-1.7041e-11, -3.6348e-11,  3.8019e-11,  ..., -1.3013e-10,\n",
      "          5.5490e-10,  3.5287e-10],\n",
      "        [-3.7921e-09, -2.2329e-09,  2.8985e-09,  ...,  3.9436e-08,\n",
      "          1.1045e-07,  2.9787e-08],\n",
      "        [ 4.5741e-09, -2.7603e-09,  8.5181e-10,  ..., -1.4813e-08,\n",
      "          1.0931e-08,  2.9013e-09],\n",
      "        ...,\n",
      "        [-1.0378e-08, -2.0886e-09, -8.2703e-09,  ..., -1.1939e-08,\n",
      "         -1.9575e-08, -1.3898e-09],\n",
      "        [ 1.3049e-08,  5.8659e-09,  9.4886e-10,  ..., -6.5583e-09,\n",
      "          9.1091e-09,  1.3243e-09],\n",
      "        [-6.3567e-09,  2.7226e-09,  3.7197e-09,  ..., -2.9693e-09,\n",
      "          1.1709e-08,  4.3256e-09]], device='cuda:0'), 'sa2_module.conv.local_nn.2.lora_A': tensor([[-1.2974e-08, -1.6797e-08,  1.9275e-09,  ...,  9.4484e-09,\n",
      "         -2.8588e-09,  5.9153e-09],\n",
      "        [ 1.1022e-08, -9.0511e-09,  1.3639e-07,  ...,  3.6176e-09,\n",
      "         -9.8704e-10,  3.7214e-09],\n",
      "        [-2.5066e-10, -8.5438e-09, -1.1072e-08,  ..., -1.0408e-09,\n",
      "          1.5156e-07,  5.5791e-09],\n",
      "        ...,\n",
      "        [-2.2123e-08, -8.6126e-09, -5.6729e-10,  ..., -9.7807e-09,\n",
      "         -6.6252e-09, -9.8454e-10],\n",
      "        [ 8.8632e-08,  1.8525e-10, -1.6592e-08,  ..., -9.3111e-10,\n",
      "         -2.5789e-09,  3.1012e-09],\n",
      "        [ 1.0737e-07,  1.0648e-09,  7.7397e-10,  ..., -1.2032e-08,\n",
      "          1.9794e-09,  3.9248e-08]], device='cuda:0'), 'sa2_module.conv.local_nn.2.lora_B': tensor([[-1.1759e-08,  3.8576e-09, -2.5469e-09,  ..., -1.8916e-09,\n",
      "         -2.2278e-08, -2.2926e-08],\n",
      "        [ 6.6749e-09, -1.4399e-08, -7.8214e-10,  ...,  6.8039e-09,\n",
      "          6.7492e-10,  1.2631e-08],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 9.6601e-09, -2.2508e-08,  1.4034e-09,  ..., -6.1450e-09,\n",
      "         -2.2900e-08, -2.7699e-09],\n",
      "        [ 4.5069e-08,  4.3386e-08,  2.5718e-09,  ..., -4.0979e-08,\n",
      "          7.7337e-08,  2.7689e-08]], device='cuda:0'), 'sa2_module.conv.local_nn.4.lora_A': tensor([[ 7.2567e-08, -4.9514e-09,  3.7297e-09,  ...,  2.6110e-09,\n",
      "         -1.2250e-09,  5.3432e-08],\n",
      "        [-5.1051e-09,  5.0657e-08,  3.1517e-10,  ...,  4.2613e-10,\n",
      "         -1.8749e-08, -1.3994e-07],\n",
      "        [-2.8686e-09, -4.7291e-10,  1.3947e-07,  ...,  5.6684e-10,\n",
      "          4.7683e-09, -3.5224e-08],\n",
      "        ...,\n",
      "        [ 2.5973e-09, -3.9945e-08,  3.0079e-07,  ...,  4.6417e-09,\n",
      "          2.4938e-09, -8.1691e-09],\n",
      "        [ 1.7507e-09, -2.1475e-08,  2.5598e-09,  ...,  3.3333e-08,\n",
      "         -4.0516e-08,  5.7167e-09],\n",
      "        [-1.0833e-09,  1.5874e-09, -9.5936e-09,  ..., -4.6529e-09,\n",
      "         -1.7670e-09,  2.4435e-08]], device='cuda:0'), 'sa2_module.conv.local_nn.4.lora_B': tensor([[-2.0405e-08, -4.4405e-08,  1.4505e-08,  ..., -2.0905e-08,\n",
      "          9.9768e-09,  1.3181e-08],\n",
      "        [-1.5486e-08,  4.3415e-08, -1.0261e-08,  ..., -4.8445e-09,\n",
      "          1.1087e-08, -5.8651e-08],\n",
      "        [-2.9560e-08,  7.6282e-09,  3.2607e-08,  ...,  7.8122e-09,\n",
      "          3.4613e-09,  5.6444e-09],\n",
      "        ...,\n",
      "        [-4.7124e-08, -6.0264e-08, -6.2182e-08,  ..., -5.1970e-08,\n",
      "         -2.9678e-09, -1.0752e-07],\n",
      "        [ 1.9220e-08,  9.7233e-08,  3.1261e-08,  ..., -2.9488e-08,\n",
      "         -2.3222e-08,  6.8161e-09],\n",
      "        [-7.1667e-09,  2.0385e-08, -6.6385e-09,  ...,  1.4009e-08,\n",
      "          1.4711e-08,  6.9219e-08]], device='cuda:0'), 'sa3_module.nn.0.lora_A': tensor([[ 1.0969e-09,  2.8154e-09, -1.9213e-09,  ...,  1.3181e-09,\n",
      "          2.9625e-08, -2.1005e-08],\n",
      "        [ 1.6620e-08,  3.0003e-09,  7.9468e-10,  ..., -1.3585e-08,\n",
      "         -3.2454e-09,  1.0366e-08],\n",
      "        [-3.6083e-10, -2.5435e-09,  3.3061e-09,  ..., -1.4267e-08,\n",
      "          1.8123e-08,  9.5520e-09],\n",
      "        ...,\n",
      "        [ 2.8582e-09, -5.7319e-10, -1.7324e-09,  ...,  1.0039e-08,\n",
      "         -8.7404e-09, -4.2228e-09],\n",
      "        [-2.6621e-09,  3.8126e-09,  1.6266e-11,  ...,  3.1342e-08,\n",
      "          1.1789e-08, -1.1471e-08],\n",
      "        [ 1.6876e-09,  3.9926e-09, -1.3321e-08,  ...,  7.9772e-09,\n",
      "          3.3792e-08,  1.0238e-07]], device='cuda:0'), 'sa3_module.nn.0.lora_B': tensor([[-3.0385e-09,  5.6581e-09,  8.9289e-09,  ...,  1.2080e-09,\n",
      "          5.5243e-09,  1.8236e-08],\n",
      "        [ 8.9351e-09, -1.8087e-09, -1.1521e-08,  ..., -1.0498e-08,\n",
      "         -1.5870e-08, -1.1971e-08],\n",
      "        [ 3.9685e-09,  1.0503e-08, -2.3528e-09,  ..., -1.1139e-09,\n",
      "         -3.5573e-09,  1.3559e-08],\n",
      "        ...,\n",
      "        [-4.8282e-09, -3.1457e-10,  6.0430e-09,  ...,  2.4360e-09,\n",
      "         -3.4369e-09,  1.8074e-09],\n",
      "        [ 1.1445e-08,  2.1480e-09,  4.5196e-09,  ..., -1.1726e-08,\n",
      "         -9.0050e-09,  5.7274e-09],\n",
      "        [-2.0713e-08,  4.1848e-09,  2.2779e-09,  ...,  1.6192e-08,\n",
      "         -1.1430e-08,  2.1838e-08]], device='cuda:0'), 'sa3_module.nn.2.lora_A': tensor([[ 5.4387e-09,  3.9413e-08,  2.5909e-08,  ...,  5.4826e-09,\n",
      "          7.9916e-09,  2.5310e-08],\n",
      "        [ 6.0111e-09, -2.8581e-09, -7.1123e-09,  ..., -7.6475e-10,\n",
      "          1.6539e-08,  5.3447e-09],\n",
      "        [-1.3155e-09, -1.1287e-08,  2.6764e-09,  ..., -8.4610e-10,\n",
      "         -4.0149e-09, -1.6568e-09],\n",
      "        ...,\n",
      "        [ 4.9368e-09,  4.2638e-09,  1.0683e-08,  ..., -7.4799e-09,\n",
      "          1.7121e-08,  3.0917e-09],\n",
      "        [-2.5959e-08, -1.1528e-07, -1.3724e-07,  ..., -6.9563e-09,\n",
      "         -3.7171e-08, -5.9597e-08],\n",
      "        [-2.7431e-09, -1.9427e-09,  7.4232e-10,  ...,  2.6269e-10,\n",
      "         -4.9526e-09,  4.7338e-10]], device='cuda:0'), 'sa3_module.nn.2.lora_B': tensor([[-2.8496e-08,  3.2846e-09, -2.9410e-09,  ..., -5.6555e-09,\n",
      "          1.1820e-07,  6.0245e-09],\n",
      "        [-3.8665e-09, -8.8798e-10, -1.2556e-09,  ...,  2.4096e-09,\n",
      "         -1.4852e-08,  2.8937e-09],\n",
      "        [ 2.3359e-09, -2.8135e-09,  4.1527e-09,  ..., -3.2691e-09,\n",
      "         -1.1089e-08, -2.1139e-09],\n",
      "        ...,\n",
      "        [ 2.1704e-08, -4.6095e-11, -4.7457e-09,  ..., -3.6898e-10,\n",
      "         -5.7188e-08, -3.6986e-09],\n",
      "        [-5.2242e-08,  1.9588e-08,  8.3859e-09,  ..., -2.2588e-08,\n",
      "          8.8161e-08, -2.5216e-09],\n",
      "        [-1.7237e-08,  7.5825e-09,  9.4624e-10,  ..., -4.1509e-09,\n",
      "          1.0505e-07, -2.0287e-09]], device='cuda:0'), 'sa3_module.nn.4.lora_A': tensor([[-5.7204e-04,  2.1413e-05, -8.8193e-06,  ...,  6.2976e-04,\n",
      "         -1.1595e-04, -3.4695e-04],\n",
      "        [ 2.6705e-04, -1.9519e-05,  8.3446e-06,  ..., -8.8783e-04,\n",
      "         -2.9734e-04,  3.5467e-04],\n",
      "        [ 8.3947e-04, -3.0600e-06,  1.4961e-05,  ..., -8.3144e-04,\n",
      "          1.2992e-04, -1.3792e-04],\n",
      "        ...,\n",
      "        [ 4.9494e-04, -3.5063e-06,  1.9974e-05,  ..., -3.7067e-04,\n",
      "          1.7586e-04,  3.4030e-04],\n",
      "        [ 1.4286e-03, -6.4977e-06, -1.2192e-05,  ..., -4.1421e-04,\n",
      "          2.1432e-04,  6.3449e-04],\n",
      "        [ 5.5826e-04, -5.0021e-05,  1.2261e-04,  ..., -1.7294e-03,\n",
      "         -3.4881e-03,  4.3744e-04]], device='cuda:0'), 'sa3_module.nn.4.lora_B': tensor([[-5.3397e-04,  5.2623e-04, -2.9507e-04,  ...,  1.8643e-03,\n",
      "          3.8287e-04, -3.8432e-03],\n",
      "        [-6.2650e-04,  3.3882e-04,  1.2804e-03,  ...,  1.8102e-03,\n",
      "          1.4825e-04, -2.7947e-03],\n",
      "        [ 1.7047e-03, -1.5750e-03, -1.4416e-03,  ..., -1.6255e-03,\n",
      "         -2.2970e-03, -1.0751e-03],\n",
      "        ...,\n",
      "        [ 1.8302e-04, -3.7666e-04, -8.4366e-07,  ...,  2.5365e-04,\n",
      "         -2.7952e-05, -7.7141e-04],\n",
      "        [-1.1824e-03,  8.3791e-04, -1.0450e-04,  ...,  1.4613e-03,\n",
      "          2.3017e-03,  1.2642e-03],\n",
      "        [-1.5313e-03,  1.5147e-03,  1.5616e-03,  ...,  1.8224e-03,\n",
      "          1.5393e-03, -1.2994e-03]], device='cuda:0'), 'fp3_module.nn.0.lora_A': tensor([[-6.0126e-04, -2.1368e-04, -2.0714e-03,  ..., -2.9667e-04,\n",
      "          1.2964e-04, -2.5593e-04],\n",
      "        [-3.5813e-04,  9.3030e-04, -8.4025e-05,  ...,  1.2802e-04,\n",
      "         -1.8216e-04, -1.8658e-04],\n",
      "        [-6.8477e-04,  1.5278e-03,  2.9396e-03,  ...,  3.7525e-03,\n",
      "          2.0787e-03,  2.9625e-03],\n",
      "        ...,\n",
      "        [-1.4474e-04, -1.1209e-04, -5.6700e-05,  ...,  4.5317e-04,\n",
      "          3.6245e-04,  3.1998e-04],\n",
      "        [ 6.8065e-04,  1.4905e-04,  2.0645e-03,  ...,  3.1858e-04,\n",
      "         -1.8318e-04,  2.5306e-04],\n",
      "        [ 1.2258e-03,  1.1684e-04,  2.0696e-03,  ...,  2.5803e-04,\n",
      "         -1.8204e-04,  2.2904e-04]], device='cuda:0'), 'fp3_module.nn.0.lora_B': tensor([[ 1.2764e-03, -1.7372e-03,  1.9286e-03,  ...,  1.1070e-03,\n",
      "         -1.2918e-03, -1.2995e-03],\n",
      "        [-1.1821e-03,  9.7141e-05,  3.1857e-04,  ...,  8.6642e-04,\n",
      "          1.2669e-03,  1.3079e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 3.8372e-03, -2.5161e-03, -3.2200e-03,  ...,  2.3915e-03,\n",
      "         -3.9783e-03, -3.9400e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.3819e-04, -5.2952e-04,  2.7774e-03,  ...,  1.0276e-03,\n",
      "          3.1039e-04,  3.0207e-04]], device='cuda:0'), 'fp3_module.nn.2.lora_A': tensor([[-4.2063e-06, -2.8296e-06,  1.3029e-08,  ..., -5.0434e-07,\n",
      "          4.8331e-09, -4.4571e-08],\n",
      "        [-4.5151e-05,  6.9436e-05, -8.7353e-09,  ...,  2.9070e-05,\n",
      "         -4.7621e-11,  2.7768e-06],\n",
      "        [ 1.2418e-03, -9.4065e-04, -3.1111e-09,  ...,  2.8077e-04,\n",
      "          6.3544e-10, -3.6964e-05],\n",
      "        ...,\n",
      "        [-3.2360e-06, -1.0583e-06,  2.5779e-09,  ..., -4.3007e-06,\n",
      "         -5.1003e-10, -2.2521e-08],\n",
      "        [ 9.4307e-06,  9.3901e-07, -4.4924e-09,  ..., -1.5711e-06,\n",
      "         -1.6210e-09,  7.9293e-07],\n",
      "        [-1.7643e-04, -9.9298e-05,  3.0807e-09,  ..., -9.0619e-05,\n",
      "          7.2661e-10,  2.1109e-07]], device='cuda:0'), 'fp3_module.nn.2.lora_B': tensor([[ 3.6845e-06, -3.5838e-04, -7.4912e-04,  ..., -2.3921e-06,\n",
      "         -5.5448e-06,  8.7205e-04],\n",
      "        [ 4.2757e-06,  7.3202e-04,  1.8718e-03,  ..., -9.6096e-07,\n",
      "         -4.9421e-06,  4.4694e-04],\n",
      "        [-1.1681e-06, -2.7844e-04,  7.7089e-04,  ..., -2.5582e-05,\n",
      "         -1.9561e-06, -5.4212e-04],\n",
      "        ...,\n",
      "        [ 1.2067e-05,  1.5872e-03, -1.4596e-04,  ...,  3.1012e-05,\n",
      "         -5.9612e-05,  2.1381e-03],\n",
      "        [ 1.9618e-05, -2.3304e-03, -1.7995e-03,  ...,  5.7096e-06,\n",
      "         -2.3304e-05, -9.0672e-04],\n",
      "        [-8.4900e-08,  2.4571e-04, -5.0881e-04,  ...,  6.7073e-06,\n",
      "         -3.0880e-06, -6.2267e-04]], device='cuda:0'), 'fp2_module.nn.0.lora_A': tensor([[-1.7152e-03, -2.2343e-03, -1.3486e-04,  ..., -2.4937e-03,\n",
      "         -7.0623e-04,  4.6540e-05],\n",
      "        [ 1.0133e-03,  1.9339e-03,  1.1394e-03,  ...,  2.7096e-03,\n",
      "          9.8339e-04,  7.4441e-05],\n",
      "        [-2.0890e-03, -1.6040e-03,  3.2352e-04,  ..., -1.7998e-03,\n",
      "         -2.5255e-04,  2.2520e-04],\n",
      "        ...,\n",
      "        [-2.4107e-03, -2.8115e-03,  1.1725e-03,  ...,  1.8655e-04,\n",
      "          1.0440e-03,  9.5171e-04],\n",
      "        [ 3.1030e-04,  7.8686e-06, -6.7773e-04,  ...,  3.3793e-03,\n",
      "         -8.3953e-04, -1.5212e-03],\n",
      "        [ 1.3969e-03,  1.9160e-03,  1.0258e-03,  ...,  2.9602e-03,\n",
      "          1.4429e-03,  7.3294e-04]], device='cuda:0'), 'fp2_module.nn.0.lora_B': tensor([[-0.0136,  0.0140, -0.0116,  ..., -0.0029,  0.0107,  0.0148],\n",
      "        [-0.0026,  0.0023, -0.0023,  ..., -0.0025,  0.0028,  0.0027],\n",
      "        [-0.0067,  0.0068, -0.0060,  ..., -0.0014,  0.0023,  0.0072],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0068, -0.0072,  0.0058,  ...,  0.0024, -0.0074, -0.0077],\n",
      "        [ 0.0153, -0.0158,  0.0140,  ...,  0.0078, -0.0107, -0.0164]],\n",
      "       device='cuda:0'), 'fp2_module.nn.2.lora_A': tensor([[ 2.6125e-04,  5.4666e-04,  2.1925e-03,  ...,  2.2079e-10,\n",
      "          9.4580e-04, -5.8401e-03],\n",
      "        [ 6.2322e-04,  9.4427e-04,  3.9715e-03,  ..., -8.5235e-10,\n",
      "          4.0649e-03, -3.9302e-03],\n",
      "        [ 2.7119e-06,  7.6391e-05, -3.7435e-04,  ...,  1.5761e-09,\n",
      "          3.9885e-05,  2.9603e-03],\n",
      "        ...,\n",
      "        [-7.9591e-05, -2.6285e-03, -5.9237e-03,  ...,  3.9216e-09,\n",
      "         -7.1048e-03,  1.7721e-03],\n",
      "        [-1.1966e-03, -2.3970e-03, -8.0233e-03,  ..., -1.7144e-08,\n",
      "         -1.0048e-02,  3.9557e-04],\n",
      "        [-4.8780e-06, -3.3095e-04, -1.8730e-03,  ..., -1.0008e-09,\n",
      "         -6.4602e-04,  6.0162e-03]], device='cuda:0'), 'fp2_module.nn.2.lora_B': tensor([[-0.0013, -0.0054, -0.0009,  ...,  0.0094,  0.0128,  0.0007],\n",
      "        [-0.0041, -0.0023,  0.0022,  ...,  0.0002, -0.0018,  0.0042],\n",
      "        [-0.0041, -0.0026,  0.0007,  ..., -0.0007, -0.0045,  0.0043],\n",
      "        ...,\n",
      "        [-0.0024, -0.0047,  0.0002,  ...,  0.0071,  0.0094,  0.0020],\n",
      "        [-0.0056, -0.0072,  0.0014,  ...,  0.0080,  0.0085,  0.0050],\n",
      "        [-0.0055, -0.0074,  0.0006,  ...,  0.0073,  0.0063,  0.0051]],\n",
      "       device='cuda:0'), 'fp1_module.nn.0.lora_A': tensor([[-0.0026, -0.0010, -0.0079,  ...,  0.0307,  0.0573,  0.1091],\n",
      "        [-0.0040, -0.0014, -0.0028,  ...,  0.0124,  0.0522,  0.0892],\n",
      "        [ 0.0113, -0.0291, -0.0161,  ...,  0.0087,  0.0538,  0.1781],\n",
      "        ...,\n",
      "        [-0.0172,  0.0233,  0.0210,  ..., -0.0205,  0.0156, -0.1741],\n",
      "        [-0.0056,  0.0241,  0.0195,  ..., -0.0299, -0.0519, -0.1398],\n",
      "        [ 0.0189, -0.0482, -0.0256,  ..., -0.0488,  0.0115,  0.1804]],\n",
      "       device='cuda:0'), 'fp1_module.nn.0.lora_B': tensor([[ 0.0201,  0.0169,  0.0268,  ..., -0.0059, -0.0212,  0.0201],\n",
      "        [ 0.0014,  0.0007, -0.0052,  ...,  0.0068,  0.0007, -0.0170],\n",
      "        [-0.0077, -0.0029, -0.0209,  ...,  0.0408,  0.0173, -0.0283],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0008, -0.0025,  0.0144,  ..., -0.0158, -0.0101,  0.0136],\n",
      "        [ 0.0537,  0.0466,  0.1008,  ..., -0.0915, -0.0756,  0.1355]],\n",
      "       device='cuda:0'), 'fp1_module.nn.2.lora_A': tensor([[ 3.1005e-02, -3.8224e-03,  2.6127e-02,  ...,  1.6155e-08,\n",
      "         -1.1780e-02, -1.0317e-01],\n",
      "        [-3.5194e-02,  2.4884e-03, -2.5828e-02,  ..., -2.4304e-09,\n",
      "          1.4645e-02,  1.0681e-01],\n",
      "        [ 3.7330e-02, -4.1998e-03,  2.7097e-02,  ...,  2.4630e-09,\n",
      "         -3.2095e-02, -1.1144e-01],\n",
      "        ...,\n",
      "        [-3.7861e-02,  2.9769e-03, -2.7185e-02,  ..., -5.9630e-10,\n",
      "         -3.6516e-02,  1.1062e-01],\n",
      "        [ 3.1869e-02, -2.8889e-03,  2.6663e-02,  ...,  1.6438e-09,\n",
      "         -2.6015e-02, -1.0629e-01],\n",
      "        [-3.3281e-02,  2.3638e-03, -2.5812e-02,  ..., -6.5777e-09,\n",
      "         -8.0234e-03,  1.0523e-01]], device='cuda:0'), 'fp1_module.nn.2.lora_B': tensor([[-0.0334,  0.0316, -0.0342,  ...,  0.0411, -0.0375,  0.0318],\n",
      "        [ 0.0003, -0.0002,  0.0003,  ..., -0.0003,  0.0003, -0.0003],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0146,  0.0136, -0.0156,  ...,  0.0124, -0.0134,  0.0125],\n",
      "        [-0.0329,  0.0323, -0.0353,  ...,  0.0364, -0.0350,  0.0313],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       device='cuda:0'), 'fp1_module.nn.4.lora_A': tensor([[ 3.5299e-02,  2.3222e-06, -5.2105e-09,  ...,  1.0107e-02,\n",
      "          3.8034e-02,  6.2623e-09],\n",
      "        [-4.0298e-02, -1.9819e-04,  9.7146e-08,  ..., -7.9223e-03,\n",
      "         -3.8991e-02,  6.4382e-09],\n",
      "        [ 3.6731e-02,  1.5436e-04, -2.7833e-09,  ...,  2.6446e-02,\n",
      "          3.4605e-02,  3.3743e-09],\n",
      "        ...,\n",
      "        [ 3.6599e-02,  1.5708e-04, -9.3923e-09,  ...,  9.4853e-03,\n",
      "          3.6659e-02,  1.2274e-10],\n",
      "        [ 3.8652e-02, -5.5950e-04,  6.5855e-09,  ...,  1.5157e-02,\n",
      "          3.6895e-02,  1.7216e-08],\n",
      "        [ 3.6328e-02, -4.5804e-04, -8.6356e-10,  ..., -1.6873e-02,\n",
      "          3.1371e-02, -4.3403e-09]], device='cuda:0'), 'fp1_module.nn.4.lora_B': tensor([[-0.0217,  0.0215, -0.0188,  ..., -0.0193, -0.0211, -0.0133],\n",
      "        [ 0.0128, -0.0125,  0.0111,  ...,  0.0131,  0.0131,  0.0058],\n",
      "        [-0.0212,  0.0225, -0.0205,  ..., -0.0210, -0.0213, -0.0293],\n",
      "        ...,\n",
      "        [-0.0372,  0.0375, -0.0339,  ..., -0.0316, -0.0359, -0.0166],\n",
      "        [ 0.0263, -0.0272,  0.0252,  ...,  0.0289,  0.0279,  0.0357],\n",
      "        [-0.0258,  0.0253, -0.0241,  ..., -0.0297, -0.0265, -0.0249]],\n",
      "       device='cuda:0'), 'mlp.0.lora_A': tensor([[ 5.3894e-02, -3.1388e-02, -6.6860e-03,  ...,  1.0389e-02,\n",
      "         -1.5258e-02,  1.6339e-02],\n",
      "        [ 4.0356e-02, -3.3102e-02, -5.2133e-03,  ...,  5.7339e-02,\n",
      "         -2.8398e-02,  5.5544e-02],\n",
      "        [-8.3716e-05,  3.0275e-02, -1.6231e-02,  ..., -5.3734e-02,\n",
      "          2.3461e-02, -7.8525e-03],\n",
      "        ...,\n",
      "        [-4.2754e-02,  4.4424e-02, -8.1589e-03,  ..., -3.8732e-02,\n",
      "         -7.6940e-03, -5.4032e-02],\n",
      "        [ 4.2202e-02, -4.9845e-03, -1.7050e-02,  ...,  6.5075e-03,\n",
      "         -4.8932e-03,  3.2826e-02],\n",
      "        [-6.0829e-02,  3.4062e-02,  1.4453e-02,  ..., -4.8421e-02,\n",
      "          1.5270e-02, -4.2945e-02]], device='cuda:0'), 'mlp.0.lora_B': tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-2.7597e-02, -2.9290e-02,  2.9671e-02,  ...,  3.0955e-02,\n",
      "         -2.9680e-02,  2.8313e-02],\n",
      "        ...,\n",
      "        [-8.3694e-08, -3.0819e-08, -3.3246e-08,  ...,  1.7464e-08,\n",
      "          7.1336e-09,  1.5083e-07],\n",
      "        [-3.6637e-02, -3.4750e-02,  2.4684e-02,  ...,  1.8698e-02,\n",
      "         -2.6941e-02,  3.2234e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], device='cuda:0'), 'mlp.3.lora_A': tensor([[ 1.2500e-07, -4.3464e-09,  2.7812e-02,  ...,  3.8726e-09,\n",
      "          4.9967e-02,  1.0195e-07],\n",
      "        [ 1.2012e-07,  6.2974e-09,  3.4605e-02,  ..., -1.3986e-09,\n",
      "          9.0736e-02,  3.6650e-09],\n",
      "        [-9.8307e-10,  9.1003e-09,  7.2035e-02,  ...,  4.8400e-10,\n",
      "          4.1772e-02, -3.0996e-09],\n",
      "        ...,\n",
      "        [-4.9518e-11,  5.2195e-09, -5.5376e-02,  ..., -2.7140e-09,\n",
      "          3.0131e-02, -1.3074e-07],\n",
      "        [-5.2418e-08, -4.7216e-09, -7.2340e-02,  ...,  4.3719e-07,\n",
      "         -5.3210e-02, -1.2209e-09],\n",
      "        [-3.6506e-08,  7.1158e-09, -4.9522e-02,  ..., -5.5569e-09,\n",
      "         -3.5756e-03, -3.0684e-09]], device='cuda:0'), 'mlp.3.lora_B': tensor([[ 0.0297,  0.0494,  0.0244,  ...,  0.0026, -0.0297, -0.0073],\n",
      "        [ 0.0402,  0.0507,  0.0372,  ..., -0.0199, -0.0398, -0.0298],\n",
      "        [ 0.0230,  0.0026,  0.0242,  ..., -0.0398, -0.0221, -0.0324],\n",
      "        ...,\n",
      "        [ 0.0255,  0.0354,  0.0223,  ..., -0.0073, -0.0238, -0.0123],\n",
      "        [-0.0174, -0.0137, -0.0147,  ...,  0.0109,  0.0154,  0.0115],\n",
      "        [-0.0359, -0.0258, -0.0336,  ...,  0.0301,  0.0341,  0.0312]],\n",
      "       device='cuda:0'), 'mlp.6.lora_A': tensor([[ 2.5873e-02,  1.1054e-01,  5.3596e-02,  ...,  7.9339e-03,\n",
      "         -6.8405e-05,  2.8729e-04],\n",
      "        [-2.9585e-02, -9.9523e-02, -4.6838e-02,  ..., -3.1594e-02,\n",
      "         -6.1113e-05, -6.1236e-04],\n",
      "        [-2.7715e-02, -9.8781e-02, -5.6474e-02,  ..., -2.0172e-02,\n",
      "         -2.8772e-05, -4.5715e-04],\n",
      "        ...,\n",
      "        [-2.8886e-02, -3.0789e-02, -5.4993e-02,  ..., -2.5256e-02,\n",
      "         -4.5841e-05, -5.0509e-04],\n",
      "        [ 2.9361e-02,  4.9690e-02,  4.4082e-02,  ...,  2.7475e-02,\n",
      "          4.9175e-05,  6.7648e-04],\n",
      "        [ 2.5756e-02,  6.4712e-02,  4.9942e-02,  ...,  1.8445e-02,\n",
      "         -4.1959e-06,  4.8805e-04]], device='cuda:0'), 'mlp.6.lora_B': tensor([[ 0.0530, -0.0606, -0.0572, -0.0574, -0.0582, -0.0589,  0.0597,  0.0558],\n",
      "        [ 0.0419, -0.0451, -0.0447, -0.0464, -0.0466, -0.0471,  0.0439,  0.0464],\n",
      "        [ 0.0587, -0.0496, -0.0552, -0.0530, -0.0505, -0.0521,  0.0530,  0.0538],\n",
      "        [-0.1313,  0.1266,  0.1349,  0.1260,  0.1270,  0.1288, -0.1297, -0.1291],\n",
      "        [-0.1202,  0.1167,  0.1264,  0.1158,  0.1163,  0.1188, -0.1201, -0.1183],\n",
      "        [-0.0072,  0.0052,  0.0068,  0.0076,  0.0072,  0.0062, -0.0076, -0.0073],\n",
      "        [-0.0208,  0.0224,  0.0210,  0.0228,  0.0215,  0.0196, -0.0215, -0.0210],\n",
      "        [-0.0738,  0.0751,  0.0748,  0.0739,  0.0740,  0.0755, -0.0739, -0.0736],\n",
      "        [-0.1647,  0.1567,  0.1721,  0.1533,  0.1567,  0.1602, -0.1622, -0.1600],\n",
      "        [-0.0371,  0.0380,  0.0388,  0.0385,  0.0378,  0.0382, -0.0376, -0.0385],\n",
      "        [-0.0934,  0.0916,  0.0981,  0.0907,  0.0920,  0.0935, -0.0937, -0.0929],\n",
      "        [-0.1340,  0.1291,  0.1383,  0.1275,  0.1289,  0.1311, -0.1326, -0.1310],\n",
      "        [ 0.0383, -0.0409, -0.0379, -0.0396, -0.0407, -0.0341,  0.0385,  0.0389]],\n",
      "       device='cuda:0'), 'lin1.lora_A': tensor([[-0.0495, -0.0019, -0.0487,  ...,  0.0673, -0.0083, -0.0031],\n",
      "        [-0.0026, -0.0674,  0.0030,  ...,  0.0595,  0.0713,  0.0186],\n",
      "        [ 0.0336, -0.0178,  0.0780,  ..., -0.0683,  0.0116, -0.0554],\n",
      "        ...,\n",
      "        [ 0.0555,  0.0502,  0.0081,  ...,  0.0025, -0.0830,  0.0547],\n",
      "        [ 0.0376,  0.0099, -0.0372,  ...,  0.0046, -0.0465,  0.0300],\n",
      "        [ 0.0374, -0.0245, -0.0375,  ..., -0.0056, -0.0202,  0.0327]],\n",
      "       device='cuda:0'), 'lin1.lora_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'lin2.lora_A': tensor([[ 0.0744, -0.0347,  0.0480,  ...,  0.0346,  0.0867,  0.0076],\n",
      "        [-0.0720,  0.0168,  0.0726,  ..., -0.0395, -0.0014, -0.0797],\n",
      "        [ 0.0761, -0.0679,  0.0052,  ..., -0.0279, -0.0575, -0.0524],\n",
      "        ...,\n",
      "        [-0.0412, -0.0814, -0.0854,  ...,  0.0678, -0.0712, -0.0264],\n",
      "        [ 0.0103, -0.0561,  0.0745,  ...,  0.0503,  0.0026, -0.0788],\n",
      "        [ 0.0045,  0.0641,  0.0526,  ..., -0.0002,  0.0446, -0.0373]],\n",
      "       device='cuda:0'), 'lin2.lora_B': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0'), 'lin3.lora_A': tensor([[-0.0052, -0.0422, -0.0822,  ..., -0.0839,  0.0675,  0.0799],\n",
      "        [-0.0478, -0.0519, -0.0182,  ...,  0.0731, -0.0281, -0.0853],\n",
      "        [-0.0547,  0.0436, -0.0275,  ...,  0.0050, -0.0131,  0.0014],\n",
      "        ...,\n",
      "        [-0.0338, -0.0278, -0.0494,  ...,  0.0624, -0.0598,  0.0670],\n",
      "        [-0.0071, -0.0837,  0.0426,  ...,  0.0808, -0.0610, -0.0650],\n",
      "        [-0.0181, -0.0533, -0.0482,  ..., -0.0700, -0.0248,  0.0867]],\n",
      "       device='cuda:0'), 'lin3.lora_B': tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "lora_path = \"checkpoints/smartlab_lora_weights_x3_45_20250416.pth\"\n",
    "\n",
    "model.load_state_dict(torch.load(lora_path), strict=False)\n",
    "\n",
    "#print(torch.load(lora_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters:\n",
      "['sa1_module.conv.local_nn.lins.0.weight',\n",
      " 'sa1_module.conv.local_nn.lins.0.bias',\n",
      " 'sa1_module.conv.local_nn.lins.1.weight',\n",
      " 'sa1_module.conv.local_nn.lins.1.bias',\n",
      " 'sa1_module.conv.local_nn.lins.2.weight',\n",
      " 'sa1_module.conv.local_nn.lins.2.bias',\n",
      " 'sa1_module.conv.local_nn.norms.0.module.weight',\n",
      " 'sa1_module.conv.local_nn.norms.0.module.bias',\n",
      " 'sa1_module.conv.local_nn.norms.1.module.weight',\n",
      " 'sa1_module.conv.local_nn.norms.1.module.bias',\n",
      " 'sa2_module.conv.local_nn.lins.0.weight',\n",
      " 'sa2_module.conv.local_nn.lins.0.bias',\n",
      " 'sa2_module.conv.local_nn.lins.1.weight',\n",
      " 'sa2_module.conv.local_nn.lins.1.bias',\n",
      " 'sa2_module.conv.local_nn.lins.2.weight',\n",
      " 'sa2_module.conv.local_nn.lins.2.bias',\n",
      " 'sa2_module.conv.local_nn.norms.0.module.weight',\n",
      " 'sa2_module.conv.local_nn.norms.0.module.bias',\n",
      " 'sa2_module.conv.local_nn.norms.1.module.weight',\n",
      " 'sa2_module.conv.local_nn.norms.1.module.bias',\n",
      " 'sa3_module.nn.lins.0.weight',\n",
      " 'sa3_module.nn.lins.0.bias',\n",
      " 'sa3_module.nn.lins.1.weight',\n",
      " 'sa3_module.nn.lins.1.bias',\n",
      " 'sa3_module.nn.lins.2.weight',\n",
      " 'sa3_module.nn.lins.2.bias',\n",
      " 'sa3_module.nn.norms.0.module.weight',\n",
      " 'sa3_module.nn.norms.0.module.bias',\n",
      " 'sa3_module.nn.norms.1.module.weight',\n",
      " 'sa3_module.nn.norms.1.module.bias',\n",
      " 'fp3_module.nn.lins.0.weight',\n",
      " 'fp3_module.nn.lins.0.bias',\n",
      " 'fp3_module.nn.lins.1.weight',\n",
      " 'fp3_module.nn.lins.1.bias',\n",
      " 'fp3_module.nn.norms.0.module.weight',\n",
      " 'fp3_module.nn.norms.0.module.bias',\n",
      " 'fp2_module.nn.lins.0.weight',\n",
      " 'fp2_module.nn.lins.0.bias',\n",
      " 'fp2_module.nn.lins.1.weight',\n",
      " 'fp2_module.nn.lins.1.bias',\n",
      " 'fp2_module.nn.norms.0.module.weight',\n",
      " 'fp2_module.nn.norms.0.module.bias',\n",
      " 'fp1_module.nn.lins.0.weight',\n",
      " 'fp1_module.nn.lins.0.bias',\n",
      " 'fp1_module.nn.lins.1.weight',\n",
      " 'fp1_module.nn.lins.1.bias',\n",
      " 'fp1_module.nn.lins.2.weight',\n",
      " 'fp1_module.nn.lins.2.bias',\n",
      " 'fp1_module.nn.norms.0.module.weight',\n",
      " 'fp1_module.nn.norms.0.module.bias',\n",
      " 'fp1_module.nn.norms.1.module.weight',\n",
      " 'fp1_module.nn.norms.1.module.bias',\n",
      " 'mlp.lins.0.weight',\n",
      " 'mlp.lins.0.bias',\n",
      " 'mlp.lins.1.weight',\n",
      " 'mlp.lins.1.bias',\n",
      " 'mlp.lins.2.weight',\n",
      " 'mlp.lins.2.bias',\n",
      " 'lin1.bias',\n",
      " 'lin1.lora_A',\n",
      " 'lin1.lora_B',\n",
      " 'lin2.bias',\n",
      " 'lin2.lora_A',\n",
      " 'lin2.lora_B',\n",
      " 'lin3.bias',\n",
      " 'lin3.lora_A',\n",
      " 'lin3.lora_B']\n"
     ]
    }
   ],
   "source": [
    "# Verify trainable parameters\n",
    "trainable_params = [n for n, p in model.named_parameters() if p.requires_grad]\n",
    "\n",
    "print(\"Trainable parameters:\")\n",
    "from pprint import pprint\n",
    "pprint(trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pcd files\n",
    "#pcd_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/Smartlab-2024-04-05_10-58-26_colour_cleaned.pcd\"\n",
    "pcd_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/SmartLab_2024_E57_Single_5mm.pcd\"\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the point cloud to its min(x,y,z) corner\n",
    " \n",
    "def move_to_corner(points):    \n",
    "    # Find the minimum x, y, z\n",
    "    min_xyz = points.min(axis=0)\n",
    "    # Translate the point cloud so that the min corner becomes the origin\n",
    "    moved_points = points - min_xyz\n",
    "    \n",
    "    return moved_points\n",
    "\n",
    "moved_points = move_to_corner(np.array(pcd.points))\n",
    "pcd.points = o3d.utility.Vector3dVector(moved_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866900\n"
     ]
    }
   ],
   "source": [
    "# Downsample the point cloud with a voxel of 0.03\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=0.03)\n",
    "\n",
    "print(len(downpcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_points_corner(points):\n",
    "    # Step 1: Shift points so that the minimum x, y, z becomes the origin.\n",
    "    min_vals = np.min(points, axis=0)\n",
    "    shifted_points = points - min_vals  # Now the lower bound is (0,0,0)\n",
    "    \n",
    "    # Step 2: Compute the scaling factors from the shifted points.\n",
    "    # The maximum after shifting represents the range in each dimension.\n",
    "    max_vals = np.max(shifted_points, axis=0)\n",
    "    scale = max_vals.copy()\n",
    "    \n",
    "    # Avoid division by zero if any dimension is flat.\n",
    "    scale[scale == 0] = 1\n",
    "    \n",
    "    # Normalize the shifted points to the [0, 1] interval.\n",
    "    normalized_points = shifted_points / scale\n",
    "\n",
    "    return normalized_points\n",
    "\n",
    "normalized = normalize_points_corner(np.array(downpcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates and colors from the point cloud\n",
    "down_points = torch.tensor(np.array(downpcd.points), dtype=torch.float32)  \n",
    "down_colors = torch.tensor(np.array(downpcd.colors), dtype=torch.float32)\n",
    "down_normalized = torch.tensor(normalized, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data object with x (3 features) and pos (coordinates)\n",
    "data = Data(x=down_normalized, pos=down_points)\n",
    "\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have only one point cloud\n",
    "dataset = [data]  # List of Data objects\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 32\n",
    "\n",
    "# Create a DataLoader (batch_size can be adjusted as needed)\n",
    "custom_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=num_workers) #, pin_memory=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts:\n",
      "tensor([[     0, 120882],\n",
      "        [     1, 127060],\n",
      "        [     2, 142705],\n",
      "        [     3,  64112],\n",
      "        [     4, 154410],\n",
      "        [     5,      2],\n",
      "        [     6,  82433],\n",
      "        [     7,   6415],\n",
      "        [     8,   5754],\n",
      "        [    10,   4143],\n",
      "        [    12, 158984]])\n",
      "Total inference time: 245.6908 seconds\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     torch_cluster::fps         0.01%      15.207ms         0.01%      21.326ms      10.663ms      242.480s        98.70%      242.487s      121.244s             2  \n",
      "                                     torch_cluster::knn         0.00%       7.656ms         0.65%        1.596s     531.944ms        1.592s         0.65%        1.596s     532.035ms             3  \n",
      "                                  torch_cluster::radius         0.01%      13.170ms         0.32%     789.457ms     394.729ms     771.078ms         0.31%     796.518ms     398.259ms             2  \n",
      "                                           aten::linear         0.00%       1.854ms         0.13%     327.674ms       8.623ms       1.215ms         0.00%     527.718ms      13.887ms            38  \n",
      "                                  aten::scatter_reduce_         0.00%     708.200us         0.00%       1.072ms     357.300us     242.255ms         0.10%     256.320ms      85.440ms             3  \n",
      "                                            aten::addmm         0.07%     159.980ms         0.07%     160.469ms       8.446ms     255.321ms         0.10%     255.570ms      13.451ms            19  \n",
      "                                     aten::index_select         0.02%      48.001ms         0.02%      49.137ms       8.190ms      44.988ms         0.02%      52.595ms       8.766ms             6  \n",
      "                                       aten::batch_norm         0.00%     375.000us         0.01%      36.380ms       3.638ms      59.000us         0.00%      51.795ms       5.179ms            10  \n",
      "                           aten::_batch_norm_impl_index         0.00%     767.400us         0.01%      36.005ms       3.601ms      99.000us         0.00%      51.736ms       5.174ms            10  \n",
      "                                aten::native_batch_norm         0.01%      32.872ms         0.01%      35.204ms       3.520ms      30.181ms         0.01%      51.608ms       5.161ms            10  \n",
      "                                              aten::cat         0.00%       3.320ms         0.00%       3.651ms     192.147us      39.562ms         0.02%      39.928ms       2.101ms            19  \n",
      "                                             aten::relu         0.00%     555.400us         0.00%      12.260ms       1.022ms      82.000us         0.00%      34.410ms       2.868ms            12  \n",
      "                                        aten::clamp_min         0.00%      11.704ms         0.00%      11.704ms     975.375us      34.328ms         0.01%      34.328ms       2.861ms            12  \n",
      "                                         aten::_unique2         0.01%      21.743ms         0.01%      21.855ms      21.855ms      21.566ms         0.01%      21.721ms      21.721ms             1  \n",
      "                                    aten::empty_strided         0.00%       2.165ms         0.00%       2.165ms      31.838us      21.325ms         0.01%      21.325ms     313.603us            68  \n",
      "                                       aten::empty_like         0.00%     186.400us         0.00%       2.109ms     175.775us     439.000us         0.00%      21.277ms       1.773ms            12  \n",
      "                                               aten::to         0.00%     724.300us         0.11%     264.016ms       3.568ms     826.000us         0.00%      16.935ms     228.851us            74  \n",
      "                                         aten::_to_copy         0.00%       1.712ms         0.11%     263.291ms       4.702ms       1.290ms         0.00%      16.109ms     287.661us            56  \n",
      "                                              aten::sum         0.01%      15.832ms         0.01%      15.832ms       5.277ms      15.621ms         0.01%      15.621ms       5.207ms             3  \n",
      "                                          aten::resize_         0.00%       2.314ms         0.00%       2.314ms      57.838us      15.397ms         0.01%      15.397ms     384.925us            40  \n",
      "                                    aten::masked_select         0.00%       1.384ms         0.96%        2.358s     235.843ms       2.932ms         0.00%      14.764ms       1.476ms            10  \n",
      "                                            aten::copy_         0.11%     261.565ms         0.11%     261.565ms       3.963ms      14.438ms         0.01%      14.438ms     218.758us            66  \n",
      "                                     aten::scatter_add_         0.00%       4.665ms         0.00%       4.678ms     584.700us      14.184ms         0.01%      14.263ms       1.783ms             8  \n",
      "                                         aten::scatter_         0.00%     348.300us         0.00%     353.200us     117.733us      14.035ms         0.01%      14.047ms       4.682ms             3  \n",
      "                                            aten::index         0.00%       4.104ms         0.00%       4.454ms     212.114us       9.223ms         0.00%       9.635ms     458.810us            21  \n",
      "                                            aten::stack         0.00%     395.900us         0.00%       1.655ms     206.850us     227.000us         0.00%       9.499ms       1.187ms             8  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         0.00%       1.911ms         0.00%       9.853ms       4.926ms     906.000us         0.00%       9.166ms       4.583ms             2  \n",
      "                                              aten::mul         0.00%     899.100us         0.00%     899.100us      69.162us       8.460ms         0.00%       8.460ms     650.769us            13  \n",
      "                                           aten::arange         0.00%       3.890ms         0.00%       7.444ms     338.368us       3.804ms         0.00%       7.483ms     340.136us            22  \n",
      "                                             aten::full         0.00%     376.400us         0.00%       1.482ms     148.210us     211.000us         0.00%       7.358ms     735.800us            10  \n",
      "                                          aten::nonzero         0.96%        2.355s         0.96%        2.356s     235.591ms       3.225ms         0.00%       6.955ms     695.500us            10  \n",
      "                                           aten::argmax         0.00%       6.093ms         0.00%       6.098ms       6.098ms       6.422ms         0.00%       6.425ms       6.425ms             1  \n",
      "                                            aten::empty         0.00%       1.757ms         0.00%       1.757ms      12.551us       5.842ms         0.00%       5.842ms      41.729us           140  \n",
      "                                            aten::fill_         0.00%     777.500us         0.00%     777.500us      25.081us       5.747ms         0.00%       5.747ms     185.387us            31  \n",
      "                                              aten::sub         0.00%       1.100ms         0.00%       1.100ms     157.129us       4.726ms         0.00%       4.726ms     675.143us             7  \n",
      "                                        aten::new_zeros         0.00%     480.600us         0.00%       1.291ms      92.193us     503.000us         0.00%       4.228ms     302.000us            14  \n",
      "                                              aten::div         0.00%     312.700us         0.00%     312.700us     104.233us       4.136ms         0.00%       4.136ms       1.379ms             3  \n",
      "                                            aten::zero_         0.00%     317.200us         0.00%     687.100us      29.874us     361.000us         0.00%       3.476ms     151.130us            23  \n",
      "                                             aten::rand         0.00%     180.600us         0.00%       3.323ms       1.661ms     163.000us         0.00%       3.374ms       1.687ms             2  \n",
      "                                         aten::uniform_         0.00%       3.134ms         0.00%       3.134ms       1.567ms       3.194ms         0.00%       3.194ms       1.597ms             2  \n",
      "                                             aten::item         0.00%     775.600us        98.76%      242.639s        6.222s     621.000us         0.00%       2.658ms      68.154us            39  \n",
      "                              aten::_local_scalar_dense        98.76%      242.638s        98.76%      242.638s        6.221s       2.037ms         0.00%       2.037ms      52.231us            39  \n",
      "                                           aten::select         0.00%       1.043ms         0.00%       1.088ms      17.833us       1.102ms         0.00%       1.637ms      26.836us            61  \n",
      "                                              aten::max         0.00%       2.137ms         0.00%       2.291ms     176.254us       1.283ms         0.00%       1.566ms     120.462us            13  \n",
      "                                       aten::as_strided         0.00%     262.800us         0.00%     262.800us       1.314us       1.443ms         0.00%       1.443ms       7.215us           200  \n",
      "                                           aten::narrow         0.00%     603.400us         0.00%       1.223ms      48.904us     353.000us         0.00%       1.142ms      45.680us            25  \n",
      "                                            aten::slice         0.00%     652.600us         0.00%     694.100us      23.934us     634.000us         0.00%     875.000us      30.172us            29  \n",
      "                                           aten::unbind         0.00%     311.700us         0.00%     727.700us     242.567us     162.000us         0.00%     790.000us     263.333us             3  \n",
      "                                                aten::t         0.00%     527.600us         0.00%       1.058ms      36.476us     239.000us         0.00%     770.000us      26.552us            29  \n",
      "                                        aten::new_empty         0.00%     316.100us         0.00%     416.300us      21.911us     567.000us         0.00%     746.000us      39.263us            19  \n",
      "                                           aten::cumsum         0.00%     613.500us         0.00%     654.500us      72.722us     471.000us         0.00%     645.000us      71.667us             9  \n",
      "                                      aten::log_softmax         0.00%     313.700us         0.02%      37.572ms      37.572ms      36.000us         0.00%     568.000us     568.000us             1  \n",
      "                                     aten::_log_softmax         0.02%      37.259ms         0.02%      37.259ms      37.259ms     532.000us         0.00%     532.000us     532.000us             1  \n",
      "                                        aten::transpose         0.00%     475.600us         0.00%     530.200us      18.283us     319.000us         0.00%     531.000us      18.310us            29  \n",
      "                                          aten::reshape         0.00%     527.700us         0.00%     604.100us      18.878us     361.000us         0.00%     530.000us      16.562us            32  \n",
      "                                               aten::ne         0.00%     352.700us         0.00%     352.700us      70.540us     448.000us         0.00%     448.000us      89.600us             5  \n",
      "                                            aten::clamp         0.00%     369.300us         0.00%     372.500us     124.167us     368.000us         0.00%     379.000us     126.333us             3  \n",
      "                                        aten::expand_as         0.00%       5.428ms         0.00%       5.630ms     625.578us      61.000us         0.00%     345.000us      38.333us             9  \n",
      "                                        aten::ones_like         0.00%      65.700us         0.00%     154.600us      77.300us      76.000us         0.00%     297.000us     148.500us             2  \n",
      "                                           aten::expand         0.00%     188.400us         0.00%     202.300us      22.478us     254.000us         0.00%     284.000us      31.556us             9  \n",
      "                                             aten::view         0.00%     191.500us         0.00%     191.500us       3.830us     271.000us         0.00%     271.000us       5.420us            50  \n",
      "                                          aten::detach_         0.00%     124.600us         0.00%     160.500us      22.929us     141.000us         0.00%     265.000us      37.857us             7  \n",
      "                                       aten::reciprocal         0.00%     248.400us         0.00%     248.400us      82.800us     224.000us         0.00%     224.000us      74.667us             3  \n",
      "                                       aten::lift_fresh         0.00%       3.900us         0.00%       3.900us       0.557us     222.000us         0.00%     222.000us      31.714us             7  \n",
      "                                            aten::zeros         0.00%      62.700us         0.00%     188.700us      94.350us      27.000us         0.00%     179.000us      89.500us             2  \n",
      "                                                detach_         0.00%      35.900us         0.00%      35.900us       5.129us     124.000us         0.00%     124.000us      17.714us             7  \n",
      "                                          aten::dropout         0.00%      21.800us         0.00%      21.800us       1.147us      77.000us         0.00%      77.000us       4.053us            19  \n",
      "                                        aten::unsqueeze         0.00%      33.600us         0.00%      37.900us      18.950us      53.000us         0.00%      67.000us      33.500us             2  \n",
      "                                             aten::ceil         0.00%      43.900us         0.00%      43.900us      21.950us      59.000us         0.00%      59.000us      29.500us             2  \n",
      "                                             aten::set_         0.00%     194.900us         0.00%     194.900us      19.490us      49.000us         0.00%      49.000us       4.900us            10  \n",
      "                                     aten::resolve_conj         0.00%       2.400us         0.00%       2.400us       0.218us      39.000us         0.00%      39.000us       3.545us            11  \n",
      "                                      aten::resolve_neg         0.00%       1.700us         0.00%       1.700us       0.155us      31.000us         0.00%      31.000us       2.818us            11  \n",
      "                                          aten::random_         0.00%      25.900us         0.00%      25.900us      25.900us       5.000us         0.00%       5.000us       5.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 245.681s\n",
      "Self CUDA time total: 245.683s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "import torch.profiler\n",
    "\n",
    "with torch.profiler.profile(\n",
    "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    ") as prof:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        for data in custom_loader:\n",
    "            data = data.to(device)\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                predictions = model(data)\n",
    "            labels = predictions.argmax(dim=-1)\n",
    "            # Process the labels as needed\n",
    "            #labels_arr = labels.cpu().numpy()\n",
    "            # Count occurrences of labels\n",
    "            unique_labels, label_counts = torch.unique(labels, return_counts=True)\n",
    "            # Combine and print\n",
    "            #result_labels = np.array(list(zip(unique_labels, label_counts)))\n",
    "            #print(\"Label counts:\")\n",
    "            #for label, count in zip(unique_labels, label_counts):\n",
    "            #    print(f\"Label {label.item()}: {count.item()}\")\n",
    "            result_labels = torch.stack((unique_labels, label_counts), dim=1).cpu()\n",
    "            print(\"Label counts:\")\n",
    "            print(result_labels)\n",
    "        end_time = time.time()\n",
    "        print(f\"Total inference time: {end_time - start_time:.4f} seconds\")  \n",
    "    \n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `labels` is the tensor containing predicted labels for each point\n",
    "predicted_colors = color_map[labels.cpu().numpy()]  # Shape: [num_points, 3]\n",
    "\n",
    "# Assuming `pcd` is your Open3D point cloud object\n",
    "downpcd.colors = o3d.utility.Vector3dVector(predicted_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the point cloud with colored labels\n",
    "o3d.visualization.draw_geometries([downpcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the point cloud to a file\n",
    "save_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/labelled/Smartlab_aalto_pcd_lora_label_pointnet2_x3_0.03_20250418.ply\"\n",
    "o3d.io.write_point_cloud(save_path, downpcd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

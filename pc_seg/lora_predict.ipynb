{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pyg_pointnet2 import PyGPointNet2NoColor\n",
    "import loralib as lora\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MLP\n",
    "from torch_geometric.loader import DataLoader\n",
    "import time\n",
    "from pc_label_map import color_map\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lora(module, r=8, alpha=16, verbose=False):\n",
    "    \"\"\"\n",
    "    Recursively replaces Linear layers with LoRA-enabled layers.\n",
    "    Handles custom modules like MLP, SAModule, and FPModule.\n",
    "    \"\"\"\n",
    "    # Special handling for MLP modules which likely contain multiple linear layers\n",
    "    if hasattr(module, '__class__') and module.__class__.__name__ == 'MLP':\n",
    "        if verbose:\n",
    "            print(f\"Processing MLP module: {module}\")\n",
    "        # Handle linear layers inside the MLP\n",
    "        if hasattr(module, 'lins'):\n",
    "            for i, lin in enumerate(module.lins):\n",
    "                # Check if the layer has the necessary attributes of a Linear layer\n",
    "                if hasattr(lin, 'in_channels') and hasattr(lin, 'out_channels') and hasattr(lin, 'weight'):\n",
    "                    lora_layer = lora.Linear(\n",
    "                        in_features=lin.in_channels,\n",
    "                        out_features=lin.out_channels,\n",
    "                        r=r,\n",
    "                        lora_alpha=alpha\n",
    "                    )\n",
    "                    lora_layer.weight.data = lin.weight.data.clone()\n",
    "                    if hasattr(lin, 'bias') and lin.bias is not None:\n",
    "                        lora_layer.bias.data = lin.bias.data.clone()\n",
    "                    module.lins[i] = lora_layer\n",
    "                    if verbose:\n",
    "                        print(f\"Replaced MLP.lins[{i}] with LoRA ({lin.__class__.__name__})\")\n",
    "\n",
    "    # Process all named children modules\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Linear):\n",
    "            # Replace this Linear layer with LoRA\n",
    "            lora_layer = lora.Linear(\n",
    "                in_features=child.in_features,\n",
    "                out_features=child.out_features,\n",
    "                r=r,\n",
    "                lora_alpha=alpha\n",
    "            )\n",
    "            \n",
    "            # Copy original weights and biases\n",
    "            lora_layer.weight.data = child.weight.data.clone()\n",
    "            if child.bias is not None:\n",
    "                lora_layer.bias.data = child.bias.data.clone()\n",
    "            \n",
    "            # Replace the layer\n",
    "            setattr(module, name, lora_layer)\n",
    "            if verbose:\n",
    "                print(f\"Replaced {name} with LoRA\")\n",
    "        elif isinstance(child, nn.Sequential):\n",
    "            # Special handling for Sequential containers\n",
    "            for idx, layer in enumerate(child):\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    lora_layer = lora.Linear(\n",
    "                        in_features=layer.in_features,\n",
    "                        out_features=layer.out_features,\n",
    "                        r=r,\n",
    "                        lora_alpha=alpha\n",
    "                    )\n",
    "                    lora_layer.weight.data = layer.weight.data.clone()\n",
    "                    if layer.bias is not None:\n",
    "                        lora_layer.bias.data = layer.bias.data.clone()\n",
    "                    child[idx] = lora_layer\n",
    "                    if verbose:\n",
    "                        print(f\"Replaced {name}[{idx}] with LoRA\")\n",
    "                else:\n",
    "                    # Recursively apply to layers within Sequential that aren't Linear\n",
    "                    apply_lora(layer, r, alpha, verbose)\n",
    "        else:\n",
    "            # Recursively apply to all other nested submodules\n",
    "            apply_lora(child, r, alpha, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_path = \"checkpoints/pointnet2_s3dis_transform_seg_x3_45_checkpoint.pth\"\n",
    "\n",
    "# Initialize model\n",
    "\n",
    "model = PyGPointNet2NoColor(num_classes=13).to(device)\n",
    "\n",
    "checkpoint = torch.load(pretrained_path, map_location=device)\n",
    "# Extract the model state dictionary\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "model.load_state_dict(model_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MLP module: MLP(6, 64, 64, 128)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced MLP.lins[2] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Replaced 2 with LoRA\n",
      "Processing MLP module: MLP(131, 128, 128, 256)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced MLP.lins[2] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Replaced 2 with LoRA\n",
      "Processing MLP module: MLP(259, 256, 512, 1024)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced MLP.lins[2] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Replaced 2 with LoRA\n",
      "Processing MLP module: MLP(1280, 256, 256)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Processing MLP module: MLP(384, 256, 128)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Processing MLP module: MLP(131, 128, 128, 128)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced MLP.lins[2] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Replaced 2 with LoRA\n",
      "Processing MLP module: MLP(128, 128, 128, 13)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced MLP.lins[2] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Replaced 2 with LoRA\n",
      "Replaced lin1 with LoRA\n",
      "Replaced lin2 with LoRA\n",
      "Replaced lin3 with LoRA\n"
     ]
    }
   ],
   "source": [
    "apply_lora(model, r=8, alpha=16, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyGPointNet2NoColor(\n",
       "  (sa1_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=MLP(6, 64, 64, 128), global_nn=None)\n",
       "  )\n",
       "  (sa2_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=MLP(131, 128, 128, 256), global_nn=None)\n",
       "  )\n",
       "  (sa3_module): GlobalSAModule(\n",
       "    (nn): MLP(259, 256, 512, 1024)\n",
       "  )\n",
       "  (fp3_module): FPModule(\n",
       "    (nn): MLP(1280, 256, 256)\n",
       "  )\n",
       "  (fp2_module): FPModule(\n",
       "    (nn): MLP(384, 256, 128)\n",
       "  )\n",
       "  (fp1_module): FPModule(\n",
       "    (nn): MLP(131, 128, 128, 128)\n",
       "  )\n",
       "  (mlp): MLP(128, 128, 128, 13)\n",
       "  (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin3): Linear(in_features=128, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lora_path = \"checkpoints/smartlab_lora_weights_x3_100_20250424.pth\"\n",
    "lora_path = \"checkpoints/smartlab_lora_weights_x3_50_20250831.pth\"\n",
    "model.load_state_dict(torch.load(lora_path), strict=False)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all parameters except LoRA\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"lora_\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable LoRA parameters: 44\n",
      "['sa1_module.conv.local_nn.lins.0.lora_A',\n",
      " 'sa1_module.conv.local_nn.lins.0.lora_B',\n",
      " 'sa1_module.conv.local_nn.lins.1.lora_A',\n",
      " 'sa1_module.conv.local_nn.lins.1.lora_B',\n",
      " 'sa1_module.conv.local_nn.lins.2.lora_A',\n",
      " 'sa1_module.conv.local_nn.lins.2.lora_B',\n",
      " 'sa2_module.conv.local_nn.lins.0.lora_A',\n",
      " 'sa2_module.conv.local_nn.lins.0.lora_B',\n",
      " 'sa2_module.conv.local_nn.lins.1.lora_A',\n",
      " 'sa2_module.conv.local_nn.lins.1.lora_B',\n",
      " 'sa2_module.conv.local_nn.lins.2.lora_A',\n",
      " 'sa2_module.conv.local_nn.lins.2.lora_B',\n",
      " 'sa3_module.nn.lins.0.lora_A',\n",
      " 'sa3_module.nn.lins.0.lora_B',\n",
      " 'sa3_module.nn.lins.1.lora_A',\n",
      " 'sa3_module.nn.lins.1.lora_B',\n",
      " 'sa3_module.nn.lins.2.lora_A',\n",
      " 'sa3_module.nn.lins.2.lora_B',\n",
      " 'fp3_module.nn.lins.0.lora_A',\n",
      " 'fp3_module.nn.lins.0.lora_B',\n",
      " 'fp3_module.nn.lins.1.lora_A',\n",
      " 'fp3_module.nn.lins.1.lora_B',\n",
      " 'fp2_module.nn.lins.0.lora_A',\n",
      " 'fp2_module.nn.lins.0.lora_B',\n",
      " 'fp2_module.nn.lins.1.lora_A',\n",
      " 'fp2_module.nn.lins.1.lora_B',\n",
      " 'fp1_module.nn.lins.0.lora_A',\n",
      " 'fp1_module.nn.lins.0.lora_B',\n",
      " 'fp1_module.nn.lins.1.lora_A',\n",
      " 'fp1_module.nn.lins.1.lora_B',\n",
      " 'fp1_module.nn.lins.2.lora_A',\n",
      " 'fp1_module.nn.lins.2.lora_B',\n",
      " 'mlp.lins.0.lora_A',\n",
      " 'mlp.lins.0.lora_B',\n",
      " 'mlp.lins.1.lora_A',\n",
      " 'mlp.lins.1.lora_B',\n",
      " 'mlp.lins.2.lora_A',\n",
      " 'mlp.lins.2.lora_B',\n",
      " 'lin1.lora_A',\n",
      " 'lin1.lora_B',\n",
      " 'lin2.lora_A',\n",
      " 'lin2.lora_B',\n",
      " 'lin3.lora_A',\n",
      " 'lin3.lora_B']\n"
     ]
    }
   ],
   "source": [
    "# Verify\n",
    "trainable_params = [n for n, p in model.named_parameters() if p.requires_grad]\n",
    "from pprint import pprint\n",
    "print(f\"Trainable LoRA parameters: {len(trainable_params)}\")\n",
    "pprint(trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pcd files\n",
    "#pcd_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/Smartlab-2024-04-05_10-58-26_colour_cleaned.pcd\"\n",
    "pcd_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/SmartLab_2024_E57_Single_5mm.pcd\"\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the point cloud to its min(x,y,z) corner\n",
    " \n",
    "def move_to_corner(points):    \n",
    "    # Find the minimum x, y, z\n",
    "    min_xyz = points.min(axis=0)\n",
    "    # Translate the point cloud so that the min corner becomes the origin\n",
    "    moved_points = points - min_xyz\n",
    "    \n",
    "    return moved_points\n",
    "\n",
    "moved_points = move_to_corner(np.array(pcd.points))\n",
    "pcd.points = o3d.utility.Vector3dVector(moved_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866900\n"
     ]
    }
   ],
   "source": [
    "# Downsample the point cloud with a voxel of 0.03\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=0.03)\n",
    "\n",
    "print(len(downpcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_points_corner(points):\n",
    "    # Step 1: Shift points so that the minimum x, y, z becomes the origin.\n",
    "    min_vals = np.min(points, axis=0)\n",
    "    shifted_points = points - min_vals  # Now the lower bound is (0,0,0)\n",
    "    \n",
    "    # Step 2: Compute the scaling factors from the shifted points.\n",
    "    # The maximum after shifting represents the range in each dimension.\n",
    "    max_vals = np.max(shifted_points, axis=0)\n",
    "    scale = max_vals.copy()\n",
    "    \n",
    "    # Avoid division by zero if any dimension is flat.\n",
    "    scale[scale == 0] = 1\n",
    "    \n",
    "    # Normalize the shifted points to the [0, 1] interval.\n",
    "    normalized_points = shifted_points / scale\n",
    "\n",
    "    return normalized_points\n",
    "\n",
    "normalized = normalize_points_corner(np.array(downpcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates and colors from the point cloud\n",
    "down_points = torch.tensor(np.array(downpcd.points), dtype=torch.float32)  \n",
    "down_colors = torch.tensor(np.array(downpcd.colors), dtype=torch.float32)\n",
    "down_normalized = torch.tensor(normalized, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data object with x (3 features) and pos (coordinates)\n",
    "\n",
    "data = Data(x=down_normalized, pos=down_points)\n",
    "\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have only one point cloud\n",
    "dataset = [data]  # List of Data objects\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 32\n",
    "\n",
    "# Create a DataLoader (batch_size can be adjusted as needed)\n",
    "custom_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=num_workers) #, pin_memory=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts:\n",
      "tensor([[     0, 110877],\n",
      "        [     1, 122822],\n",
      "        [     2,  74731],\n",
      "        [     3,   3582],\n",
      "        [     4, 197720],\n",
      "        [     6,   6906],\n",
      "        [     7,   9116],\n",
      "        [     8,   2037],\n",
      "        [     9,      1],\n",
      "        [    10, 264165],\n",
      "        [    12,  74943]])\n",
      "Total inference time: 245.9322 seconds\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     torch_cluster::fps         0.00%       1.252ms         0.00%       5.337ms       2.668ms      242.803s        98.73%      242.806s      121.403s             2  \n",
      "                                     torch_cluster::knn         0.00%     973.800us         0.69%        1.699s     566.358ms        1.692s         0.69%        1.699s     566.495ms             3  \n",
      "                                  torch_cluster::radius         0.00%     308.200us         0.33%     819.027ms     409.513ms     813.531ms         0.33%     821.103ms     410.551ms             2  \n",
      "                                  aten::scatter_reduce_         0.00%     451.000us         0.00%     611.600us     203.867us     283.682ms         0.12%     339.264ms     113.088ms             3  \n",
      "                                           aten::linear         0.00%       1.576ms         0.00%      11.671ms     307.132us       1.447ms         0.00%     158.692ms       4.176ms            38  \n",
      "                                            aten::addmm         0.00%       2.504ms         0.00%       2.576ms     135.579us      70.215ms         0.03%      70.390ms       3.705ms            19  \n",
      "                                         aten::scatter_         0.00%     140.400us         0.00%     146.300us      48.767us      55.546ms         0.02%      55.564ms      18.521ms             3  \n",
      "                                       aten::batch_norm         0.00%     216.400us         0.00%       2.182ms     218.220us      61.000us         0.00%      34.486ms       3.449ms            10  \n",
      "                           aten::_batch_norm_impl_index         0.00%     472.200us         0.00%       1.966ms     196.580us      95.000us         0.00%      34.425ms       3.442ms            10  \n",
      "                                aten::native_batch_norm         0.00%     937.600us         0.00%       1.456ms     145.570us      33.405ms         0.01%      34.301ms       3.430ms            10  \n",
      "                                             aten::relu         0.00%     248.800us         0.00%     505.600us      42.133us      84.000us         0.00%      32.551ms       2.713ms            12  \n",
      "                                        aten::clamp_min         0.00%     256.800us         0.00%     256.800us      21.400us      32.467ms         0.01%      32.467ms       2.706ms            12  \n",
      "                                              aten::cat         0.00%       1.412ms         0.00%       2.492ms     131.147us      25.947ms         0.01%      26.783ms       1.410ms            19  \n",
      "                                               aten::to         0.00%     946.800us         0.12%     296.615ms       4.008ms       1.042ms         0.00%      16.746ms     226.297us            74  \n",
      "                                         aten::_to_copy         0.00%       2.173ms         0.12%     295.668ms       5.280ms       1.423ms         0.00%      15.704ms     280.429us            56  \n",
      "                                     aten::scatter_add_         0.00%     674.500us         0.00%     694.700us      86.837us      14.930ms         0.01%      15.039ms       1.880ms             8  \n",
      "                                            aten::copy_         0.12%     293.478ms         0.12%     293.478ms       4.447ms      13.806ms         0.01%      13.806ms     209.182us            66  \n",
      "                                              aten::mul         0.00%     492.300us         0.00%     492.300us      37.869us      11.080ms         0.00%      11.080ms     852.308us            13  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         0.00%       4.555ms         0.00%       9.741ms       4.870ms       2.664ms         0.00%       9.795ms       4.897ms             2  \n",
      "                                    aten::masked_select         0.00%       2.328ms         1.02%        2.514s     251.382ms       3.848ms         0.00%       9.795ms     979.500us            10  \n",
      "                                            aten::index         0.00%       2.006ms         0.00%       2.629ms     125.195us       8.120ms         0.00%       8.849ms     421.381us            21  \n",
      "                                     aten::index_select         0.00%     430.400us         0.00%     465.700us      77.617us       8.283ms         0.00%       8.386ms       1.398ms             6  \n",
      "                                              aten::div         0.00%      95.600us         0.00%      95.600us      31.867us       5.253ms         0.00%       5.253ms       1.751ms             3  \n",
      "                                          aten::nonzero         1.02%        2.510s         1.02%        2.511s     251.079ms       3.761ms         0.00%       4.727ms     472.700us            10  \n",
      "                                        aten::new_zeros         0.00%     605.100us         0.00%       1.682ms     120.150us     477.000us         0.00%       4.419ms     315.643us            14  \n",
      "                                            aten::fill_         0.00%       2.603ms         0.00%       2.603ms      83.958us       4.399ms         0.00%       4.399ms     141.903us            31  \n",
      "                                             aten::item         0.00%       1.454ms        98.84%      243.066s        6.232s       1.936ms         0.00%       3.858ms      98.923us            39  \n",
      "                                            aten::zero_         0.00%     445.700us         0.00%     903.100us      39.265us     436.000us         0.00%       3.577ms     155.522us            23  \n",
      "                                            aten::stack         0.00%     370.700us         0.00%     916.300us     114.538us     304.000us         0.00%       3.409ms     426.125us             8  \n",
      "                                           aten::select         0.00%       2.248ms         0.00%       2.540ms      41.646us       2.754ms         0.00%       3.263ms      53.492us            61  \n",
      "                                           aten::arange         0.00%       1.444ms         0.00%       2.318ms     105.373us       1.275ms         0.00%       2.552ms     116.000us            22  \n",
      "                                              aten::max         0.00%       1.716ms         0.00%       1.960ms     150.746us       1.537ms         0.00%       2.127ms     163.615us            13  \n",
      "                                           aten::unbind         0.00%       1.020ms         0.00%       2.074ms     691.433us     286.000us         0.00%       2.100ms     700.000us             3  \n",
      "                                           aten::narrow         0.00%     933.200us         0.00%       2.243ms      89.708us     485.000us         0.00%       2.088ms      83.520us            25  \n",
      "                                              aten::sub         0.00%     286.900us         0.00%     286.900us      40.986us       1.947ms         0.00%       1.947ms     278.143us             7  \n",
      "                                            aten::empty         0.00%     858.400us         0.00%     858.400us       6.131us       1.932ms         0.00%       1.932ms      13.800us           140  \n",
      "                              aten::_local_scalar_dense        98.84%      243.064s        98.84%      243.064s        6.232s       1.922ms         0.00%       1.922ms      49.282us            39  \n",
      "                                       aten::as_strided         0.00%     689.100us         0.00%     689.100us       3.446us       1.780ms         0.00%       1.780ms       8.900us           200  \n",
      "                                            aten::slice         0.00%       1.386ms         0.00%       1.462ms      50.403us       1.445ms         0.00%       1.758ms      60.621us            29  \n",
      "                                             aten::full         0.00%     594.600us         0.00%       2.709ms     270.930us     318.000us         0.00%       1.580ms     158.000us            10  \n",
      "                                        aten::new_empty         0.00%     456.700us         0.00%     636.900us      33.521us       1.156ms         0.00%       1.379ms      72.579us            19  \n",
      "                                           aten::cumsum         0.00%       1.022ms         0.00%       1.120ms     124.478us       1.029ms         0.00%       1.232ms     136.889us             9  \n",
      "                                                aten::t         0.00%     741.300us         0.00%       1.398ms      48.221us     322.000us         0.00%       1.153ms      39.759us            29  \n",
      "                                          aten::reshape         0.00%     722.000us         0.00%     880.500us      27.516us     524.000us         0.00%     992.000us      31.000us            32  \n",
      "                                        aten::transpose         0.00%     592.100us         0.00%     657.100us      22.659us     583.000us         0.00%     831.000us      28.655us            29  \n",
      "                                       aten::empty_like         0.00%     287.100us         0.00%     354.100us      29.508us     681.000us         0.00%     740.000us      61.667us            12  \n",
      "                                    aten::empty_strided         0.00%     329.200us         0.00%     329.200us       4.841us     678.000us         0.00%     678.000us       9.971us            68  \n",
      "                                          aten::resize_         0.00%     323.800us         0.00%     323.800us       8.095us     664.000us         0.00%     664.000us      16.600us            40  \n",
      "                                             aten::view         0.00%     276.800us         0.00%     276.800us       5.536us     611.000us         0.00%     611.000us      12.220us            50  \n",
      "                                     aten::resolve_conj         0.00%       5.000us         0.00%       5.000us       0.455us     562.000us         0.00%     562.000us      51.091us            11  \n",
      "                                         aten::_unique2         0.00%     340.200us         0.02%      53.397ms      53.397ms     387.000us         0.00%     533.000us     533.000us             1  \n",
      "                                               aten::ne         0.00%     205.900us         0.00%     205.900us      41.180us     521.000us         0.00%     521.000us     104.200us             5  \n",
      "                                        aten::ones_like         0.00%     213.300us         0.00%     447.600us     223.800us     179.000us         0.00%     480.000us     240.000us             2  \n",
      "                                          aten::detach_         0.00%     174.700us         0.00%     261.800us      37.400us     203.000us         0.00%     397.000us      56.714us             7  \n",
      "                                        aten::expand_as         0.00%     223.800us         0.00%     452.100us      50.233us     103.000us         0.00%     356.000us      39.556us             9  \n",
      "                                           aten::argmax         0.00%      58.300us         0.00%      59.700us      59.700us     259.000us         0.00%     262.000us     262.000us             1  \n",
      "                                           aten::expand         0.00%     208.400us         0.00%     228.300us      25.367us     213.000us         0.00%     253.000us      28.111us             9  \n",
      "                                            aten::clamp         0.00%     244.200us         0.00%     248.900us      82.967us     194.000us         0.00%     251.000us      83.667us             3  \n",
      "                                              aten::sum         0.00%     248.200us         0.00%     248.200us      82.733us     250.000us         0.00%     250.000us      83.333us             3  \n",
      "                                            aten::zeros         0.00%      87.700us         0.00%     175.100us      87.550us      80.000us         0.00%     210.000us     105.000us             2  \n",
      "                                             aten::rand         0.00%      76.100us         0.00%     147.400us      73.700us      64.000us         0.00%     207.000us     103.500us             2  \n",
      "                                                detach_         0.00%      87.100us         0.00%      87.100us      12.443us     194.000us         0.00%     194.000us      27.714us             7  \n",
      "                                      aten::log_softmax         0.00%      29.500us         0.00%      56.700us      56.700us       7.000us         0.00%     173.000us     173.000us             1  \n",
      "                                     aten::_log_softmax         0.00%      27.200us         0.00%      27.200us      27.200us     166.000us         0.00%     166.000us     166.000us             1  \n",
      "                                             aten::set_         0.00%     256.600us         0.00%     256.600us      25.660us     139.000us         0.00%     139.000us      13.900us            10  \n",
      "                                       aten::reciprocal         0.00%     165.500us         0.00%     165.500us      55.167us     135.000us         0.00%     135.000us      45.000us             3  \n",
      "                                         aten::uniform_         0.00%      62.800us         0.00%      62.800us      31.400us     125.000us         0.00%     125.000us      62.500us             2  \n",
      "                                      aten::resolve_neg         0.00%       4.200us         0.00%       4.200us       0.382us      89.000us         0.00%      89.000us       8.091us            11  \n",
      "                                       aten::lift_fresh         0.00%       5.900us         0.00%       5.900us       0.843us      67.000us         0.00%      67.000us       9.571us             7  \n",
      "                                          aten::dropout         0.00%      24.600us         0.00%      24.600us       1.295us      64.000us         0.00%      64.000us       3.368us            19  \n",
      "                                             aten::ceil         0.00%      61.600us         0.00%      61.600us      30.800us      49.000us         0.00%      49.000us      24.500us             2  \n",
      "                                        aten::unsqueeze         0.00%      25.900us         0.00%      29.900us      14.950us      26.000us         0.00%      38.000us      19.000us             2  \n",
      "                                          aten::random_         0.00%      27.400us         0.00%      27.400us      27.400us       3.000us         0.00%       3.000us       3.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 245.916s\n",
      "Self CUDA time total: 245.919s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "import torch.profiler\n",
    "\n",
    "with torch.profiler.profile(\n",
    "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    ") as prof:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        for data in custom_loader:\n",
    "            data = data.to(device)\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                predictions = model(data)\n",
    "            labels = predictions.argmax(dim=-1)\n",
    "            # Process the labels as needed\n",
    "            #labels_arr = labels.cpu().numpy()\n",
    "            # Count occurrences of labels\n",
    "            unique_labels, label_counts = torch.unique(labels, return_counts=True)\n",
    "            # Combine and print\n",
    "            #result_labels = np.array(list(zip(unique_labels, label_counts)))\n",
    "            #print(\"Label counts:\")\n",
    "            #for label, count in zip(unique_labels, label_counts):\n",
    "            #    print(f\"Label {label.item()}: {count.item()}\")\n",
    "            result_labels = torch.stack((unique_labels, label_counts), dim=1).cpu()\n",
    "            print(\"Label counts:\")\n",
    "            print(result_labels)\n",
    "        end_time = time.time()\n",
    "        print(f\"Total inference time: {end_time - start_time:.4f} seconds\")  \n",
    "    \n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `labels` is the tensor containing predicted labels for each point\n",
    "predicted_colors = color_map[labels.cpu().numpy()]  # Shape: [num_points, 3]\n",
    "\n",
    "# Assuming `pcd` is your Open3D point cloud object\n",
    "downpcd.colors = o3d.utility.Vector3dVector(predicted_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the point cloud with colored labels\n",
    "o3d.visualization.draw_geometries([downpcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the point cloud to a file\n",
    "save_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/labelled/Smartlab_pcd_lora_label_pointnet2_x3_0.03_20250831.ply\"\n",
    "o3d.io.write_point_cloud(save_path, downpcd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

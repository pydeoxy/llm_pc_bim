{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pyg_pointnet2 import PyGPointNet2NoColor, PyGPointNet2X3LoRa, PyGPointNet2NoColorLoRa\n",
    "import loralib as lora\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MLP\n",
    "from torch_geometric.loader import DataLoader\n",
    "import time\n",
    "from pc_label_map import color_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lora(module, r=8, alpha=16, verbose=False):\n",
    "    \"\"\"\n",
    "    Recursively replaces ALL Linear layers with LoRA-enabled layers.\n",
    "    \"\"\"\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Linear):\n",
    "            # Replace this Linear layer with LoRA\n",
    "            lora_layer = lora.Linear(\n",
    "                in_features=child.in_features,\n",
    "                out_features=child.out_features,\n",
    "                r=r,\n",
    "                lora_alpha=alpha\n",
    "            )\n",
    "            \n",
    "            # Copy original weights and biases\n",
    "            lora_layer.weight.data = child.weight.data.clone()\n",
    "            if child.bias is not None:\n",
    "                lora_layer.bias.data = child.bias.data.clone()\n",
    "            \n",
    "            # Replace the layer\n",
    "            setattr(module, name, lora_layer)\n",
    "            if verbose:\n",
    "                print(f\"Replaced {name} with LoRA\")\n",
    "        elif isinstance(child, nn.Sequential):\n",
    "            # Handle Sequential containers (e.g., MLP layers)\n",
    "            for idx, layer in enumerate(child):\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    # Replace Linear layers inside Sequential\n",
    "                    lora_layer = lora.Linear(\n",
    "                        in_features=layer.in_features,\n",
    "                        out_features=layer.out_features,\n",
    "                        r=r,\n",
    "                        lora_alpha=alpha\n",
    "                    )\n",
    "                    lora_layer.weight.data = layer.weight.data.clone()\n",
    "                    if layer.bias is not None:\n",
    "                        lora_layer.bias.data = layer.bias.data.clone()\n",
    "                    child[idx] = lora_layer\n",
    "                    if verbose:\n",
    "                        print(f\"Replaced {name}[{idx}] with LoRA\")\n",
    "        else:\n",
    "            # Recursively apply to nested submodules\n",
    "            apply_lora(child, r, alpha, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['sa1_module.conv.local_nn.0.weight', 'sa1_module.conv.local_nn.0.bias', 'sa1_module.conv.local_nn.0.lora_A', 'sa1_module.conv.local_nn.0.lora_B', 'sa1_module.conv.local_nn.2.weight', 'sa1_module.conv.local_nn.2.bias', 'sa1_module.conv.local_nn.2.lora_A', 'sa1_module.conv.local_nn.2.lora_B', 'sa1_module.conv.local_nn.4.weight', 'sa1_module.conv.local_nn.4.bias', 'sa1_module.conv.local_nn.4.lora_A', 'sa1_module.conv.local_nn.4.lora_B', 'sa2_module.conv.local_nn.0.weight', 'sa2_module.conv.local_nn.0.bias', 'sa2_module.conv.local_nn.0.lora_A', 'sa2_module.conv.local_nn.0.lora_B', 'sa2_module.conv.local_nn.2.weight', 'sa2_module.conv.local_nn.2.bias', 'sa2_module.conv.local_nn.2.lora_A', 'sa2_module.conv.local_nn.2.lora_B', 'sa2_module.conv.local_nn.4.weight', 'sa2_module.conv.local_nn.4.bias', 'sa2_module.conv.local_nn.4.lora_A', 'sa2_module.conv.local_nn.4.lora_B', 'sa3_module.nn.0.weight', 'sa3_module.nn.0.bias', 'sa3_module.nn.0.lora_A', 'sa3_module.nn.0.lora_B', 'sa3_module.nn.2.weight', 'sa3_module.nn.2.bias', 'sa3_module.nn.2.lora_A', 'sa3_module.nn.2.lora_B', 'sa3_module.nn.4.weight', 'sa3_module.nn.4.bias', 'sa3_module.nn.4.lora_A', 'sa3_module.nn.4.lora_B', 'fp3_module.nn.0.weight', 'fp3_module.nn.0.bias', 'fp3_module.nn.0.lora_A', 'fp3_module.nn.0.lora_B', 'fp3_module.nn.2.weight', 'fp3_module.nn.2.bias', 'fp3_module.nn.2.lora_A', 'fp3_module.nn.2.lora_B', 'fp2_module.nn.0.weight', 'fp2_module.nn.0.bias', 'fp2_module.nn.0.lora_A', 'fp2_module.nn.0.lora_B', 'fp2_module.nn.2.weight', 'fp2_module.nn.2.bias', 'fp2_module.nn.2.lora_A', 'fp2_module.nn.2.lora_B', 'fp1_module.nn.0.weight', 'fp1_module.nn.0.bias', 'fp1_module.nn.0.lora_A', 'fp1_module.nn.0.lora_B', 'fp1_module.nn.2.weight', 'fp1_module.nn.2.bias', 'fp1_module.nn.2.lora_A', 'fp1_module.nn.2.lora_B', 'fp1_module.nn.4.weight', 'fp1_module.nn.4.bias', 'fp1_module.nn.4.lora_A', 'fp1_module.nn.4.lora_B', 'mlp.0.weight', 'mlp.0.bias', 'mlp.0.lora_A', 'mlp.0.lora_B', 'mlp.3.weight', 'mlp.3.bias', 'mlp.3.lora_A', 'mlp.3.lora_B', 'mlp.6.weight', 'mlp.6.bias', 'mlp.6.lora_A', 'mlp.6.lora_B', 'lin1.lora_A', 'lin1.lora_B', 'lin2.lora_A', 'lin2.lora_B', 'lin3.lora_A', 'lin3.lora_B'], unexpected_keys=['sa1_module.conv.local_nn.lins.0.weight', 'sa1_module.conv.local_nn.lins.0.bias', 'sa1_module.conv.local_nn.lins.1.weight', 'sa1_module.conv.local_nn.lins.1.bias', 'sa1_module.conv.local_nn.lins.2.weight', 'sa1_module.conv.local_nn.lins.2.bias', 'sa1_module.conv.local_nn.norms.0.module.weight', 'sa1_module.conv.local_nn.norms.0.module.bias', 'sa1_module.conv.local_nn.norms.0.module.running_mean', 'sa1_module.conv.local_nn.norms.0.module.running_var', 'sa1_module.conv.local_nn.norms.0.module.num_batches_tracked', 'sa1_module.conv.local_nn.norms.1.module.weight', 'sa1_module.conv.local_nn.norms.1.module.bias', 'sa1_module.conv.local_nn.norms.1.module.running_mean', 'sa1_module.conv.local_nn.norms.1.module.running_var', 'sa1_module.conv.local_nn.norms.1.module.num_batches_tracked', 'sa2_module.conv.local_nn.lins.0.weight', 'sa2_module.conv.local_nn.lins.0.bias', 'sa2_module.conv.local_nn.lins.1.weight', 'sa2_module.conv.local_nn.lins.1.bias', 'sa2_module.conv.local_nn.lins.2.weight', 'sa2_module.conv.local_nn.lins.2.bias', 'sa2_module.conv.local_nn.norms.0.module.weight', 'sa2_module.conv.local_nn.norms.0.module.bias', 'sa2_module.conv.local_nn.norms.0.module.running_mean', 'sa2_module.conv.local_nn.norms.0.module.running_var', 'sa2_module.conv.local_nn.norms.0.module.num_batches_tracked', 'sa2_module.conv.local_nn.norms.1.module.weight', 'sa2_module.conv.local_nn.norms.1.module.bias', 'sa2_module.conv.local_nn.norms.1.module.running_mean', 'sa2_module.conv.local_nn.norms.1.module.running_var', 'sa2_module.conv.local_nn.norms.1.module.num_batches_tracked', 'sa3_module.nn.lins.0.weight', 'sa3_module.nn.lins.0.bias', 'sa3_module.nn.lins.1.weight', 'sa3_module.nn.lins.1.bias', 'sa3_module.nn.lins.2.weight', 'sa3_module.nn.lins.2.bias', 'sa3_module.nn.norms.0.module.weight', 'sa3_module.nn.norms.0.module.bias', 'sa3_module.nn.norms.0.module.running_mean', 'sa3_module.nn.norms.0.module.running_var', 'sa3_module.nn.norms.0.module.num_batches_tracked', 'sa3_module.nn.norms.1.module.weight', 'sa3_module.nn.norms.1.module.bias', 'sa3_module.nn.norms.1.module.running_mean', 'sa3_module.nn.norms.1.module.running_var', 'sa3_module.nn.norms.1.module.num_batches_tracked', 'fp3_module.nn.lins.0.weight', 'fp3_module.nn.lins.0.bias', 'fp3_module.nn.lins.1.weight', 'fp3_module.nn.lins.1.bias', 'fp3_module.nn.norms.0.module.weight', 'fp3_module.nn.norms.0.module.bias', 'fp3_module.nn.norms.0.module.running_mean', 'fp3_module.nn.norms.0.module.running_var', 'fp3_module.nn.norms.0.module.num_batches_tracked', 'fp2_module.nn.lins.0.weight', 'fp2_module.nn.lins.0.bias', 'fp2_module.nn.lins.1.weight', 'fp2_module.nn.lins.1.bias', 'fp2_module.nn.norms.0.module.weight', 'fp2_module.nn.norms.0.module.bias', 'fp2_module.nn.norms.0.module.running_mean', 'fp2_module.nn.norms.0.module.running_var', 'fp2_module.nn.norms.0.module.num_batches_tracked', 'fp1_module.nn.lins.0.weight', 'fp1_module.nn.lins.0.bias', 'fp1_module.nn.lins.1.weight', 'fp1_module.nn.lins.1.bias', 'fp1_module.nn.lins.2.weight', 'fp1_module.nn.lins.2.bias', 'fp1_module.nn.norms.0.module.weight', 'fp1_module.nn.norms.0.module.bias', 'fp1_module.nn.norms.0.module.running_mean', 'fp1_module.nn.norms.0.module.running_var', 'fp1_module.nn.norms.0.module.num_batches_tracked', 'fp1_module.nn.norms.1.module.weight', 'fp1_module.nn.norms.1.module.bias', 'fp1_module.nn.norms.1.module.running_mean', 'fp1_module.nn.norms.1.module.running_var', 'fp1_module.nn.norms.1.module.num_batches_tracked', 'mlp.lins.0.weight', 'mlp.lins.0.bias', 'mlp.lins.1.weight', 'mlp.lins.1.bias', 'mlp.lins.2.weight', 'mlp.lins.2.bias'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_path = \"checkpoints/pointnet2_s3dis_transform_seg_x3_45_checkpoint.pth\"\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PyGPointNet2NoColorLoRa(num_classes=13).to(device)\n",
    "\n",
    "checkpoint = torch.load(pretrained_path, map_location=device)\n",
    "# Extract the model state dictionary\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "model.load_state_dict(model_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyGPointNet2NoColorLoRa(\n",
      "  (sa1_module): SAModule(\n",
      "    (conv): PointNetConv(local_nn=Sequential(\n",
      "      (0): Linear(in_features=6, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=64, out_features=128, bias=True)\n",
      "    ), global_nn=None)\n",
      "  )\n",
      "  (sa2_module): SAModule(\n",
      "    (conv): PointNetConv(local_nn=Sequential(\n",
      "      (0): Linear(in_features=131, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=128, out_features=256, bias=True)\n",
      "    ), global_nn=None)\n",
      "  )\n",
      "  (sa3_module): GlobalSAModule(\n",
      "    (nn): Sequential(\n",
      "      (0): Linear(in_features=259, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=512, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fp3_module): FPModule(\n",
      "    (nn): Sequential(\n",
      "      (0): Linear(in_features=1280, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fp2_module): FPModule(\n",
      "    (nn): Sequential(\n",
      "      (0): Linear(in_features=384, out_features=256, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fp1_module): FPModule(\n",
      "    (nn): Sequential(\n",
      "      (0): Linear(in_features=131, out_features=128, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=13, bias=True)\n",
      "  )\n",
      "  (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (lin3): Linear(in_features=128, out_features=13, bias=True)\n",
      ")\n",
      "PyGPointNet2NoColor(\n",
      "  (sa1_module): SAModule(\n",
      "    (conv): PointNetConv(local_nn=MLP(6, 64, 64, 128), global_nn=None)\n",
      "  )\n",
      "  (sa2_module): SAModule(\n",
      "    (conv): PointNetConv(local_nn=MLP(131, 128, 128, 256), global_nn=None)\n",
      "  )\n",
      "  (sa3_module): GlobalSAModule(\n",
      "    (nn): MLP(259, 256, 512, 1024)\n",
      "  )\n",
      "  (fp3_module): FPModule(\n",
      "    (nn): MLP(1280, 256, 256)\n",
      "  )\n",
      "  (fp2_module): FPModule(\n",
      "    (nn): MLP(384, 256, 128)\n",
      "  )\n",
      "  (fp1_module): FPModule(\n",
      "    (nn): MLP(131, 128, 128, 128)\n",
      "  )\n",
      "  (mlp): MLP(128, 128, 128, 13)\n",
      "  (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (lin3): Linear(in_features=128, out_features=13, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modela = PyGPointNet2NoColorLoRa(num_classes=13).to(device)\n",
    "modelb = PyGPointNet2NoColor(num_classes=13).to(device)\n",
    "\n",
    "print(modela)\n",
    "print(modelb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced local_nn[0] with LoRA\n",
      "Replaced local_nn[2] with LoRA\n",
      "Replaced local_nn[4] with LoRA\n",
      "Replaced local_nn[0] with LoRA\n",
      "Replaced local_nn[2] with LoRA\n",
      "Replaced local_nn[4] with LoRA\n",
      "Replaced nn[0] with LoRA\n",
      "Replaced nn[2] with LoRA\n",
      "Replaced nn[4] with LoRA\n",
      "Replaced nn[0] with LoRA\n",
      "Replaced nn[2] with LoRA\n",
      "Replaced nn[0] with LoRA\n",
      "Replaced nn[2] with LoRA\n",
      "Replaced nn[0] with LoRA\n",
      "Replaced nn[2] with LoRA\n",
      "Replaced nn[4] with LoRA\n",
      "Replaced mlp[0] with LoRA\n",
      "Replaced mlp[3] with LoRA\n",
      "Replaced mlp[6] with LoRA\n",
      "Replaced lin1 with LoRA\n",
      "Replaced lin2 with LoRA\n",
      "Replaced lin3 with LoRA\n"
     ]
    }
   ],
   "source": [
    "apply_lora(model, r=8, alpha=16, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyGPointNet2NoColorLoRa(\n",
       "  (sa1_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=Sequential(\n",
       "      (0): Linear(in_features=6, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=128, bias=True)\n",
       "    ), global_nn=None)\n",
       "  )\n",
       "  (sa2_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=Sequential(\n",
       "      (0): Linear(in_features=131, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=256, bias=True)\n",
       "    ), global_nn=None)\n",
       "  )\n",
       "  (sa3_module): GlobalSAModule(\n",
       "    (nn): Sequential(\n",
       "      (0): Linear(in_features=259, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fp3_module): FPModule(\n",
       "    (nn): Sequential(\n",
       "      (0): Linear(in_features=1280, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fp2_module): FPModule(\n",
       "    (nn): Sequential(\n",
       "      (0): Linear(in_features=384, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fp1_module): FPModule(\n",
       "    (nn): Sequential(\n",
       "      (0): Linear(in_features=131, out_features=128, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=13, bias=True)\n",
       "  )\n",
       "  (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin3): Linear(in_features=128, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_path = \"checkpoints/smartlab_lora_weights_x3_100_20250424.pth\"\n",
    "model.load_state_dict(torch.load(lora_path), strict=False)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all parameters except LoRA\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"lora_\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable LoRA parameters: 44\n",
      "['sa1_module.conv.local_nn.0.lora_A',\n",
      " 'sa1_module.conv.local_nn.0.lora_B',\n",
      " 'sa1_module.conv.local_nn.2.lora_A',\n",
      " 'sa1_module.conv.local_nn.2.lora_B',\n",
      " 'sa1_module.conv.local_nn.4.lora_A',\n",
      " 'sa1_module.conv.local_nn.4.lora_B',\n",
      " 'sa2_module.conv.local_nn.0.lora_A',\n",
      " 'sa2_module.conv.local_nn.0.lora_B',\n",
      " 'sa2_module.conv.local_nn.2.lora_A',\n",
      " 'sa2_module.conv.local_nn.2.lora_B',\n",
      " 'sa2_module.conv.local_nn.4.lora_A',\n",
      " 'sa2_module.conv.local_nn.4.lora_B',\n",
      " 'sa3_module.nn.0.lora_A',\n",
      " 'sa3_module.nn.0.lora_B',\n",
      " 'sa3_module.nn.2.lora_A',\n",
      " 'sa3_module.nn.2.lora_B',\n",
      " 'sa3_module.nn.4.lora_A',\n",
      " 'sa3_module.nn.4.lora_B',\n",
      " 'fp3_module.nn.0.lora_A',\n",
      " 'fp3_module.nn.0.lora_B',\n",
      " 'fp3_module.nn.2.lora_A',\n",
      " 'fp3_module.nn.2.lora_B',\n",
      " 'fp2_module.nn.0.lora_A',\n",
      " 'fp2_module.nn.0.lora_B',\n",
      " 'fp2_module.nn.2.lora_A',\n",
      " 'fp2_module.nn.2.lora_B',\n",
      " 'fp1_module.nn.0.lora_A',\n",
      " 'fp1_module.nn.0.lora_B',\n",
      " 'fp1_module.nn.2.lora_A',\n",
      " 'fp1_module.nn.2.lora_B',\n",
      " 'fp1_module.nn.4.lora_A',\n",
      " 'fp1_module.nn.4.lora_B',\n",
      " 'mlp.0.lora_A',\n",
      " 'mlp.0.lora_B',\n",
      " 'mlp.3.lora_A',\n",
      " 'mlp.3.lora_B',\n",
      " 'mlp.6.lora_A',\n",
      " 'mlp.6.lora_B',\n",
      " 'lin1.lora_A',\n",
      " 'lin1.lora_B',\n",
      " 'lin2.lora_A',\n",
      " 'lin2.lora_B',\n",
      " 'lin3.lora_A',\n",
      " 'lin3.lora_B']\n"
     ]
    }
   ],
   "source": [
    "# Verify\n",
    "trainable_params = [n for n, p in model.named_parameters() if p.requires_grad]\n",
    "from pprint import pprint\n",
    "print(f\"Trainable LoRA parameters: {len(trainable_params)}\")\n",
    "pprint(trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pcd files\n",
    "#pcd_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/Smartlab-2024-04-05_10-58-26_colour_cleaned.pcd\"\n",
    "pcd_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/SmartLab_2024_E57_Single_5mm.pcd\"\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the point cloud to its min(x,y,z) corner\n",
    " \n",
    "def move_to_corner(points):    \n",
    "    # Find the minimum x, y, z\n",
    "    min_xyz = points.min(axis=0)\n",
    "    # Translate the point cloud so that the min corner becomes the origin\n",
    "    moved_points = points - min_xyz\n",
    "    \n",
    "    return moved_points\n",
    "\n",
    "moved_points = move_to_corner(np.array(pcd.points))\n",
    "pcd.points = o3d.utility.Vector3dVector(moved_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866900\n"
     ]
    }
   ],
   "source": [
    "# Downsample the point cloud with a voxel of 0.03\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=0.03)\n",
    "\n",
    "print(len(downpcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_points_corner(points):\n",
    "    # Step 1: Shift points so that the minimum x, y, z becomes the origin.\n",
    "    min_vals = np.min(points, axis=0)\n",
    "    shifted_points = points - min_vals  # Now the lower bound is (0,0,0)\n",
    "    \n",
    "    # Step 2: Compute the scaling factors from the shifted points.\n",
    "    # The maximum after shifting represents the range in each dimension.\n",
    "    max_vals = np.max(shifted_points, axis=0)\n",
    "    scale = max_vals.copy()\n",
    "    \n",
    "    # Avoid division by zero if any dimension is flat.\n",
    "    scale[scale == 0] = 1\n",
    "    \n",
    "    # Normalize the shifted points to the [0, 1] interval.\n",
    "    normalized_points = shifted_points / scale\n",
    "\n",
    "    return normalized_points\n",
    "\n",
    "normalized = normalize_points_corner(np.array(downpcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates and colors from the point cloud\n",
    "down_points = torch.tensor(np.array(downpcd.points), dtype=torch.float32)  \n",
    "down_colors = torch.tensor(np.array(downpcd.colors), dtype=torch.float32)\n",
    "down_normalized = torch.tensor(normalized, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data object with x (3 features) and pos (coordinates)\n",
    "\n",
    "data = Data(x=down_normalized, pos=down_points)\n",
    "\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have only one point cloud\n",
    "dataset = [data]  # List of Data objects\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 32\n",
    "\n",
    "# Create a DataLoader (batch_size can be adjusted as needed)\n",
    "custom_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=num_workers) #, pin_memory=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts:\n",
      "tensor([[     2, 866900]])\n",
      "Total inference time: 242.5465 seconds\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     torch_cluster::fps         0.00%       1.993ms         0.01%      18.659ms       9.329ms      239.383s        98.70%      239.399s      119.700s             2  \n",
      "                                     torch_cluster::knn         0.00%       2.497ms         0.65%        1.576s     525.425ms        1.572s         0.65%        1.577s     525.566ms             3  \n",
      "                                  torch_cluster::radius         0.00%       4.516ms         0.31%     743.657ms     371.829ms     727.995ms         0.30%     751.037ms     375.519ms             2  \n",
      "                                           aten::linear         0.00%       1.681ms         0.17%     422.765ms      11.125ms       1.046ms         0.00%     579.350ms      15.246ms            38  \n",
      "                                            aten::addmm         0.09%     206.760ms         0.09%     208.213ms      10.959ms     280.771ms         0.12%     280.901ms      14.784ms            19  \n",
      "                                  aten::scatter_reduce_         0.00%     260.200us         0.00%     488.200us     162.733us     226.258ms         0.09%     237.288ms      79.096ms             3  \n",
      "                                             aten::relu         0.00%     235.100us         0.01%      33.616ms       2.801ms      77.000us         0.00%      51.259ms       4.272ms            12  \n",
      "                                        aten::clamp_min         0.01%      33.381ms         0.01%      33.381ms       2.782ms      51.182ms         0.02%      51.182ms       4.265ms            12  \n",
      "                                              aten::cat         0.00%       7.352ms         0.00%       8.532ms     449.037us      46.574ms         0.02%      46.892ms       2.468ms            19  \n",
      "                                     aten::index_select         0.02%      40.139ms         0.02%      41.469ms       6.912ms      37.275ms         0.02%      44.743ms       7.457ms             6  \n",
      "                                         aten::_unique2         0.01%      34.058ms         0.01%      34.169ms      34.169ms      33.857ms         0.01%      33.974ms      33.974ms             1  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         0.00%       2.940ms         0.01%      19.814ms       9.907ms       2.047ms         0.00%      19.864ms       9.932ms             2  \n",
      "                                               aten::to         0.00%     770.200us         0.09%     214.963ms       2.905ms       1.187ms         0.00%      19.236ms     259.946us            74  \n",
      "                                         aten::_to_copy         0.00%       1.971ms         0.09%     214.193ms       3.825ms       1.319ms         0.00%      18.049ms     322.304us            56  \n",
      "                                            aten::copy_         0.09%     211.965ms         0.09%     211.965ms       3.785ms      16.176ms         0.01%      16.176ms     288.857us            56  \n",
      "                                     aten::scatter_add_         0.00%       2.376ms         0.00%       2.393ms     299.138us      15.486ms         0.01%      15.647ms       1.956ms             8  \n",
      "                                              aten::div         0.01%      12.205ms         0.01%      12.205ms       4.068ms      15.209ms         0.01%      15.209ms       5.070ms             3  \n",
      "                                          aten::resize_         0.00%       2.443ms         0.00%       2.443ms      61.075us      15.171ms         0.01%      15.171ms     379.275us            40  \n",
      "                                    aten::masked_select         0.00%       1.230ms         0.67%        1.619s     161.938ms       2.799ms         0.00%      13.906ms       1.391ms            10  \n",
      "                                         aten::scatter_         0.00%     219.400us         0.00%     223.200us      74.400us      10.997ms         0.00%      11.011ms       3.670ms             3  \n",
      "                                              aten::mul         0.00%     347.800us         0.00%     347.800us      26.754us      10.996ms         0.00%      10.996ms     845.846us            13  \n",
      "                                            aten::stack         0.00%     311.500us         0.00%       2.435ms     304.363us     170.000us         0.00%       9.532ms       1.192ms             8  \n",
      "                                           aten::argmax         0.00%       8.487ms         0.00%       8.490ms       8.490ms       8.758ms         0.00%       8.766ms       8.766ms             1  \n",
      "                                            aten::index        93.98%      227.924s        93.98%      227.925s       10.854s       7.737ms         0.00%       8.288ms     394.667us            21  \n",
      "                                              aten::sum         0.00%       7.157ms         0.00%       7.157ms       2.386ms       7.224ms         0.00%       7.224ms       2.408ms             3  \n",
      "                                             aten::ceil         0.00%       6.513ms         0.00%       6.513ms       3.256ms       6.537ms         0.00%       6.537ms       3.268ms             2  \n",
      "                                              aten::max         0.00%       7.186ms         0.00%       7.319ms     563.015us       6.301ms         0.00%       6.530ms     502.308us            13  \n",
      "                                           aten::cumsum         0.00%       6.280ms         0.00%       6.392ms     710.200us       6.267ms         0.00%       6.382ms     709.111us             9  \n",
      "                                             aten::full         0.00%     610.500us         0.00%       5.717ms     571.750us     297.000us         0.00%       6.100ms     610.000us            10  \n",
      "                                          aten::nonzero         0.67%        1.616s         0.67%        1.617s     161.681ms       2.674ms         0.00%       6.031ms     603.100us            10  \n",
      "                                            aten::empty         0.00%       2.758ms         0.00%       2.758ms      25.075us       5.438ms         0.00%       5.438ms      49.436us           110  \n",
      "                                           aten::arange         0.00%       2.418ms         0.00%       4.508ms     204.927us       2.511ms         0.00%       4.794ms     217.909us            22  \n",
      "                                            aten::fill_         0.00%       4.710ms         0.00%       4.710ms     151.929us       4.443ms         0.00%       4.443ms     143.323us            31  \n",
      "                                              aten::sub         0.00%     455.400us         0.00%     455.400us      65.057us       4.261ms         0.00%       4.261ms     608.714us             7  \n",
      "                                        aten::new_zeros         0.00%     466.800us         0.00%       1.363ms      97.371us     370.000us         0.00%       4.048ms     289.143us            14  \n",
      "                                            aten::zero_         0.00%     470.900us         0.00%     885.000us      38.478us     293.000us         0.00%       3.447ms     149.870us            23  \n",
      "                                             aten::item         0.00%     514.400us         4.79%       11.623s     611.752ms     379.000us         0.00%       2.530ms     133.158us            19  \n",
      "                              aten::_local_scalar_dense         4.79%       11.623s         4.79%       11.623s     611.725ms       2.151ms         0.00%       2.151ms     113.211us            19  \n",
      "                                             aten::rand         0.00%      60.100us         0.00%       1.608ms     804.200us      61.000us         0.00%       1.631ms     815.500us             2  \n",
      "                                         aten::uniform_         0.00%       1.539ms         0.00%       1.539ms     769.400us       1.549ms         0.00%       1.549ms     774.500us             2  \n",
      "                                           aten::narrow         0.00%     941.500us         0.00%       1.832ms      73.296us     522.000us         0.00%       1.225ms      49.000us            25  \n",
      "                                       aten::as_strided         0.00%     260.700us         0.00%     260.700us       1.534us       1.174ms         0.00%       1.174ms       6.906us           170  \n",
      "                                           aten::select         0.00%     863.100us         0.00%     896.700us      28.926us     834.000us         0.00%       1.013ms      32.677us            31  \n",
      "                                                aten::t         0.00%     481.200us         0.00%       1.055ms      36.390us     541.000us         0.00%     976.000us      33.655us            29  \n",
      "                                            aten::slice         0.00%     937.300us         0.00%     988.300us      34.079us     535.000us         0.00%     808.000us      27.862us            29  \n",
      "                                        aten::new_empty         0.00%     271.500us         0.00%     392.800us      20.674us     529.000us         0.00%     689.000us      36.263us            19  \n",
      "                                    aten::empty_strided         0.00%     280.500us         0.00%     280.500us       4.836us     587.000us         0.00%     587.000us      10.121us            58  \n",
      "                                          aten::reshape         0.00%     459.500us         0.00%     535.000us      16.719us     313.000us         0.00%     561.000us      17.531us            32  \n",
      "                                               aten::ne         0.28%     688.885ms         0.28%     688.885ms     137.777ms     534.000us         0.00%     534.000us     106.800us             5  \n",
      "                                        aten::transpose         0.00%     521.200us         0.00%     574.100us      19.797us     285.000us         0.00%     435.000us      15.000us            29  \n",
      "                                             aten::view         0.00%     178.800us         0.00%     178.800us       3.576us     335.000us         0.00%     335.000us       6.700us            50  \n",
      "                                        aten::ones_like         0.00%      63.500us         0.00%     154.900us      77.450us      69.000us         0.00%     279.000us     139.500us             2  \n",
      "                                           aten::unbind         0.00%     135.700us         0.00%     229.100us      76.367us      71.000us         0.00%     277.000us      92.333us             3  \n",
      "                                      aten::log_softmax         0.00%      60.100us         0.02%      49.071ms      49.071ms       6.000us         0.00%     275.000us     275.000us             1  \n",
      "                                     aten::_log_softmax         0.02%      49.011ms         0.02%      49.011ms      49.011ms     269.000us         0.00%     269.000us     269.000us             1  \n",
      "                                          aten::detach_         0.00%      99.500us         0.00%     121.000us      17.286us     173.000us         0.00%     232.000us      33.143us             7  \n",
      "                                            aten::zeros         0.00%      58.700us         0.00%     138.000us      69.000us      67.000us         0.00%     197.000us      98.500us             2  \n",
      "                                        aten::expand_as         0.00%     125.400us         0.00%     288.800us      32.089us      63.000us         0.00%     165.000us      18.333us             9  \n",
      "                                            aten::clamp         0.00%     189.400us         0.00%     193.000us      64.333us     139.000us         0.00%     150.000us      50.000us             3  \n",
      "                                           aten::expand         0.00%     148.400us         0.00%     163.400us      18.156us      69.000us         0.00%     102.000us      11.333us             9  \n",
      "                                       aten::reciprocal         0.00%     127.800us         0.00%     127.800us      42.600us     101.000us         0.00%     101.000us      33.667us             3  \n",
      "                                       aten::empty_like         0.00%      41.100us         0.00%      64.600us      32.300us      40.000us         0.00%      73.000us      36.500us             2  \n",
      "                                                detach_         0.00%      21.500us         0.00%      21.500us       3.071us      59.000us         0.00%      59.000us       8.429us             7  \n",
      "                                          aten::random_         0.00%      38.000us         0.00%      38.000us      38.000us      47.000us         0.00%      47.000us      47.000us             1  \n",
      "                                        aten::unsqueeze         0.00%      32.700us         0.00%      36.400us      18.200us      35.000us         0.00%      46.000us      23.000us             2  \n",
      "                                             aten::set_         0.00%     150.100us         0.00%     150.100us      15.010us      43.000us         0.00%      43.000us       4.300us            10  \n",
      "                                       aten::lift_fresh         0.00%       6.100us         0.00%       6.100us       0.871us      41.000us         0.00%      41.000us       5.857us             7  \n",
      "                                          aten::dropout         0.00%       4.400us         0.00%       4.400us       2.200us       6.000us         0.00%       6.000us       3.000us             2  \n",
      "                                      aten::resolve_neg         0.00%       0.700us         0.00%       0.700us       0.700us       6.000us         0.00%       6.000us       6.000us             1  \n",
      "                                     aten::resolve_conj         0.00%       0.700us         0.00%       0.700us       0.700us       5.000us         0.00%       5.000us       5.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 242.527s\n",
      "Self CUDA time total: 242.527s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "import torch.profiler\n",
    "\n",
    "with torch.profiler.profile(\n",
    "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    ") as prof:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        for data in custom_loader:\n",
    "            data = data.to(device)\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                predictions = model(data)\n",
    "            labels = predictions.argmax(dim=-1)\n",
    "            # Process the labels as needed\n",
    "            #labels_arr = labels.cpu().numpy()\n",
    "            # Count occurrences of labels\n",
    "            unique_labels, label_counts = torch.unique(labels, return_counts=True)\n",
    "            # Combine and print\n",
    "            #result_labels = np.array(list(zip(unique_labels, label_counts)))\n",
    "            #print(\"Label counts:\")\n",
    "            #for label, count in zip(unique_labels, label_counts):\n",
    "            #    print(f\"Label {label.item()}: {count.item()}\")\n",
    "            result_labels = torch.stack((unique_labels, label_counts), dim=1).cpu()\n",
    "            print(\"Label counts:\")\n",
    "            print(result_labels)\n",
    "        end_time = time.time()\n",
    "        print(f\"Total inference time: {end_time - start_time:.4f} seconds\")  \n",
    "    \n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `labels` is the tensor containing predicted labels for each point\n",
    "predicted_colors = color_map[labels.cpu().numpy()]  # Shape: [num_points, 3]\n",
    "\n",
    "# Assuming `pcd` is your Open3D point cloud object\n",
    "downpcd.colors = o3d.utility.Vector3dVector(predicted_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the point cloud with colored labels\n",
    "o3d.visualization.draw_geometries([downpcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the point cloud to a file\n",
    "save_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/labelled/Smartlab_aalto_pcd_lora_label_pointnet2_x3_0.03_20250418.ply\"\n",
    "o3d.io.write_point_cloud(save_path, downpcd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pyg_pointnet2 import PyGPointNet2NoColor\n",
    "import loralib as lora\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import MLP\n",
    "from torch_geometric.loader import DataLoader\n",
    "import time\n",
    "from pc_label_map import color_map\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_lora(module, r=8, alpha=16, verbose=False):\n",
    "    \"\"\"\n",
    "    Recursively replaces Linear layers with LoRA-enabled layers.\n",
    "    Handles custom modules like MLP, SAModule, and FPModule.\n",
    "    \"\"\"\n",
    "    # Special handling for MLP modules which likely contain multiple linear layers\n",
    "    if hasattr(module, '__class__') and module.__class__.__name__ == 'MLP':\n",
    "        if verbose:\n",
    "            print(f\"Processing MLP module: {module}\")\n",
    "        # Handle linear layers inside the MLP\n",
    "        if hasattr(module, 'lins'):\n",
    "            for i, lin in enumerate(module.lins):\n",
    "                # Check if the layer has the necessary attributes of a Linear layer\n",
    "                if hasattr(lin, 'in_channels') and hasattr(lin, 'out_channels') and hasattr(lin, 'weight'):\n",
    "                    lora_layer = lora.Linear(\n",
    "                        in_features=lin.in_channels,\n",
    "                        out_features=lin.out_channels,\n",
    "                        r=r,\n",
    "                        lora_alpha=alpha\n",
    "                    )\n",
    "                    lora_layer.weight.data = lin.weight.data.clone()\n",
    "                    if hasattr(lin, 'bias') and lin.bias is not None:\n",
    "                        lora_layer.bias.data = lin.bias.data.clone()\n",
    "                    module.lins[i] = lora_layer\n",
    "                    if verbose:\n",
    "                        print(f\"Replaced MLP.lins[{i}] with LoRA ({lin.__class__.__name__})\")\n",
    "\n",
    "    # Process all named children modules\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Linear):\n",
    "            # Replace this Linear layer with LoRA\n",
    "            lora_layer = lora.Linear(\n",
    "                in_features=child.in_features,\n",
    "                out_features=child.out_features,\n",
    "                r=r,\n",
    "                lora_alpha=alpha\n",
    "            )\n",
    "            \n",
    "            # Copy original weights and biases\n",
    "            lora_layer.weight.data = child.weight.data.clone()\n",
    "            if child.bias is not None:\n",
    "                lora_layer.bias.data = child.bias.data.clone()\n",
    "            \n",
    "            # Replace the layer\n",
    "            setattr(module, name, lora_layer)\n",
    "            if verbose:\n",
    "                print(f\"Replaced {name} with LoRA\")\n",
    "        elif isinstance(child, nn.Sequential):\n",
    "            # Special handling for Sequential containers\n",
    "            for idx, layer in enumerate(child):\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    lora_layer = lora.Linear(\n",
    "                        in_features=layer.in_features,\n",
    "                        out_features=layer.out_features,\n",
    "                        r=r,\n",
    "                        lora_alpha=alpha\n",
    "                    )\n",
    "                    lora_layer.weight.data = layer.weight.data.clone()\n",
    "                    if layer.bias is not None:\n",
    "                        lora_layer.bias.data = layer.bias.data.clone()\n",
    "                    child[idx] = lora_layer\n",
    "                    if verbose:\n",
    "                        print(f\"Replaced {name}[{idx}] with LoRA\")\n",
    "                else:\n",
    "                    # Recursively apply to layers within Sequential that aren't Linear\n",
    "                    apply_lora(layer, r, alpha, verbose)\n",
    "        else:\n",
    "            # Recursively apply to all other nested submodules\n",
    "            apply_lora(child, r, alpha, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_path = \"checkpoints/pointnet2_s3dis_transform_seg_x3_45_checkpoint.pth\"\n",
    "\n",
    "# Initialize model\n",
    "\n",
    "model = PyGPointNet2NoColor(num_classes=13).to(device)\n",
    "\n",
    "checkpoint = torch.load(pretrained_path, map_location=device)\n",
    "# Extract the model state dictionary\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "model.load_state_dict(model_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing MLP module: MLP(6, 64, 64, 128)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced MLP.lins[2] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Replaced 2 with LoRA\n",
      "Processing MLP module: MLP(131, 128, 128, 256)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced MLP.lins[2] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Replaced 2 with LoRA\n",
      "Processing MLP module: MLP(259, 256, 512, 1024)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced MLP.lins[2] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Replaced 2 with LoRA\n",
      "Processing MLP module: MLP(1280, 256, 256)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Processing MLP module: MLP(384, 256, 128)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Processing MLP module: MLP(131, 128, 128, 128)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced MLP.lins[2] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Replaced 2 with LoRA\n",
      "Processing MLP module: MLP(128, 128, 128, 13)\n",
      "Replaced MLP.lins[0] with LoRA (Linear)\n",
      "Replaced MLP.lins[1] with LoRA (Linear)\n",
      "Replaced MLP.lins[2] with LoRA (Linear)\n",
      "Replaced 0 with LoRA\n",
      "Replaced 1 with LoRA\n",
      "Replaced 2 with LoRA\n",
      "Replaced lin1 with LoRA\n",
      "Replaced lin2 with LoRA\n",
      "Replaced lin3 with LoRA\n"
     ]
    }
   ],
   "source": [
    "apply_lora(model, r=8, alpha=16, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyGPointNet2NoColor(\n",
       "  (sa1_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=MLP(6, 64, 64, 128), global_nn=None)\n",
       "  )\n",
       "  (sa2_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=MLP(131, 128, 128, 256), global_nn=None)\n",
       "  )\n",
       "  (sa3_module): GlobalSAModule(\n",
       "    (nn): MLP(259, 256, 512, 1024)\n",
       "  )\n",
       "  (fp3_module): FPModule(\n",
       "    (nn): MLP(1280, 256, 256)\n",
       "  )\n",
       "  (fp2_module): FPModule(\n",
       "    (nn): MLP(384, 256, 128)\n",
       "  )\n",
       "  (fp1_module): FPModule(\n",
       "    (nn): MLP(131, 128, 128, 128)\n",
       "  )\n",
       "  (mlp): MLP(128, 128, 128, 13)\n",
       "  (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin3): Linear(in_features=128, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_path = \"checkpoints/smartlab_lora_weights_x3_100_20250424.pth\"\n",
    "model.load_state_dict(torch.load(lora_path), strict=False)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all parameters except LoRA\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"lora_\" in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable LoRA parameters: 44\n",
      "['sa1_module.conv.local_nn.lins.0.lora_A',\n",
      " 'sa1_module.conv.local_nn.lins.0.lora_B',\n",
      " 'sa1_module.conv.local_nn.lins.1.lora_A',\n",
      " 'sa1_module.conv.local_nn.lins.1.lora_B',\n",
      " 'sa1_module.conv.local_nn.lins.2.lora_A',\n",
      " 'sa1_module.conv.local_nn.lins.2.lora_B',\n",
      " 'sa2_module.conv.local_nn.lins.0.lora_A',\n",
      " 'sa2_module.conv.local_nn.lins.0.lora_B',\n",
      " 'sa2_module.conv.local_nn.lins.1.lora_A',\n",
      " 'sa2_module.conv.local_nn.lins.1.lora_B',\n",
      " 'sa2_module.conv.local_nn.lins.2.lora_A',\n",
      " 'sa2_module.conv.local_nn.lins.2.lora_B',\n",
      " 'sa3_module.nn.lins.0.lora_A',\n",
      " 'sa3_module.nn.lins.0.lora_B',\n",
      " 'sa3_module.nn.lins.1.lora_A',\n",
      " 'sa3_module.nn.lins.1.lora_B',\n",
      " 'sa3_module.nn.lins.2.lora_A',\n",
      " 'sa3_module.nn.lins.2.lora_B',\n",
      " 'fp3_module.nn.lins.0.lora_A',\n",
      " 'fp3_module.nn.lins.0.lora_B',\n",
      " 'fp3_module.nn.lins.1.lora_A',\n",
      " 'fp3_module.nn.lins.1.lora_B',\n",
      " 'fp2_module.nn.lins.0.lora_A',\n",
      " 'fp2_module.nn.lins.0.lora_B',\n",
      " 'fp2_module.nn.lins.1.lora_A',\n",
      " 'fp2_module.nn.lins.1.lora_B',\n",
      " 'fp1_module.nn.lins.0.lora_A',\n",
      " 'fp1_module.nn.lins.0.lora_B',\n",
      " 'fp1_module.nn.lins.1.lora_A',\n",
      " 'fp1_module.nn.lins.1.lora_B',\n",
      " 'fp1_module.nn.lins.2.lora_A',\n",
      " 'fp1_module.nn.lins.2.lora_B',\n",
      " 'mlp.lins.0.lora_A',\n",
      " 'mlp.lins.0.lora_B',\n",
      " 'mlp.lins.1.lora_A',\n",
      " 'mlp.lins.1.lora_B',\n",
      " 'mlp.lins.2.lora_A',\n",
      " 'mlp.lins.2.lora_B',\n",
      " 'lin1.lora_A',\n",
      " 'lin1.lora_B',\n",
      " 'lin2.lora_A',\n",
      " 'lin2.lora_B',\n",
      " 'lin3.lora_A',\n",
      " 'lin3.lora_B']\n"
     ]
    }
   ],
   "source": [
    "# Verify\n",
    "trainable_params = [n for n, p in model.named_parameters() if p.requires_grad]\n",
    "from pprint import pprint\n",
    "print(f\"Trainable LoRA parameters: {len(trainable_params)}\")\n",
    "pprint(trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pcd files\n",
    "#pcd_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/Smartlab-2024-04-05_10-58-26_colour_cleaned.pcd\"\n",
    "pcd_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/SmartLab_2024_E57_Single_5mm.pcd\"\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the point cloud to its min(x,y,z) corner\n",
    " \n",
    "def move_to_corner(points):    \n",
    "    # Find the minimum x, y, z\n",
    "    min_xyz = points.min(axis=0)\n",
    "    # Translate the point cloud so that the min corner becomes the origin\n",
    "    moved_points = points - min_xyz\n",
    "    \n",
    "    return moved_points\n",
    "\n",
    "moved_points = move_to_corner(np.array(pcd.points))\n",
    "pcd.points = o3d.utility.Vector3dVector(moved_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866900\n"
     ]
    }
   ],
   "source": [
    "# Downsample the point cloud with a voxel of 0.03\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=0.03)\n",
    "\n",
    "print(len(downpcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_points_corner(points):\n",
    "    # Step 1: Shift points so that the minimum x, y, z becomes the origin.\n",
    "    min_vals = np.min(points, axis=0)\n",
    "    shifted_points = points - min_vals  # Now the lower bound is (0,0,0)\n",
    "    \n",
    "    # Step 2: Compute the scaling factors from the shifted points.\n",
    "    # The maximum after shifting represents the range in each dimension.\n",
    "    max_vals = np.max(shifted_points, axis=0)\n",
    "    scale = max_vals.copy()\n",
    "    \n",
    "    # Avoid division by zero if any dimension is flat.\n",
    "    scale[scale == 0] = 1\n",
    "    \n",
    "    # Normalize the shifted points to the [0, 1] interval.\n",
    "    normalized_points = shifted_points / scale\n",
    "\n",
    "    return normalized_points\n",
    "\n",
    "normalized = normalize_points_corner(np.array(downpcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coordinates and colors from the point cloud\n",
    "down_points = torch.tensor(np.array(downpcd.points), dtype=torch.float32)  \n",
    "down_colors = torch.tensor(np.array(downpcd.colors), dtype=torch.float32)\n",
    "down_normalized = torch.tensor(normalized, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data object with x (3 features) and pos (coordinates)\n",
    "\n",
    "data = Data(x=down_normalized, pos=down_points)\n",
    "\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have only one point cloud\n",
    "dataset = [data]  # List of Data objects\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 32\n",
    "\n",
    "# Create a DataLoader (batch_size can be adjusted as needed)\n",
    "custom_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=num_workers) #, pin_memory=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts:\n",
      "tensor([[     0, 110914],\n",
      "        [     1, 123106],\n",
      "        [     2,  78799],\n",
      "        [     3,   3930],\n",
      "        [     4, 209059],\n",
      "        [     6,   9527],\n",
      "        [     7,  11721],\n",
      "        [     8,   2520],\n",
      "        [     9,      4],\n",
      "        [    10, 234999],\n",
      "        [    12,  82321]])\n",
      "Total inference time: 242.8952 seconds\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     torch_cluster::fps         0.01%      14.031ms         0.02%      41.350ms      20.675ms      239.472s        98.60%      239.498s      119.749s             2  \n",
      "                                     torch_cluster::knn         0.01%      13.302ms         0.67%        1.620s     540.060ms        1.614s         0.66%        1.621s     540.199ms             3  \n",
      "                                  torch_cluster::radius         0.01%      13.774ms         0.35%     850.793ms     425.396ms     831.390ms         0.34%     857.810ms     428.905ms             2  \n",
      "                                           aten::linear         0.00%       2.016ms         0.14%     331.275ms       8.718ms       1.463ms         0.00%     528.443ms      13.906ms            38  \n",
      "                                  aten::scatter_reduce_         0.00%     979.200us         0.00%       1.302ms     433.967us     263.939ms         0.11%     285.579ms      95.193ms             3  \n",
      "                                            aten::addmm         0.07%     161.820ms         0.07%     161.901ms       8.521ms     255.158ms         0.11%     255.328ms      13.438ms            19  \n",
      "                                       aten::batch_norm         0.00%     380.600us         0.02%      36.713ms       3.671ms      60.000us         0.00%      54.810ms       5.481ms            10  \n",
      "                           aten::_batch_norm_impl_index         0.00%     746.600us         0.01%      36.332ms       3.633ms      94.000us         0.00%      54.750ms       5.475ms            10  \n",
      "                                aten::native_batch_norm         0.01%      32.974ms         0.01%      35.544ms       3.554ms      31.808ms         0.01%      54.625ms       5.463ms            10  \n",
      "                                              aten::cat         0.00%       8.430ms         0.00%       9.043ms     475.942us      51.628ms         0.02%      52.286ms       2.752ms            19  \n",
      "                                     aten::index_select         0.02%      45.806ms         0.02%      46.833ms       7.806ms      43.435ms         0.02%      51.134ms       8.522ms             6  \n",
      "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...         0.00%       3.893ms         0.02%      38.336ms      19.168ms       3.053ms         0.00%      37.962ms      18.981ms             2  \n",
      "                                             aten::relu         0.00%     604.000us         0.00%      11.706ms     975.492us      78.000us         0.00%      36.419ms       3.035ms            12  \n",
      "                                        aten::clamp_min         0.00%      11.102ms         0.00%      11.102ms     925.158us      36.341ms         0.01%      36.341ms       3.028ms            12  \n",
      "                                         aten::_unique2         0.01%      26.262ms         0.01%      26.410ms      26.410ms      26.199ms         0.01%      26.415ms      26.415ms             1  \n",
      "                                               aten::to         0.00%     772.700us         0.11%     261.949ms       3.540ms     878.000us         0.00%      24.062ms     325.162us            74  \n",
      "                                         aten::_to_copy         0.00%       2.050ms         0.11%     261.176ms       4.664ms       1.170ms         0.00%      23.184ms     414.000us            56  \n",
      "                                    aten::empty_strided         0.00%       2.353ms         0.00%       2.353ms      34.603us      22.579ms         0.01%      22.579ms     332.044us            68  \n",
      "                                       aten::empty_like         0.00%     183.600us         0.00%       2.262ms     188.508us     549.000us         0.00%      22.553ms       1.879ms            12  \n",
      "                                         aten::scatter_         0.00%     310.900us         0.00%     316.800us     105.600us      21.607ms         0.01%      21.621ms       7.207ms             3  \n",
      "                                            aten::copy_         0.11%     259.154ms         0.11%     259.154ms       3.927ms      21.567ms         0.01%      21.567ms     326.773us            66  \n",
      "                                     aten::scatter_add_         0.00%       5.467ms         0.00%       5.485ms     685.650us      18.465ms         0.01%      18.561ms       2.320ms             8  \n",
      "                                           aten::cumsum         0.01%      18.975ms         0.01%      19.027ms       2.114ms      18.226ms         0.01%      18.400ms       2.044ms             9  \n",
      "                                    aten::masked_select         0.00%       2.960ms         0.68%        1.655s     165.483ms       4.059ms         0.00%      17.570ms       1.757ms            10  \n",
      "                                          aten::resize_         0.00%       1.996ms         0.00%       1.996ms      49.895us      15.369ms         0.01%      15.369ms     384.225us            40  \n",
      "                                              aten::sum         0.01%      15.213ms         0.01%      15.213ms       5.071ms      15.238ms         0.01%      15.238ms       5.079ms             3  \n",
      "                                              aten::max         0.01%      12.176ms         0.01%      12.350ms     950.008us      13.710ms         0.01%      14.150ms       1.088ms            13  \n",
      "                                              aten::div         0.00%       9.082ms         0.00%       9.082ms       3.027ms      12.029ms         0.00%      12.029ms       4.010ms             3  \n",
      "                                              aten::mul         0.00%     830.000us         0.00%     830.000us      63.846us      11.421ms         0.00%      11.421ms     878.538us            13  \n",
      "                                            aten::stack         0.00%     775.000us         0.00%       1.873ms     234.087us     412.000us         0.00%      10.047ms       1.256ms             8  \n",
      "                                            aten::index        93.89%      228.030s        93.89%      228.031s       10.859s       8.978ms         0.00%       9.934ms     473.048us            21  \n",
      "                                           aten::arange         0.00%       4.378ms         0.00%       8.150ms     370.464us       4.259ms         0.00%       8.210ms     373.182us            22  \n",
      "                                          aten::nonzero         0.68%        1.649s         0.68%        1.651s     165.056ms       4.067ms         0.00%       8.099ms     809.900us            10  \n",
      "                                           aten::argmax         0.00%       7.214ms         0.00%       7.226ms       7.226ms       7.477ms         0.00%       7.497ms       7.497ms             1  \n",
      "                                             aten::ceil         0.00%       7.587ms         0.00%       7.587ms       3.793ms       7.272ms         0.00%       7.272ms       3.636ms             2  \n",
      "                                             aten::full         0.00%     518.900us         0.00%       9.085ms     908.460us     343.000us         0.00%       6.081ms     608.100us            10  \n",
      "                                            aten::empty         0.00%       1.303ms         0.00%       1.303ms       9.307us       5.903ms         0.00%       5.903ms      42.164us           140  \n",
      "                                              aten::sub         0.00%       1.183ms         0.00%       1.183ms     168.971us       4.881ms         0.00%       4.881ms     697.286us             7  \n",
      "                                            aten::fill_         0.00%       8.462ms         0.00%       8.462ms     272.965us       4.689ms         0.00%       4.689ms     151.258us            31  \n",
      "                                        aten::new_zeros         0.00%     415.200us         0.00%       1.220ms      87.171us     518.000us         0.00%       4.463ms     318.786us            14  \n",
      "                                             aten::rand         0.00%     220.500us         0.00%       3.828ms       1.914ms     209.000us         0.00%       3.878ms       1.939ms             2  \n",
      "                                            aten::zero_         0.00%     443.600us         0.00%     789.600us      34.330us     394.000us         0.00%       3.773ms     164.043us            23  \n",
      "                                         aten::uniform_         0.00%       3.595ms         0.00%       3.595ms       1.798ms       3.656ms         0.00%       3.656ms       1.828ms             2  \n",
      "                                           aten::narrow         0.00%     710.200us         0.00%       2.235ms      89.404us     957.000us         0.00%       2.436ms      97.440us            25  \n",
      "                                             aten::item         0.00%     905.000us         4.79%       11.638s     298.416ms     737.000us         0.00%       2.220ms      56.923us            39  \n",
      "                                           aten::select         0.00%       1.449ms         0.00%       1.540ms      25.251us       1.652ms         0.00%       2.191ms      35.918us            61  \n",
      "                                       aten::as_strided         0.00%     675.400us         0.00%     675.400us       3.377us       2.070ms         0.00%       2.070ms      10.350us           200  \n",
      "                                            aten::slice         0.00%       1.352ms         0.00%       1.664ms      57.376us     983.000us         0.00%       1.630ms      56.207us            29  \n",
      "                              aten::_local_scalar_dense         4.79%       11.637s         4.79%       11.637s     298.393ms       1.483ms         0.00%       1.483ms      38.026us            39  \n",
      "                                          aten::reshape         0.00%       1.020ms         0.00%       1.127ms      35.225us     796.000us         0.00%       1.264ms      39.500us            32  \n",
      "                                                aten::t         0.00%     842.700us         0.00%       1.673ms      57.690us     428.000us         0.00%       1.253ms      43.207us            29  \n",
      "                                           aten::unbind         0.00%     608.900us         0.00%       1.062ms     353.967us     237.000us         0.00%     933.000us     311.000us             3  \n",
      "                                          aten::random_         0.00%     523.700us         0.00%     523.700us     523.700us     915.000us         0.00%     915.000us     915.000us             1  \n",
      "                                        aten::transpose         0.00%     726.600us         0.00%     830.300us      28.631us     591.000us         0.00%     825.000us      28.448us            29  \n",
      "                                        aten::new_empty         0.00%     280.300us         0.00%     407.700us      21.458us     591.000us         0.00%     748.000us      39.368us            19  \n",
      "                                             aten::view         0.00%     573.400us         0.00%     573.400us      11.468us     624.000us         0.00%     624.000us      12.480us            50  \n",
      "                                               aten::ne         0.32%     782.546ms         0.32%     782.546ms     156.509ms     591.000us         0.00%     591.000us     118.200us             5  \n",
      "                                            aten::clamp         0.00%     564.500us         0.00%     568.700us     189.567us     472.000us         0.00%     517.000us     172.333us             3  \n",
      "                                      aten::log_softmax         0.00%     204.900us         0.02%      51.686ms      51.686ms       7.000us         0.00%     350.000us     350.000us             1  \n",
      "                                     aten::_log_softmax         0.02%      51.481ms         0.02%      51.481ms      51.481ms     343.000us         0.00%     343.000us     343.000us             1  \n",
      "                                        aten::expand_as         0.00%     461.900us         0.00%     639.100us      71.011us      71.000us         0.00%     313.000us      34.778us             9  \n",
      "                                       aten::reciprocal         0.00%     327.800us         0.00%     327.800us     109.267us     295.000us         0.00%     295.000us      98.333us             3  \n",
      "                                        aten::ones_like         0.00%      52.800us         0.00%     124.100us      62.050us     108.000us         0.00%     293.000us     146.500us             2  \n",
      "                                           aten::expand         0.00%     161.900us         0.00%     177.200us      19.689us     209.000us         0.00%     242.000us      26.889us             9  \n",
      "                                          aten::detach_         0.00%     121.900us         0.00%     137.500us      19.643us     117.000us         0.00%     193.000us      27.571us             7  \n",
      "                                            aten::zeros         0.00%      39.900us         0.00%      88.400us      44.200us      30.000us         0.00%     159.000us      79.500us             2  \n",
      "                                             aten::set_         0.00%     311.200us         0.00%     311.200us      31.120us     134.000us         0.00%     134.000us      13.400us            10  \n",
      "                                       aten::lift_fresh         0.00%       4.200us         0.00%       4.200us       0.600us     108.000us         0.00%     108.000us      15.429us             7  \n",
      "                                                detach_         0.00%      15.600us         0.00%      15.600us       2.229us      76.000us         0.00%      76.000us      10.857us             7  \n",
      "                                      aten::resolve_neg         0.00%       2.200us         0.00%       2.200us       0.200us      74.000us         0.00%      74.000us       6.727us            11  \n",
      "                                          aten::dropout         0.00%      23.100us         0.00%      23.100us       1.216us      61.000us         0.00%      61.000us       3.211us            19  \n",
      "                                        aten::unsqueeze         0.00%      39.600us         0.00%      43.800us      21.900us      38.000us         0.00%      55.000us      27.500us             2  \n",
      "                                     aten::resolve_conj         0.00%       3.900us         0.00%       3.900us       0.355us      54.000us         0.00%      54.000us       4.909us            11  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 242.866s\n",
      "Self CUDA time total: 242.875s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "\n",
    "import torch.profiler\n",
    "\n",
    "with torch.profiler.profile(\n",
    "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "    record_shapes=True,\n",
    ") as prof:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        for data in custom_loader:\n",
    "            data = data.to(device)\n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                predictions = model(data)\n",
    "            labels = predictions.argmax(dim=-1)\n",
    "            # Process the labels as needed\n",
    "            #labels_arr = labels.cpu().numpy()\n",
    "            # Count occurrences of labels\n",
    "            unique_labels, label_counts = torch.unique(labels, return_counts=True)\n",
    "            # Combine and print\n",
    "            #result_labels = np.array(list(zip(unique_labels, label_counts)))\n",
    "            #print(\"Label counts:\")\n",
    "            #for label, count in zip(unique_labels, label_counts):\n",
    "            #    print(f\"Label {label.item()}: {count.item()}\")\n",
    "            result_labels = torch.stack((unique_labels, label_counts), dim=1).cpu()\n",
    "            print(\"Label counts:\")\n",
    "            print(result_labels)\n",
    "        end_time = time.time()\n",
    "        print(f\"Total inference time: {end_time - start_time:.4f} seconds\")  \n",
    "    \n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `labels` is the tensor containing predicted labels for each point\n",
    "predicted_colors = color_map[labels.cpu().numpy()]  # Shape: [num_points, 3]\n",
    "\n",
    "# Assuming `pcd` is your Open3D point cloud object\n",
    "downpcd.colors = o3d.utility.Vector3dVector(predicted_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the point cloud with colored labels\n",
    "o3d.visualization.draw_geometries([downpcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the point cloud to a file\n",
    "save_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/labelled/Smartlab_pcd_lora_label_pointnet2_x3_0.03_20250426.ply\"\n",
    "o3d.io.write_point_cloud(save_path, downpcd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projappl/project_2013104/pengyan1/venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/PUHTI_TYKKY_FRQGCcR/miniconda/envs/env1/lib/python310.zip',\n",
       " '/PUHTI_TYKKY_FRQGCcR/miniconda/envs/env1/lib/python3.10',\n",
       " '/PUHTI_TYKKY_FRQGCcR/miniconda/envs/env1/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/PUHTI_TYKKY_FRQGCcR/miniconda/envs/env1/lib/python3.10/site-packages',\n",
       " '/projappl/project_2013104/pengyan1/venv/lib/python3.10/site-packages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "folder_path = os.path.abspath(\"/projappl/project_2013104/pengyan1/venv/lib/python3.10/site-packages\")\n",
    "if folder_path not in sys.path:\n",
    "    sys.path.append(folder_path)\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MLP, PointNetConv, fps, global_max_pool, radius\n",
    "from torchmetrics.functional import jaccard_index\n",
    "from torchmetrics import JaccardIndex\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import S3DIS\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MLP, knn_interpolate\n",
    "from torch_geometric.typing import WITH_TORCH_CLUSTER\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "if not WITH_TORCH_CLUSTER:\n",
    "    quit(\"This example requires 'torch-cluster'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_area = 6  \n",
    "path = \"/scratch/project_2013104/datasets/s3dis/\"\n",
    "\n",
    "# transform and pre_transform\n",
    "transform = T.Compose([\n",
    "    T.RandomJitter(0.01),\n",
    "    T.RandomRotate(15, axis=0),\n",
    "    T.RandomRotate(15, axis=1),\n",
    "    T.RandomRotate(15, axis=2)\n",
    "])\n",
    "#pre_transform = T.NormalizeScale()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = S3DIS(root=path, test_area=test_area, train=True, force_reload=True, \n",
    "                      transform=transform)#,pre_transform=pre_transform)\n",
    "test_dataset = S3DIS(root=path, test_area=test_area, train=False, force_reload=True, \n",
    "                     transform=transform)#,pre_transform=pre_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "num_workers=10\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAModule(torch.nn.Module):\n",
    "    def __init__(self, ratio, r, nn):\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "        self.r = r\n",
    "        self.conv = PointNetConv(nn, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        idx = fps(pos, batch, ratio=self.ratio)\n",
    "        row, col = radius(pos, pos[idx], self.r, batch, batch[idx],\n",
    "                          max_num_neighbors=64)\n",
    "        edge_index = torch.stack([col, row], dim=0)\n",
    "        x_dst = None if x is None else x[idx]\n",
    "        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n",
    "        pos, batch = pos[idx], batch[idx]\n",
    "        return x, pos, batch\n",
    "\n",
    "\n",
    "class GlobalSAModule(torch.nn.Module):\n",
    "    def __init__(self, nn):\n",
    "        super().__init__()\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        x = self.nn(torch.cat([x, pos], dim=1))\n",
    "        x = global_max_pool(x, batch)\n",
    "        pos = pos.new_zeros((x.size(0), 3))\n",
    "        batch = torch.arange(x.size(0), device=batch.device)\n",
    "        return x, pos, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPModule(torch.nn.Module):\n",
    "    def __init__(self, k, nn):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch, x_skip, pos_skip, batch_skip):\n",
    "        x = knn_interpolate(x, pos, pos_skip, batch, batch_skip, k=self.k)\n",
    "        if x_skip is not None:\n",
    "            x = torch.cat([x, x_skip], dim=1)\n",
    "        x = self.nn(x)\n",
    "        return x, pos_skip, batch_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input channels account for both `pos` and node features.\n",
    "        self.sa1_module = SAModule(0.2, 0.2, MLP([3 + 6, 64, 64, 128])) # 3 (pos) + 6 (x)\n",
    "        self.sa2_module = SAModule(0.25, 0.4, MLP([128 + 3, 128, 128, 256]))\n",
    "        self.sa3_module = GlobalSAModule(MLP([256 + 3, 256, 512, 1024]))\n",
    "\n",
    "        self.fp3_module = FPModule(1, MLP([1024 + 256, 256, 256]))\n",
    "        self.fp2_module = FPModule(3, MLP([256 + 128, 256, 128]))\n",
    "        self.fp1_module = FPModule(3, MLP([128 + 6, 128, 128, 128]))\n",
    "\n",
    "        self.mlp = MLP([128, 128, 128, num_classes], dropout=0.5, norm=None)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(128, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 128)\n",
    "        self.lin3 = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        sa0_out = (data.x, data.pos, data.batch)\n",
    "        sa1_out = self.sa1_module(*sa0_out)\n",
    "        sa2_out = self.sa2_module(*sa1_out)\n",
    "        sa3_out = self.sa3_module(*sa2_out)\n",
    "\n",
    "        fp3_out = self.fp3_module(*sa3_out, *sa2_out)\n",
    "        fp2_out = self.fp2_module(*fp3_out, *sa1_out)\n",
    "        x, _, _ = self.fp1_module(*fp2_out, *sa0_out)\n",
    "\n",
    "        return self.mlp(x).log_softmax(dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(train_dataset.num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = correct_nodes = total_nodes = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct_nodes += out.argmax(dim=1).eq(data.y).sum().item()\n",
    "        total_nodes += data.num_nodes\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'[{i+1}/{len(train_loader)}] Loss: {total_loss / 10:.4f} '\n",
    "                  f'Train Acc: {correct_nodes / total_nodes:.4f}')\n",
    "            total_loss = correct_nodes = total_nodes = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    jaccard = JaccardIndex(num_classes=loader.dataset.num_classes, task=\"multiclass\").to(device)\n",
    "    \n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        outs = model(data)\n",
    "        preds = outs.argmax(dim=-1)\n",
    "        jaccard.update(preds, data.y)\n",
    "    \n",
    "    return jaccard.compute().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/318] Loss: 0.5014 Train Acc: 0.8335\n",
      "[20/318] Loss: 0.4716 Train Acc: 0.8499\n",
      "[30/318] Loss: 0.4170 Train Acc: 0.8696\n",
      "[40/318] Loss: 0.4527 Train Acc: 0.8554\n",
      "[50/318] Loss: 0.4486 Train Acc: 0.8605\n",
      "[60/318] Loss: 0.4109 Train Acc: 0.8718\n",
      "[70/318] Loss: 0.3873 Train Acc: 0.8795\n",
      "[80/318] Loss: 0.4178 Train Acc: 0.8688\n",
      "[90/318] Loss: 0.3812 Train Acc: 0.8792\n",
      "[100/318] Loss: 0.4188 Train Acc: 0.8725\n",
      "[110/318] Loss: 0.4478 Train Acc: 0.8608\n",
      "[120/318] Loss: 0.4024 Train Acc: 0.8731\n",
      "[130/318] Loss: 0.3637 Train Acc: 0.8846\n",
      "[140/318] Loss: 0.3751 Train Acc: 0.8822\n",
      "[150/318] Loss: 0.3659 Train Acc: 0.8858\n",
      "[160/318] Loss: 0.3874 Train Acc: 0.8777\n",
      "[170/318] Loss: 0.3755 Train Acc: 0.8807\n",
      "[180/318] Loss: 0.3823 Train Acc: 0.8780\n",
      "[190/318] Loss: 0.4063 Train Acc: 0.8746\n",
      "[200/318] Loss: 0.4127 Train Acc: 0.8686\n",
      "[210/318] Loss: 0.4128 Train Acc: 0.8712\n",
      "[220/318] Loss: 0.3887 Train Acc: 0.8755\n",
      "[230/318] Loss: 0.3843 Train Acc: 0.8754\n",
      "[240/318] Loss: 0.3822 Train Acc: 0.8780\n",
      "[250/318] Loss: 0.3877 Train Acc: 0.8802\n",
      "[260/318] Loss: 0.3845 Train Acc: 0.8784\n",
      "[270/318] Loss: 0.3511 Train Acc: 0.8865\n",
      "[280/318] Loss: 0.3930 Train Acc: 0.8779\n",
      "[290/318] Loss: 0.3791 Train Acc: 0.8780\n",
      "[300/318] Loss: 0.3603 Train Acc: 0.8824\n",
      "[310/318] Loss: 0.3985 Train Acc: 0.8750\n",
      "Epoch: 01, Test IoU: 0.5659, Time: 102.34s\n",
      "[10/318] Loss: 0.4618 Train Acc: 0.8537\n",
      "[20/318] Loss: 0.4062 Train Acc: 0.8700\n",
      "[30/318] Loss: 0.3746 Train Acc: 0.8813\n",
      "[40/318] Loss: 0.3908 Train Acc: 0.8759\n",
      "[50/318] Loss: 0.3735 Train Acc: 0.8839\n",
      "[60/318] Loss: 0.3704 Train Acc: 0.8820\n",
      "[70/318] Loss: 0.3674 Train Acc: 0.8827\n",
      "[80/318] Loss: 0.3479 Train Acc: 0.8877\n",
      "[90/318] Loss: 0.3740 Train Acc: 0.8816\n",
      "[100/318] Loss: 0.3933 Train Acc: 0.8702\n",
      "[110/318] Loss: 0.3737 Train Acc: 0.8786\n",
      "[120/318] Loss: 0.3695 Train Acc: 0.8844\n",
      "[130/318] Loss: 0.3667 Train Acc: 0.8829\n",
      "[140/318] Loss: 0.3672 Train Acc: 0.8829\n",
      "[150/318] Loss: 0.3541 Train Acc: 0.8855\n",
      "[160/318] Loss: 0.3388 Train Acc: 0.8909\n",
      "[170/318] Loss: 0.3425 Train Acc: 0.8916\n",
      "[180/318] Loss: 0.3269 Train Acc: 0.8971\n",
      "[190/318] Loss: 0.3390 Train Acc: 0.8907\n",
      "[200/318] Loss: 0.3610 Train Acc: 0.8847\n",
      "[210/318] Loss: 0.3425 Train Acc: 0.8897\n",
      "[220/318] Loss: 0.3756 Train Acc: 0.8765\n",
      "[230/318] Loss: 0.3398 Train Acc: 0.8895\n",
      "[240/318] Loss: 0.3360 Train Acc: 0.8900\n",
      "[250/318] Loss: 0.3232 Train Acc: 0.8936\n",
      "[260/318] Loss: 0.3271 Train Acc: 0.8902\n",
      "[270/318] Loss: 0.3378 Train Acc: 0.8905\n",
      "[280/318] Loss: 0.3341 Train Acc: 0.8934\n",
      "[290/318] Loss: 0.3487 Train Acc: 0.8883\n",
      "[300/318] Loss: 0.3213 Train Acc: 0.8961\n",
      "[310/318] Loss: 0.3568 Train Acc: 0.8848\n",
      "Epoch: 02, Test IoU: 0.5950, Time: 114.78s\n",
      "[10/318] Loss: 0.3342 Train Acc: 0.8928\n",
      "[20/318] Loss: 0.3200 Train Acc: 0.8928\n",
      "[30/318] Loss: 0.3496 Train Acc: 0.8857\n",
      "[40/318] Loss: 0.3273 Train Acc: 0.8912\n",
      "[50/318] Loss: 0.3490 Train Acc: 0.8874\n",
      "[60/318] Loss: 0.2937 Train Acc: 0.9032\n",
      "[70/318] Loss: 0.3096 Train Acc: 0.8984\n",
      "[80/318] Loss: 0.3554 Train Acc: 0.8873\n",
      "[90/318] Loss: 0.3203 Train Acc: 0.8955\n",
      "[100/318] Loss: 0.3203 Train Acc: 0.8970\n",
      "[110/318] Loss: 0.3012 Train Acc: 0.9008\n",
      "[120/318] Loss: 0.3086 Train Acc: 0.8999\n",
      "[130/318] Loss: 0.3153 Train Acc: 0.8952\n",
      "[140/318] Loss: 0.3111 Train Acc: 0.8988\n",
      "[150/318] Loss: 0.3391 Train Acc: 0.8921\n",
      "[160/318] Loss: 0.3227 Train Acc: 0.8934\n",
      "[170/318] Loss: 0.3138 Train Acc: 0.8974\n",
      "[180/318] Loss: 0.3237 Train Acc: 0.8969\n",
      "[190/318] Loss: 0.2964 Train Acc: 0.9049\n",
      "[200/318] Loss: 0.2873 Train Acc: 0.9072\n",
      "[210/318] Loss: 0.2990 Train Acc: 0.9030\n",
      "[220/318] Loss: 0.3050 Train Acc: 0.8980\n",
      "[230/318] Loss: 0.3110 Train Acc: 0.8956\n",
      "[240/318] Loss: 0.3057 Train Acc: 0.9012\n",
      "[250/318] Loss: 0.3421 Train Acc: 0.8881\n",
      "[260/318] Loss: 0.3403 Train Acc: 0.8911\n",
      "[270/318] Loss: 0.3001 Train Acc: 0.8997\n",
      "[280/318] Loss: 0.2826 Train Acc: 0.9080\n",
      "[290/318] Loss: 0.2827 Train Acc: 0.9077\n",
      "[300/318] Loss: 0.3225 Train Acc: 0.8975\n",
      "[310/318] Loss: 0.2864 Train Acc: 0.9082\n",
      "Epoch: 03, Test IoU: 0.5877, Time: 102.68s\n",
      "[10/318] Loss: 0.3899 Train Acc: 0.8685\n",
      "[20/318] Loss: 0.3571 Train Acc: 0.8868\n",
      "[30/318] Loss: 0.3385 Train Acc: 0.8930\n",
      "[40/318] Loss: 0.3102 Train Acc: 0.8989\n",
      "[50/318] Loss: 0.3041 Train Acc: 0.9002\n",
      "[60/318] Loss: 0.3297 Train Acc: 0.8942\n",
      "[70/318] Loss: 0.3353 Train Acc: 0.8899\n",
      "[80/318] Loss: 0.3265 Train Acc: 0.8926\n",
      "[90/318] Loss: 0.3162 Train Acc: 0.8960\n",
      "[100/318] Loss: 0.3082 Train Acc: 0.8979\n",
      "[110/318] Loss: 0.3054 Train Acc: 0.9013\n",
      "[120/318] Loss: 0.2866 Train Acc: 0.9034\n",
      "[130/318] Loss: 0.2896 Train Acc: 0.9028\n",
      "[140/318] Loss: 0.2788 Train Acc: 0.9076\n",
      "[150/318] Loss: 0.2831 Train Acc: 0.9088\n",
      "[160/318] Loss: 0.2760 Train Acc: 0.9078\n",
      "[170/318] Loss: 0.2944 Train Acc: 0.9030\n",
      "[180/318] Loss: 0.2767 Train Acc: 0.9105\n",
      "[190/318] Loss: 0.3055 Train Acc: 0.9016\n",
      "[200/318] Loss: 0.3051 Train Acc: 0.8999\n",
      "[210/318] Loss: 0.3150 Train Acc: 0.9015\n",
      "[220/318] Loss: 0.2777 Train Acc: 0.9096\n",
      "[230/318] Loss: 0.2831 Train Acc: 0.9090\n",
      "[240/318] Loss: 0.2814 Train Acc: 0.9101\n",
      "[250/318] Loss: 0.2818 Train Acc: 0.9077\n",
      "[260/318] Loss: 0.3059 Train Acc: 0.9017\n",
      "[270/318] Loss: 0.2928 Train Acc: 0.9041\n",
      "[280/318] Loss: 0.2809 Train Acc: 0.9109\n",
      "[290/318] Loss: 0.2740 Train Acc: 0.9097\n",
      "[300/318] Loss: 0.2767 Train Acc: 0.9100\n",
      "[310/318] Loss: 0.2815 Train Acc: 0.9078\n",
      "Epoch: 04, Test IoU: 0.6068, Time: 103.12s\n",
      "[10/318] Loss: 0.2883 Train Acc: 0.9064\n",
      "[20/318] Loss: 0.2818 Train Acc: 0.9074\n",
      "[30/318] Loss: 0.2809 Train Acc: 0.9063\n",
      "[40/318] Loss: 0.2428 Train Acc: 0.9186\n",
      "[50/318] Loss: 0.2770 Train Acc: 0.9088\n",
      "[60/318] Loss: 0.2700 Train Acc: 0.9119\n",
      "[70/318] Loss: 0.2639 Train Acc: 0.9133\n",
      "[80/318] Loss: 0.2854 Train Acc: 0.9083\n",
      "[90/318] Loss: 0.2660 Train Acc: 0.9155\n",
      "[100/318] Loss: 0.2825 Train Acc: 0.9103\n",
      "[110/318] Loss: 0.2668 Train Acc: 0.9119\n",
      "[120/318] Loss: 0.2975 Train Acc: 0.9015\n",
      "[130/318] Loss: 0.2835 Train Acc: 0.9064\n",
      "[140/318] Loss: 0.2398 Train Acc: 0.9219\n",
      "[150/318] Loss: 0.2492 Train Acc: 0.9197\n",
      "[160/318] Loss: 0.2606 Train Acc: 0.9149\n",
      "[170/318] Loss: 0.2685 Train Acc: 0.9127\n",
      "[180/318] Loss: 0.2574 Train Acc: 0.9141\n",
      "[190/318] Loss: 0.2579 Train Acc: 0.9152\n",
      "[200/318] Loss: 0.2629 Train Acc: 0.9153\n",
      "[210/318] Loss: 0.2555 Train Acc: 0.9146\n",
      "[220/318] Loss: 0.2493 Train Acc: 0.9180\n",
      "[230/318] Loss: 0.2628 Train Acc: 0.9144\n",
      "[240/318] Loss: 0.2764 Train Acc: 0.9096\n",
      "[250/318] Loss: 0.2678 Train Acc: 0.9133\n",
      "[260/318] Loss: 0.2515 Train Acc: 0.9188\n",
      "[270/318] Loss: 0.2703 Train Acc: 0.9159\n",
      "[280/318] Loss: 0.2370 Train Acc: 0.9232\n",
      "[290/318] Loss: 0.2601 Train Acc: 0.9137\n",
      "[300/318] Loss: 0.2410 Train Acc: 0.9187\n",
      "[310/318] Loss: 0.2721 Train Acc: 0.9129\n",
      "Epoch: 05, Test IoU: 0.6646, Time: 103.39s\n",
      "[10/318] Loss: 0.2542 Train Acc: 0.9142\n",
      "[20/318] Loss: 0.2566 Train Acc: 0.9174\n",
      "[30/318] Loss: 0.2840 Train Acc: 0.9084\n",
      "[40/318] Loss: 0.2621 Train Acc: 0.9144\n",
      "[50/318] Loss: 0.2521 Train Acc: 0.9191\n",
      "[60/318] Loss: 0.2511 Train Acc: 0.9163\n",
      "[70/318] Loss: 0.2588 Train Acc: 0.9151\n",
      "[80/318] Loss: 0.2381 Train Acc: 0.9198\n",
      "[90/318] Loss: 0.2477 Train Acc: 0.9173\n",
      "[100/318] Loss: 0.2424 Train Acc: 0.9199\n",
      "[110/318] Loss: 0.2596 Train Acc: 0.9135\n",
      "[120/318] Loss: 0.2508 Train Acc: 0.9168\n",
      "[130/318] Loss: 0.2466 Train Acc: 0.9186\n",
      "[140/318] Loss: 0.2562 Train Acc: 0.9165\n",
      "[150/318] Loss: 0.2578 Train Acc: 0.9165\n",
      "[160/318] Loss: 0.2735 Train Acc: 0.9103\n",
      "[170/318] Loss: 0.2576 Train Acc: 0.9191\n",
      "[180/318] Loss: 0.2257 Train Acc: 0.9258\n",
      "[190/318] Loss: 0.2432 Train Acc: 0.9193\n",
      "[200/318] Loss: 0.2263 Train Acc: 0.9270\n",
      "[210/318] Loss: 0.2401 Train Acc: 0.9197\n",
      "[220/318] Loss: 0.2331 Train Acc: 0.9226\n",
      "[230/318] Loss: 0.2508 Train Acc: 0.9189\n",
      "[240/318] Loss: 0.2536 Train Acc: 0.9164\n",
      "[250/318] Loss: 0.2634 Train Acc: 0.9139\n",
      "[260/318] Loss: 0.2389 Train Acc: 0.9233\n",
      "[270/318] Loss: 0.2345 Train Acc: 0.9230\n",
      "[280/318] Loss: 0.2233 Train Acc: 0.9284\n",
      "[290/318] Loss: 0.2479 Train Acc: 0.9167\n",
      "[300/318] Loss: 0.2496 Train Acc: 0.9184\n",
      "[310/318] Loss: 0.2383 Train Acc: 0.9214\n",
      "Epoch: 06, Test IoU: 0.6534, Time: 102.38s\n",
      "[10/318] Loss: 0.3419 Train Acc: 0.8899\n",
      "[20/318] Loss: 0.3432 Train Acc: 0.8908\n",
      "[30/318] Loss: 0.2981 Train Acc: 0.9028\n",
      "[40/318] Loss: 0.2692 Train Acc: 0.9136\n",
      "[50/318] Loss: 0.2823 Train Acc: 0.9067\n",
      "[60/318] Loss: 0.2637 Train Acc: 0.9140\n",
      "[70/318] Loss: 0.2541 Train Acc: 0.9162\n",
      "[80/318] Loss: 0.2542 Train Acc: 0.9142\n",
      "[90/318] Loss: 0.2214 Train Acc: 0.9254\n",
      "[100/318] Loss: 0.2314 Train Acc: 0.9216\n",
      "[110/318] Loss: 0.2391 Train Acc: 0.9202\n",
      "[120/318] Loss: 0.2698 Train Acc: 0.9167\n",
      "[130/318] Loss: 0.2566 Train Acc: 0.9164\n",
      "[140/318] Loss: 0.2573 Train Acc: 0.9161\n",
      "[150/318] Loss: 0.2459 Train Acc: 0.9191\n",
      "[160/318] Loss: 0.2401 Train Acc: 0.9199\n",
      "[170/318] Loss: 0.2513 Train Acc: 0.9167\n",
      "[180/318] Loss: 0.2314 Train Acc: 0.9225\n",
      "[190/318] Loss: 0.2324 Train Acc: 0.9244\n",
      "[200/318] Loss: 0.2458 Train Acc: 0.9190\n",
      "[210/318] Loss: 0.2428 Train Acc: 0.9202\n",
      "[220/318] Loss: 0.2387 Train Acc: 0.9203\n",
      "[230/318] Loss: 0.2319 Train Acc: 0.9220\n",
      "[240/318] Loss: 0.2227 Train Acc: 0.9264\n",
      "[250/318] Loss: 0.2158 Train Acc: 0.9295\n",
      "[260/318] Loss: 0.2415 Train Acc: 0.9193\n",
      "[270/318] Loss: 0.2450 Train Acc: 0.9189\n",
      "[280/318] Loss: 0.2143 Train Acc: 0.9311\n",
      "[290/318] Loss: 0.2497 Train Acc: 0.9219\n",
      "[300/318] Loss: 0.2316 Train Acc: 0.9242\n",
      "[310/318] Loss: 0.2075 Train Acc: 0.9316\n",
      "Epoch: 07, Test IoU: 0.6676, Time: 102.35s\n",
      "[10/318] Loss: 0.3757 Train Acc: 0.8825\n",
      "[20/318] Loss: 0.3667 Train Acc: 0.8786\n",
      "[30/318] Loss: 0.3084 Train Acc: 0.8996\n",
      "[40/318] Loss: 0.2743 Train Acc: 0.9111\n",
      "[50/318] Loss: 0.2893 Train Acc: 0.9050\n",
      "[60/318] Loss: 0.2496 Train Acc: 0.9188\n",
      "[70/318] Loss: 0.2411 Train Acc: 0.9209\n",
      "[80/318] Loss: 0.2241 Train Acc: 0.9254\n",
      "[90/318] Loss: 0.2159 Train Acc: 0.9287\n",
      "[100/318] Loss: 0.2415 Train Acc: 0.9191\n",
      "[110/318] Loss: 0.2550 Train Acc: 0.9142\n",
      "[120/318] Loss: 0.2346 Train Acc: 0.9204\n",
      "[130/318] Loss: 0.2300 Train Acc: 0.9232\n",
      "[140/318] Loss: 0.2427 Train Acc: 0.9210\n",
      "[150/318] Loss: 0.2285 Train Acc: 0.9232\n",
      "[160/318] Loss: 0.2168 Train Acc: 0.9299\n",
      "[170/318] Loss: 0.2059 Train Acc: 0.9294\n",
      "[180/318] Loss: 0.2272 Train Acc: 0.9238\n",
      "[190/318] Loss: 0.2151 Train Acc: 0.9285\n",
      "[200/318] Loss: 0.2180 Train Acc: 0.9266\n",
      "[210/318] Loss: 0.2215 Train Acc: 0.9258\n",
      "[220/318] Loss: 0.2210 Train Acc: 0.9264\n",
      "[230/318] Loss: 0.2055 Train Acc: 0.9322\n",
      "[240/318] Loss: 0.2265 Train Acc: 0.9282\n",
      "[250/318] Loss: 0.2048 Train Acc: 0.9364\n",
      "[260/318] Loss: 0.2304 Train Acc: 0.9233\n",
      "[270/318] Loss: 0.2284 Train Acc: 0.9230\n",
      "[280/318] Loss: 0.2444 Train Acc: 0.9198\n",
      "[290/318] Loss: 0.2087 Train Acc: 0.9317\n",
      "[300/318] Loss: 0.2254 Train Acc: 0.9251\n",
      "[310/318] Loss: 0.2306 Train Acc: 0.9242\n",
      "Epoch: 08, Test IoU: 0.6841, Time: 102.60s\n",
      "[10/318] Loss: 0.3024 Train Acc: 0.9063\n",
      "[20/318] Loss: 0.2807 Train Acc: 0.9105\n",
      "[30/318] Loss: 0.2442 Train Acc: 0.9172\n",
      "[40/318] Loss: 0.2443 Train Acc: 0.9205\n",
      "[50/318] Loss: 0.2363 Train Acc: 0.9216\n",
      "[60/318] Loss: 0.2435 Train Acc: 0.9208\n",
      "[70/318] Loss: 0.2270 Train Acc: 0.9254\n",
      "[80/318] Loss: 0.2188 Train Acc: 0.9311\n",
      "[90/318] Loss: 0.2219 Train Acc: 0.9272\n",
      "[100/318] Loss: 0.1957 Train Acc: 0.9346\n",
      "[110/318] Loss: 0.2145 Train Acc: 0.9308\n",
      "[120/318] Loss: 0.1986 Train Acc: 0.9339\n",
      "[130/318] Loss: 0.2143 Train Acc: 0.9266\n",
      "[140/318] Loss: 0.2170 Train Acc: 0.9281\n",
      "[150/318] Loss: 0.2170 Train Acc: 0.9292\n",
      "[160/318] Loss: 0.2198 Train Acc: 0.9273\n",
      "[170/318] Loss: 0.2061 Train Acc: 0.9312\n",
      "[180/318] Loss: 0.2272 Train Acc: 0.9249\n",
      "[190/318] Loss: 0.2230 Train Acc: 0.9263\n",
      "[200/318] Loss: 0.2046 Train Acc: 0.9309\n",
      "[210/318] Loss: 0.2070 Train Acc: 0.9317\n",
      "[220/318] Loss: 0.2133 Train Acc: 0.9299\n",
      "[230/318] Loss: 0.2080 Train Acc: 0.9318\n",
      "[240/318] Loss: 0.2034 Train Acc: 0.9318\n",
      "[250/318] Loss: 0.1996 Train Acc: 0.9360\n",
      "[260/318] Loss: 0.1955 Train Acc: 0.9354\n",
      "[270/318] Loss: 0.1978 Train Acc: 0.9350\n",
      "[280/318] Loss: 0.2054 Train Acc: 0.9300\n",
      "[290/318] Loss: 0.2093 Train Acc: 0.9302\n",
      "[300/318] Loss: 0.2013 Train Acc: 0.9312\n",
      "[310/318] Loss: 0.2057 Train Acc: 0.9318\n",
      "Epoch: 09, Test IoU: 0.6910, Time: 102.49s\n",
      "[10/318] Loss: 0.2050 Train Acc: 0.9307\n",
      "[20/318] Loss: 0.2038 Train Acc: 0.9329\n",
      "[30/318] Loss: 0.2006 Train Acc: 0.9317\n",
      "[40/318] Loss: 0.2007 Train Acc: 0.9335\n",
      "[50/318] Loss: 0.1866 Train Acc: 0.9375\n",
      "[60/318] Loss: 0.1807 Train Acc: 0.9400\n",
      "[70/318] Loss: 0.1832 Train Acc: 0.9391\n",
      "[80/318] Loss: 0.1951 Train Acc: 0.9372\n",
      "[90/318] Loss: 0.2129 Train Acc: 0.9279\n",
      "[100/318] Loss: 0.1915 Train Acc: 0.9353\n",
      "[110/318] Loss: 0.1883 Train Acc: 0.9368\n",
      "[120/318] Loss: 0.2090 Train Acc: 0.9275\n",
      "[130/318] Loss: 0.1841 Train Acc: 0.9393\n",
      "[140/318] Loss: 0.1886 Train Acc: 0.9398\n",
      "[150/318] Loss: 0.1808 Train Acc: 0.9415\n",
      "[160/318] Loss: 0.1821 Train Acc: 0.9393\n",
      "[170/318] Loss: 0.1929 Train Acc: 0.9355\n",
      "[180/318] Loss: 0.1858 Train Acc: 0.9372\n",
      "[190/318] Loss: 0.1837 Train Acc: 0.9391\n",
      "[200/318] Loss: 0.1862 Train Acc: 0.9377\n",
      "[210/318] Loss: 0.2082 Train Acc: 0.9314\n",
      "[220/318] Loss: 0.1807 Train Acc: 0.9399\n",
      "[230/318] Loss: 0.1988 Train Acc: 0.9345\n",
      "[240/318] Loss: 0.1900 Train Acc: 0.9358\n",
      "[250/318] Loss: 0.1996 Train Acc: 0.9322\n",
      "[260/318] Loss: 0.2155 Train Acc: 0.9287\n",
      "[270/318] Loss: 0.2061 Train Acc: 0.9312\n",
      "[280/318] Loss: 0.1975 Train Acc: 0.9367\n",
      "[290/318] Loss: 0.2135 Train Acc: 0.9296\n",
      "[300/318] Loss: 0.2064 Train Acc: 0.9344\n",
      "[310/318] Loss: 0.2076 Train Acc: 0.9314\n",
      "Epoch: 10, Test IoU: 0.6392, Time: 102.73s\n",
      "[10/318] Loss: 0.2373 Train Acc: 0.9221\n",
      "[20/318] Loss: 0.2407 Train Acc: 0.9223\n",
      "[30/318] Loss: 0.2429 Train Acc: 0.9204\n",
      "[40/318] Loss: 0.2086 Train Acc: 0.9328\n",
      "[50/318] Loss: 0.2278 Train Acc: 0.9258\n",
      "[60/318] Loss: 0.1980 Train Acc: 0.9367\n",
      "[70/318] Loss: 0.2125 Train Acc: 0.9290\n",
      "[80/318] Loss: 0.1944 Train Acc: 0.9362\n",
      "[90/318] Loss: 0.2029 Train Acc: 0.9324\n",
      "[100/318] Loss: 0.1900 Train Acc: 0.9382\n",
      "[110/318] Loss: 0.1744 Train Acc: 0.9433\n",
      "[120/318] Loss: 0.1934 Train Acc: 0.9360\n",
      "[130/318] Loss: 0.2001 Train Acc: 0.9342\n",
      "[140/318] Loss: 0.1965 Train Acc: 0.9346\n",
      "[150/318] Loss: 0.1925 Train Acc: 0.9359\n",
      "[160/318] Loss: 0.1705 Train Acc: 0.9434\n",
      "[170/318] Loss: 0.1609 Train Acc: 0.9470\n",
      "[180/318] Loss: 0.1730 Train Acc: 0.9430\n",
      "[190/318] Loss: 0.1811 Train Acc: 0.9403\n",
      "[200/318] Loss: 0.1846 Train Acc: 0.9391\n",
      "[210/318] Loss: 0.1758 Train Acc: 0.9412\n",
      "[220/318] Loss: 0.1965 Train Acc: 0.9341\n",
      "[230/318] Loss: 0.1963 Train Acc: 0.9331\n",
      "[240/318] Loss: 0.1817 Train Acc: 0.9396\n",
      "[250/318] Loss: 0.1926 Train Acc: 0.9367\n",
      "[260/318] Loss: 0.1980 Train Acc: 0.9371\n",
      "[270/318] Loss: 0.1964 Train Acc: 0.9381\n",
      "[280/318] Loss: 0.1760 Train Acc: 0.9402\n",
      "[290/318] Loss: 0.1870 Train Acc: 0.9377\n",
      "[300/318] Loss: 0.1830 Train Acc: 0.9402\n",
      "[310/318] Loss: 0.1966 Train Acc: 0.9338\n",
      "Epoch: 11, Test IoU: 0.6723, Time: 102.74s\n",
      "[10/318] Loss: 0.2626 Train Acc: 0.9155\n",
      "[20/318] Loss: 0.2557 Train Acc: 0.9172\n",
      "[30/318] Loss: 0.2187 Train Acc: 0.9307\n",
      "[40/318] Loss: 0.1999 Train Acc: 0.9339\n",
      "[50/318] Loss: 0.1918 Train Acc: 0.9359\n",
      "[60/318] Loss: 0.1880 Train Acc: 0.9360\n",
      "[70/318] Loss: 0.2004 Train Acc: 0.9327\n",
      "[80/318] Loss: 0.1784 Train Acc: 0.9400\n",
      "[90/318] Loss: 0.1964 Train Acc: 0.9364\n",
      "[100/318] Loss: 0.1814 Train Acc: 0.9406\n",
      "[110/318] Loss: 0.1917 Train Acc: 0.9361\n",
      "[120/318] Loss: 0.1547 Train Acc: 0.9487\n",
      "[130/318] Loss: 0.1734 Train Acc: 0.9415\n",
      "[140/318] Loss: 0.1694 Train Acc: 0.9441\n",
      "[150/318] Loss: 0.1822 Train Acc: 0.9385\n",
      "[160/318] Loss: 0.2058 Train Acc: 0.9341\n",
      "[170/318] Loss: 0.1890 Train Acc: 0.9367\n",
      "[180/318] Loss: 0.1853 Train Acc: 0.9381\n",
      "[190/318] Loss: 0.1718 Train Acc: 0.9437\n",
      "[200/318] Loss: 0.1782 Train Acc: 0.9396\n",
      "[210/318] Loss: 0.1761 Train Acc: 0.9422\n",
      "[220/318] Loss: 0.1754 Train Acc: 0.9411\n",
      "[230/318] Loss: 0.1938 Train Acc: 0.9362\n",
      "[240/318] Loss: 0.1695 Train Acc: 0.9424\n",
      "[250/318] Loss: 0.1794 Train Acc: 0.9405\n",
      "[260/318] Loss: 0.2207 Train Acc: 0.9270\n",
      "[270/318] Loss: 0.1766 Train Acc: 0.9434\n",
      "[280/318] Loss: 0.1826 Train Acc: 0.9376\n",
      "[290/318] Loss: 0.1721 Train Acc: 0.9445\n",
      "[300/318] Loss: 0.1694 Train Acc: 0.9448\n",
      "[310/318] Loss: 0.1824 Train Acc: 0.9386\n",
      "Epoch: 12, Test IoU: 0.6873, Time: 102.36s\n",
      "[10/318] Loss: 0.1972 Train Acc: 0.9336\n",
      "[20/318] Loss: 0.1901 Train Acc: 0.9371\n",
      "[30/318] Loss: 0.2036 Train Acc: 0.9365\n",
      "[40/318] Loss: 0.1929 Train Acc: 0.9336\n",
      "[50/318] Loss: 0.1925 Train Acc: 0.9375\n",
      "[60/318] Loss: 0.1777 Train Acc: 0.9404\n",
      "[70/318] Loss: 0.1670 Train Acc: 0.9436\n",
      "[80/318] Loss: 0.1658 Train Acc: 0.9432\n",
      "[90/318] Loss: 0.1726 Train Acc: 0.9418\n",
      "[100/318] Loss: 0.1734 Train Acc: 0.9434\n",
      "[110/318] Loss: 0.1647 Train Acc: 0.9452\n",
      "[120/318] Loss: 0.1861 Train Acc: 0.9408\n",
      "[130/318] Loss: 0.1652 Train Acc: 0.9436\n",
      "[140/318] Loss: 0.1640 Train Acc: 0.9454\n",
      "[150/318] Loss: 0.1642 Train Acc: 0.9447\n",
      "[160/318] Loss: 0.1815 Train Acc: 0.9397\n",
      "[170/318] Loss: 0.1776 Train Acc: 0.9403\n",
      "[180/318] Loss: 0.1806 Train Acc: 0.9394\n",
      "[190/318] Loss: 0.1639 Train Acc: 0.9462\n",
      "[200/318] Loss: 0.1572 Train Acc: 0.9480\n",
      "[210/318] Loss: 0.1662 Train Acc: 0.9456\n",
      "[220/318] Loss: 0.1788 Train Acc: 0.9402\n",
      "[230/318] Loss: 0.1600 Train Acc: 0.9466\n",
      "[240/318] Loss: 0.1709 Train Acc: 0.9432\n",
      "[250/318] Loss: 0.1879 Train Acc: 0.9392\n",
      "[260/318] Loss: 0.1822 Train Acc: 0.9385\n",
      "[270/318] Loss: 0.1923 Train Acc: 0.9349\n",
      "[280/318] Loss: 0.1679 Train Acc: 0.9439\n",
      "[290/318] Loss: 0.1841 Train Acc: 0.9420\n",
      "[300/318] Loss: 0.1807 Train Acc: 0.9392\n",
      "[310/318] Loss: 0.1638 Train Acc: 0.9464\n",
      "Epoch: 13, Test IoU: 0.6843, Time: 102.72s\n",
      "[10/318] Loss: 0.2306 Train Acc: 0.9224\n",
      "[20/318] Loss: 0.2078 Train Acc: 0.9322\n",
      "[30/318] Loss: 0.1928 Train Acc: 0.9363\n",
      "[40/318] Loss: 0.1780 Train Acc: 0.9410\n",
      "[50/318] Loss: 0.1857 Train Acc: 0.9375\n",
      "[60/318] Loss: 0.1769 Train Acc: 0.9417\n",
      "[70/318] Loss: 0.1668 Train Acc: 0.9437\n",
      "[80/318] Loss: 0.1693 Train Acc: 0.9424\n",
      "[90/318] Loss: 0.1762 Train Acc: 0.9405\n",
      "[100/318] Loss: 0.1723 Train Acc: 0.9426\n",
      "[110/318] Loss: 0.1708 Train Acc: 0.9425\n",
      "[120/318] Loss: 0.1739 Train Acc: 0.9426\n",
      "[130/318] Loss: 0.1579 Train Acc: 0.9472\n",
      "[140/318] Loss: 0.1591 Train Acc: 0.9466\n",
      "[150/318] Loss: 0.1588 Train Acc: 0.9472\n",
      "[160/318] Loss: 0.1535 Train Acc: 0.9489\n",
      "[170/318] Loss: 0.1529 Train Acc: 0.9491\n",
      "[180/318] Loss: 0.1685 Train Acc: 0.9445\n",
      "[190/318] Loss: 0.1716 Train Acc: 0.9433\n",
      "[200/318] Loss: 0.1679 Train Acc: 0.9448\n",
      "[210/318] Loss: 0.1666 Train Acc: 0.9460\n",
      "[220/318] Loss: 0.1664 Train Acc: 0.9460\n",
      "[230/318] Loss: 0.1763 Train Acc: 0.9425\n",
      "[240/318] Loss: 0.1575 Train Acc: 0.9469\n",
      "[250/318] Loss: 0.1842 Train Acc: 0.9369\n",
      "[260/318] Loss: 0.1763 Train Acc: 0.9416\n",
      "[270/318] Loss: 0.1634 Train Acc: 0.9447\n",
      "[280/318] Loss: 0.1592 Train Acc: 0.9475\n",
      "[290/318] Loss: 0.1705 Train Acc: 0.9423\n",
      "[300/318] Loss: 0.1544 Train Acc: 0.9473\n",
      "[310/318] Loss: 0.1685 Train Acc: 0.9423\n",
      "Epoch: 14, Test IoU: 0.7038, Time: 102.51s\n",
      "[10/318] Loss: 0.3694 Train Acc: 0.8801\n",
      "[20/318] Loss: 0.3571 Train Acc: 0.8830\n",
      "[30/318] Loss: 0.3133 Train Acc: 0.8993\n",
      "[40/318] Loss: 0.2781 Train Acc: 0.9090\n",
      "[50/318] Loss: 0.2706 Train Acc: 0.9136\n",
      "[60/318] Loss: 0.2541 Train Acc: 0.9163\n",
      "[70/318] Loss: 0.2305 Train Acc: 0.9248\n",
      "[80/318] Loss: 0.1988 Train Acc: 0.9320\n",
      "[90/318] Loss: 0.2228 Train Acc: 0.9258\n",
      "[100/318] Loss: 0.1901 Train Acc: 0.9369\n",
      "[110/318] Loss: 0.2087 Train Acc: 0.9298\n",
      "[120/318] Loss: 0.2235 Train Acc: 0.9287\n",
      "[130/318] Loss: 0.1976 Train Acc: 0.9346\n",
      "[140/318] Loss: 0.1925 Train Acc: 0.9337\n",
      "[150/318] Loss: 0.1877 Train Acc: 0.9375\n",
      "[160/318] Loss: 0.1921 Train Acc: 0.9370\n",
      "[170/318] Loss: 0.1769 Train Acc: 0.9433\n",
      "[180/318] Loss: 0.1774 Train Acc: 0.9393\n",
      "[190/318] Loss: 0.1888 Train Acc: 0.9368\n",
      "[200/318] Loss: 0.1709 Train Acc: 0.9426\n",
      "[210/318] Loss: 0.1774 Train Acc: 0.9405\n",
      "[220/318] Loss: 0.1875 Train Acc: 0.9349\n",
      "[230/318] Loss: 0.1667 Train Acc: 0.9434\n",
      "[240/318] Loss: 0.1732 Train Acc: 0.9416\n",
      "[250/318] Loss: 0.1571 Train Acc: 0.9473\n",
      "[260/318] Loss: 0.1651 Train Acc: 0.9446\n",
      "[270/318] Loss: 0.1706 Train Acc: 0.9423\n",
      "[280/318] Loss: 0.1648 Train Acc: 0.9436\n",
      "[290/318] Loss: 0.1666 Train Acc: 0.9454\n",
      "[300/318] Loss: 0.1711 Train Acc: 0.9424\n",
      "[310/318] Loss: 0.1599 Train Acc: 0.9459\n",
      "Epoch: 15, Test IoU: 0.6995, Time: 113.81s\n",
      "[10/318] Loss: 0.3147 Train Acc: 0.9058\n",
      "[20/318] Loss: 0.2908 Train Acc: 0.9060\n",
      "[30/318] Loss: 0.2345 Train Acc: 0.9236\n",
      "[40/318] Loss: 0.2264 Train Acc: 0.9253\n",
      "[50/318] Loss: 0.1979 Train Acc: 0.9324\n",
      "[60/318] Loss: 0.1885 Train Acc: 0.9372\n",
      "[70/318] Loss: 0.1828 Train Acc: 0.9391\n",
      "[80/318] Loss: 0.1676 Train Acc: 0.9443\n",
      "[90/318] Loss: 0.1701 Train Acc: 0.9441\n",
      "[100/318] Loss: 0.1694 Train Acc: 0.9435\n",
      "[110/318] Loss: 0.1688 Train Acc: 0.9423\n",
      "[120/318] Loss: 0.1566 Train Acc: 0.9474\n",
      "[130/318] Loss: 0.1622 Train Acc: 0.9459\n",
      "[140/318] Loss: 0.1751 Train Acc: 0.9402\n",
      "[150/318] Loss: 0.1851 Train Acc: 0.9378\n",
      "[160/318] Loss: 0.1552 Train Acc: 0.9462\n",
      "[170/318] Loss: 0.1611 Train Acc: 0.9464\n",
      "[180/318] Loss: 0.1557 Train Acc: 0.9470\n",
      "[190/318] Loss: 0.1488 Train Acc: 0.9500\n",
      "[200/318] Loss: 0.1772 Train Acc: 0.9411\n",
      "[210/318] Loss: 0.1423 Train Acc: 0.9522\n",
      "[220/318] Loss: 0.1446 Train Acc: 0.9493\n",
      "[230/318] Loss: 0.1671 Train Acc: 0.9451\n",
      "[240/318] Loss: 0.1558 Train Acc: 0.9461\n",
      "[250/318] Loss: 0.1662 Train Acc: 0.9454\n",
      "[260/318] Loss: 0.1681 Train Acc: 0.9425\n",
      "[270/318] Loss: 0.1594 Train Acc: 0.9460\n",
      "[280/318] Loss: 0.1696 Train Acc: 0.9439\n",
      "[290/318] Loss: 0.1510 Train Acc: 0.9503\n",
      "[300/318] Loss: 0.1453 Train Acc: 0.9516\n",
      "[310/318] Loss: 0.1520 Train Acc: 0.9485\n",
      "Epoch: 16, Test IoU: 0.6794, Time: 102.87s\n",
      "[10/318] Loss: 0.3629 Train Acc: 0.8941\n",
      "[20/318] Loss: 0.4147 Train Acc: 0.8851\n",
      "[30/318] Loss: 0.3826 Train Acc: 0.8765\n",
      "[40/318] Loss: 0.3357 Train Acc: 0.8911\n",
      "[50/318] Loss: 0.3066 Train Acc: 0.9030\n",
      "[60/318] Loss: 0.2986 Train Acc: 0.9040\n",
      "[70/318] Loss: 0.2425 Train Acc: 0.9217\n",
      "[80/318] Loss: 0.2100 Train Acc: 0.9319\n",
      "[90/318] Loss: 0.2250 Train Acc: 0.9278\n",
      "[100/318] Loss: 0.2060 Train Acc: 0.9310\n",
      "[110/318] Loss: 0.1898 Train Acc: 0.9363\n",
      "[120/318] Loss: 0.1745 Train Acc: 0.9426\n",
      "[130/318] Loss: 0.1719 Train Acc: 0.9436\n",
      "[140/318] Loss: 0.1692 Train Acc: 0.9445\n",
      "[150/318] Loss: 0.1913 Train Acc: 0.9353\n",
      "[160/318] Loss: 0.1768 Train Acc: 0.9409\n",
      "[170/318] Loss: 0.1781 Train Acc: 0.9408\n",
      "[180/318] Loss: 0.1745 Train Acc: 0.9412\n",
      "[190/318] Loss: 0.1541 Train Acc: 0.9487\n",
      "[200/318] Loss: 0.1798 Train Acc: 0.9405\n",
      "[210/318] Loss: 0.1782 Train Acc: 0.9401\n",
      "[220/318] Loss: 0.1674 Train Acc: 0.9418\n",
      "[230/318] Loss: 0.1623 Train Acc: 0.9458\n",
      "[240/318] Loss: 0.1685 Train Acc: 0.9457\n",
      "[250/318] Loss: 0.1703 Train Acc: 0.9438\n",
      "[260/318] Loss: 0.1569 Train Acc: 0.9481\n",
      "[270/318] Loss: 0.1608 Train Acc: 0.9450\n",
      "[280/318] Loss: 0.1522 Train Acc: 0.9494\n",
      "[290/318] Loss: 0.1569 Train Acc: 0.9471\n",
      "[300/318] Loss: 0.1553 Train Acc: 0.9481\n",
      "[310/318] Loss: 0.1668 Train Acc: 0.9451\n",
      "Epoch: 17, Test IoU: 0.7199, Time: 102.58s\n",
      "[10/318] Loss: 0.1706 Train Acc: 0.9418\n",
      "[20/318] Loss: 0.1654 Train Acc: 0.9445\n",
      "[30/318] Loss: 0.1576 Train Acc: 0.9473\n",
      "[40/318] Loss: 0.1474 Train Acc: 0.9513\n",
      "[50/318] Loss: 0.1561 Train Acc: 0.9467\n",
      "[60/318] Loss: 0.1456 Train Acc: 0.9506\n",
      "[70/318] Loss: 0.1457 Train Acc: 0.9513\n",
      "[80/318] Loss: 0.1500 Train Acc: 0.9484\n",
      "[90/318] Loss: 0.1453 Train Acc: 0.9509\n",
      "[100/318] Loss: 0.1395 Train Acc: 0.9527\n",
      "[110/318] Loss: 0.1474 Train Acc: 0.9495\n",
      "[120/318] Loss: 0.1482 Train Acc: 0.9490\n",
      "[130/318] Loss: 0.1431 Train Acc: 0.9521\n",
      "[140/318] Loss: 0.1292 Train Acc: 0.9564\n",
      "[150/318] Loss: 0.1449 Train Acc: 0.9519\n",
      "[160/318] Loss: 0.1531 Train Acc: 0.9501\n",
      "[170/318] Loss: 0.1447 Train Acc: 0.9508\n",
      "[180/318] Loss: 0.1477 Train Acc: 0.9513\n",
      "[190/318] Loss: 0.1434 Train Acc: 0.9517\n",
      "[200/318] Loss: 0.1512 Train Acc: 0.9506\n",
      "[210/318] Loss: 0.1664 Train Acc: 0.9464\n",
      "[220/318] Loss: 0.1573 Train Acc: 0.9484\n",
      "[230/318] Loss: 0.1498 Train Acc: 0.9505\n",
      "[240/318] Loss: 0.1507 Train Acc: 0.9504\n",
      "[250/318] Loss: 0.1497 Train Acc: 0.9502\n",
      "[260/318] Loss: 0.1404 Train Acc: 0.9532\n",
      "[270/318] Loss: 0.1489 Train Acc: 0.9493\n",
      "[280/318] Loss: 0.1420 Train Acc: 0.9526\n",
      "[290/318] Loss: 0.1505 Train Acc: 0.9493\n",
      "[300/318] Loss: 0.1452 Train Acc: 0.9500\n",
      "[310/318] Loss: 0.1557 Train Acc: 0.9473\n",
      "Epoch: 18, Test IoU: 0.7113, Time: 102.56s\n",
      "[10/318] Loss: 0.2083 Train Acc: 0.9310\n",
      "[20/318] Loss: 0.2109 Train Acc: 0.9290\n",
      "[30/318] Loss: 0.2000 Train Acc: 0.9353\n",
      "[40/318] Loss: 0.1975 Train Acc: 0.9344\n",
      "[50/318] Loss: 0.1765 Train Acc: 0.9396\n",
      "[60/318] Loss: 0.1621 Train Acc: 0.9454\n",
      "[70/318] Loss: 0.1720 Train Acc: 0.9424\n",
      "[80/318] Loss: 0.1554 Train Acc: 0.9481\n",
      "[90/318] Loss: 0.1433 Train Acc: 0.9524\n",
      "[100/318] Loss: 0.1650 Train Acc: 0.9432\n",
      "[110/318] Loss: 0.1512 Train Acc: 0.9476\n",
      "[120/318] Loss: 0.1559 Train Acc: 0.9466\n",
      "[130/318] Loss: 0.1563 Train Acc: 0.9482\n",
      "[140/318] Loss: 0.1349 Train Acc: 0.9549\n",
      "[150/318] Loss: 0.1560 Train Acc: 0.9479\n",
      "[160/318] Loss: 0.1561 Train Acc: 0.9470\n",
      "[170/318] Loss: 0.1318 Train Acc: 0.9554\n",
      "[180/318] Loss: 0.1487 Train Acc: 0.9495\n",
      "[190/318] Loss: 0.1453 Train Acc: 0.9492\n",
      "[200/318] Loss: 0.1446 Train Acc: 0.9505\n",
      "[210/318] Loss: 0.1330 Train Acc: 0.9539\n",
      "[220/318] Loss: 0.1350 Train Acc: 0.9539\n",
      "[230/318] Loss: 0.1392 Train Acc: 0.9523\n",
      "[240/318] Loss: 0.1362 Train Acc: 0.9525\n",
      "[250/318] Loss: 0.1360 Train Acc: 0.9540\n",
      "[260/318] Loss: 0.1300 Train Acc: 0.9558\n",
      "[270/318] Loss: 0.1345 Train Acc: 0.9553\n",
      "[280/318] Loss: 0.1290 Train Acc: 0.9556\n",
      "[290/318] Loss: 0.1341 Train Acc: 0.9531\n",
      "[300/318] Loss: 0.1349 Train Acc: 0.9544\n",
      "[310/318] Loss: 0.1480 Train Acc: 0.9503\n",
      "Epoch: 19, Test IoU: 0.7160, Time: 102.76s\n",
      "[10/318] Loss: 0.1916 Train Acc: 0.9380\n",
      "[20/318] Loss: 0.1800 Train Acc: 0.9409\n",
      "[30/318] Loss: 0.1589 Train Acc: 0.9457\n",
      "[40/318] Loss: 0.1617 Train Acc: 0.9440\n",
      "[50/318] Loss: 0.1562 Train Acc: 0.9474\n",
      "[60/318] Loss: 0.1336 Train Acc: 0.9539\n",
      "[70/318] Loss: 0.1472 Train Acc: 0.9508\n",
      "[80/318] Loss: 0.1353 Train Acc: 0.9534\n",
      "[90/318] Loss: 0.1495 Train Acc: 0.9513\n",
      "[100/318] Loss: 0.1311 Train Acc: 0.9568\n",
      "[110/318] Loss: 0.1386 Train Acc: 0.9538\n",
      "[120/318] Loss: 0.1402 Train Acc: 0.9521\n",
      "[130/318] Loss: 0.1392 Train Acc: 0.9529\n",
      "[140/318] Loss: 0.1400 Train Acc: 0.9526\n",
      "[150/318] Loss: 0.1311 Train Acc: 0.9561\n",
      "[160/318] Loss: 0.1337 Train Acc: 0.9544\n",
      "[170/318] Loss: 0.1404 Train Acc: 0.9532\n",
      "[180/318] Loss: 0.1270 Train Acc: 0.9564\n",
      "[190/318] Loss: 0.1497 Train Acc: 0.9501\n",
      "[200/318] Loss: 0.1416 Train Acc: 0.9510\n",
      "[210/318] Loss: 0.1275 Train Acc: 0.9566\n",
      "[220/318] Loss: 0.1392 Train Acc: 0.9529\n",
      "[230/318] Loss: 0.1511 Train Acc: 0.9502\n",
      "[240/318] Loss: 0.1365 Train Acc: 0.9538\n",
      "[250/318] Loss: 0.1323 Train Acc: 0.9559\n",
      "[260/318] Loss: 0.1338 Train Acc: 0.9542\n",
      "[270/318] Loss: 0.1399 Train Acc: 0.9522\n",
      "[280/318] Loss: 0.1300 Train Acc: 0.9567\n",
      "[290/318] Loss: 0.1241 Train Acc: 0.9575\n",
      "[300/318] Loss: 0.1293 Train Acc: 0.9564\n",
      "[310/318] Loss: 0.1375 Train Acc: 0.9537\n",
      "Epoch: 20, Test IoU: 0.7255, Time: 102.51s\n",
      "[10/318] Loss: 0.2423 Train Acc: 0.9178\n",
      "[20/318] Loss: 0.2177 Train Acc: 0.9325\n",
      "[30/318] Loss: 0.2109 Train Acc: 0.9352\n",
      "[40/318] Loss: 0.1786 Train Acc: 0.9426\n",
      "[50/318] Loss: 0.1617 Train Acc: 0.9452\n",
      "[60/318] Loss: 0.1738 Train Acc: 0.9408\n",
      "[70/318] Loss: 0.1605 Train Acc: 0.9464\n",
      "[80/318] Loss: 0.1627 Train Acc: 0.9451\n",
      "[90/318] Loss: 0.1419 Train Acc: 0.9516\n",
      "[100/318] Loss: 0.1369 Train Acc: 0.9534\n",
      "[110/318] Loss: 0.1390 Train Acc: 0.9531\n",
      "[120/318] Loss: 0.1489 Train Acc: 0.9515\n",
      "[130/318] Loss: 0.1422 Train Acc: 0.9523\n",
      "[140/318] Loss: 0.1450 Train Acc: 0.9514\n",
      "[150/318] Loss: 0.1344 Train Acc: 0.9548\n",
      "[160/318] Loss: 0.1329 Train Acc: 0.9551\n",
      "[170/318] Loss: 0.1357 Train Acc: 0.9543\n",
      "[180/318] Loss: 0.1322 Train Acc: 0.9549\n",
      "[190/318] Loss: 0.1335 Train Acc: 0.9544\n",
      "[200/318] Loss: 0.1499 Train Acc: 0.9506\n",
      "[210/318] Loss: 0.1319 Train Acc: 0.9553\n",
      "[220/318] Loss: 0.1408 Train Acc: 0.9521\n",
      "[230/318] Loss: 0.1331 Train Acc: 0.9556\n",
      "[240/318] Loss: 0.1342 Train Acc: 0.9560\n",
      "[250/318] Loss: 0.1373 Train Acc: 0.9534\n",
      "[260/318] Loss: 0.1363 Train Acc: 0.9535\n",
      "[270/318] Loss: 0.1353 Train Acc: 0.9535\n",
      "[280/318] Loss: 0.1438 Train Acc: 0.9506\n",
      "[290/318] Loss: 0.1276 Train Acc: 0.9568\n",
      "[300/318] Loss: 0.1301 Train Acc: 0.9549\n",
      "[310/318] Loss: 0.1309 Train Acc: 0.9558\n",
      "Epoch: 21, Test IoU: 0.6930, Time: 102.48s\n",
      "[10/318] Loss: 0.1925 Train Acc: 0.9381\n",
      "[20/318] Loss: 0.1937 Train Acc: 0.9361\n",
      "[30/318] Loss: 0.1855 Train Acc: 0.9388\n",
      "[40/318] Loss: 0.1653 Train Acc: 0.9444\n",
      "[50/318] Loss: 0.1667 Train Acc: 0.9438\n",
      "[60/318] Loss: 0.1525 Train Acc: 0.9495\n",
      "[70/318] Loss: 0.1545 Train Acc: 0.9497\n",
      "[80/318] Loss: 0.1396 Train Acc: 0.9533\n",
      "[90/318] Loss: 0.1341 Train Acc: 0.9549\n",
      "[100/318] Loss: 0.1437 Train Acc: 0.9506\n",
      "[110/318] Loss: 0.1500 Train Acc: 0.9493\n",
      "[120/318] Loss: 0.1378 Train Acc: 0.9531\n",
      "[130/318] Loss: 0.1430 Train Acc: 0.9514\n",
      "[140/318] Loss: 0.1367 Train Acc: 0.9528\n",
      "[150/318] Loss: 0.1351 Train Acc: 0.9545\n",
      "[160/318] Loss: 0.1228 Train Acc: 0.9588\n",
      "[170/318] Loss: 0.1366 Train Acc: 0.9540\n",
      "[180/318] Loss: 0.1354 Train Acc: 0.9550\n",
      "[190/318] Loss: 0.1232 Train Acc: 0.9577\n",
      "[200/318] Loss: 0.1375 Train Acc: 0.9533\n",
      "[210/318] Loss: 0.1250 Train Acc: 0.9566\n",
      "[220/318] Loss: 0.1273 Train Acc: 0.9570\n",
      "[230/318] Loss: 0.1276 Train Acc: 0.9567\n",
      "[240/318] Loss: 0.1309 Train Acc: 0.9556\n",
      "[250/318] Loss: 0.1265 Train Acc: 0.9561\n",
      "[260/318] Loss: 0.1328 Train Acc: 0.9537\n",
      "[270/318] Loss: 0.1434 Train Acc: 0.9519\n",
      "[280/318] Loss: 0.1340 Train Acc: 0.9539\n",
      "[290/318] Loss: 0.1258 Train Acc: 0.9585\n",
      "[300/318] Loss: 0.1268 Train Acc: 0.9581\n",
      "[310/318] Loss: 0.1345 Train Acc: 0.9538\n",
      "Epoch: 22, Test IoU: 0.7293, Time: 102.68s\n",
      "[10/318] Loss: 0.1815 Train Acc: 0.9411\n",
      "[20/318] Loss: 0.1652 Train Acc: 0.9437\n",
      "[30/318] Loss: 0.1557 Train Acc: 0.9466\n",
      "[40/318] Loss: 0.1519 Train Acc: 0.9485\n",
      "[50/318] Loss: 0.1455 Train Acc: 0.9504\n",
      "[60/318] Loss: 0.1335 Train Acc: 0.9543\n",
      "[70/318] Loss: 0.1305 Train Acc: 0.9555\n",
      "[80/318] Loss: 0.1412 Train Acc: 0.9536\n",
      "[90/318] Loss: 0.1304 Train Acc: 0.9553\n",
      "[100/318] Loss: 0.1245 Train Acc: 0.9575\n",
      "[110/318] Loss: 0.1216 Train Acc: 0.9584\n",
      "[120/318] Loss: 0.1295 Train Acc: 0.9553\n",
      "[130/318] Loss: 0.1214 Train Acc: 0.9590\n",
      "[140/318] Loss: 0.1134 Train Acc: 0.9612\n",
      "[150/318] Loss: 0.1220 Train Acc: 0.9591\n",
      "[160/318] Loss: 0.1215 Train Acc: 0.9596\n",
      "[170/318] Loss: 0.1186 Train Acc: 0.9606\n",
      "[180/318] Loss: 0.1320 Train Acc: 0.9546\n",
      "[190/318] Loss: 0.1266 Train Acc: 0.9577\n",
      "[200/318] Loss: 0.1382 Train Acc: 0.9538\n",
      "[210/318] Loss: 0.1322 Train Acc: 0.9541\n",
      "[220/318] Loss: 0.1253 Train Acc: 0.9571\n",
      "[230/318] Loss: 0.1145 Train Acc: 0.9611\n",
      "[240/318] Loss: 0.1260 Train Acc: 0.9570\n",
      "[250/318] Loss: 0.1221 Train Acc: 0.9577\n",
      "[260/318] Loss: 0.1235 Train Acc: 0.9575\n",
      "[270/318] Loss: 0.1206 Train Acc: 0.9585\n",
      "[280/318] Loss: 0.1201 Train Acc: 0.9582\n",
      "[290/318] Loss: 0.1338 Train Acc: 0.9543\n",
      "[300/318] Loss: 0.1239 Train Acc: 0.9573\n",
      "[310/318] Loss: 0.1170 Train Acc: 0.9591\n",
      "Epoch: 23, Test IoU: 0.7084, Time: 102.42s\n",
      "[10/318] Loss: 0.1328 Train Acc: 0.9550\n",
      "[20/318] Loss: 0.1352 Train Acc: 0.9544\n",
      "[30/318] Loss: 0.1286 Train Acc: 0.9559\n",
      "[40/318] Loss: 0.1221 Train Acc: 0.9607\n",
      "[50/318] Loss: 0.1213 Train Acc: 0.9585\n",
      "[60/318] Loss: 0.1372 Train Acc: 0.9551\n",
      "[70/318] Loss: 0.1381 Train Acc: 0.9530\n",
      "[80/318] Loss: 0.1322 Train Acc: 0.9558\n",
      "[90/318] Loss: 0.1268 Train Acc: 0.9578\n",
      "[100/318] Loss: 0.1329 Train Acc: 0.9552\n",
      "[110/318] Loss: 0.1241 Train Acc: 0.9578\n",
      "[120/318] Loss: 0.1208 Train Acc: 0.9576\n",
      "[130/318] Loss: 0.1208 Train Acc: 0.9588\n",
      "[140/318] Loss: 0.1136 Train Acc: 0.9612\n",
      "[150/318] Loss: 0.1284 Train Acc: 0.9557\n",
      "[160/318] Loss: 0.1235 Train Acc: 0.9583\n",
      "[170/318] Loss: 0.1245 Train Acc: 0.9582\n",
      "[180/318] Loss: 0.1230 Train Acc: 0.9588\n",
      "[190/318] Loss: 0.1229 Train Acc: 0.9579\n",
      "[200/318] Loss: 0.1215 Train Acc: 0.9587\n",
      "[210/318] Loss: 0.1168 Train Acc: 0.9601\n",
      "[220/318] Loss: 0.1165 Train Acc: 0.9592\n",
      "[230/318] Loss: 0.1197 Train Acc: 0.9591\n",
      "[240/318] Loss: 0.1192 Train Acc: 0.9584\n",
      "[250/318] Loss: 0.1152 Train Acc: 0.9597\n",
      "[260/318] Loss: 0.1164 Train Acc: 0.9614\n",
      "[270/318] Loss: 0.1256 Train Acc: 0.9582\n",
      "[280/318] Loss: 0.1162 Train Acc: 0.9603\n",
      "[290/318] Loss: 0.1234 Train Acc: 0.9572\n",
      "[300/318] Loss: 0.1240 Train Acc: 0.9573\n",
      "[310/318] Loss: 0.1288 Train Acc: 0.9551\n",
      "Epoch: 24, Test IoU: 0.7044, Time: 102.54s\n",
      "[10/318] Loss: 0.2465 Train Acc: 0.9266\n",
      "[20/318] Loss: 0.2305 Train Acc: 0.9256\n",
      "[30/318] Loss: 0.1739 Train Acc: 0.9416\n",
      "[40/318] Loss: 0.1796 Train Acc: 0.9412\n",
      "[50/318] Loss: 0.1752 Train Acc: 0.9416\n",
      "[60/318] Loss: 0.1781 Train Acc: 0.9400\n",
      "[70/318] Loss: 0.1491 Train Acc: 0.9493\n",
      "[80/318] Loss: 0.1434 Train Acc: 0.9511\n",
      "[90/318] Loss: 0.1369 Train Acc: 0.9529\n",
      "[100/318] Loss: 0.1501 Train Acc: 0.9476\n",
      "[110/318] Loss: 0.1479 Train Acc: 0.9493\n",
      "[120/318] Loss: 0.1408 Train Acc: 0.9522\n",
      "[130/318] Loss: 0.1339 Train Acc: 0.9554\n",
      "[140/318] Loss: 0.1274 Train Acc: 0.9571\n",
      "[150/318] Loss: 0.1229 Train Acc: 0.9581\n",
      "[160/318] Loss: 0.1294 Train Acc: 0.9556\n",
      "[170/318] Loss: 0.1206 Train Acc: 0.9581\n",
      "[180/318] Loss: 0.1090 Train Acc: 0.9639\n",
      "[190/318] Loss: 0.1317 Train Acc: 0.9551\n",
      "[200/318] Loss: 0.1142 Train Acc: 0.9610\n",
      "[210/318] Loss: 0.1189 Train Acc: 0.9598\n",
      "[220/318] Loss: 0.1322 Train Acc: 0.9550\n",
      "[230/318] Loss: 0.1190 Train Acc: 0.9584\n",
      "[240/318] Loss: 0.1279 Train Acc: 0.9571\n",
      "[250/318] Loss: 0.1216 Train Acc: 0.9577\n",
      "[260/318] Loss: 0.1208 Train Acc: 0.9588\n",
      "[270/318] Loss: 0.1226 Train Acc: 0.9580\n",
      "[280/318] Loss: 0.1231 Train Acc: 0.9581\n",
      "[290/318] Loss: 0.1235 Train Acc: 0.9576\n",
      "[300/318] Loss: 0.1260 Train Acc: 0.9568\n",
      "[310/318] Loss: 0.1135 Train Acc: 0.9606\n",
      "Epoch: 25, Test IoU: 0.6975, Time: 102.37s\n",
      "[10/318] Loss: 0.4442 Train Acc: 0.8716\n",
      "[20/318] Loss: 0.4334 Train Acc: 0.8676\n",
      "[30/318] Loss: 0.3564 Train Acc: 0.8859\n",
      "[40/318] Loss: 0.3296 Train Acc: 0.8953\n",
      "[50/318] Loss: 0.3024 Train Acc: 0.8959\n",
      "[60/318] Loss: 0.2690 Train Acc: 0.9098\n",
      "[70/318] Loss: 0.2297 Train Acc: 0.9250\n",
      "[80/318] Loss: 0.2106 Train Acc: 0.9323\n",
      "[90/318] Loss: 0.2045 Train Acc: 0.9339\n",
      "[100/318] Loss: 0.1987 Train Acc: 0.9342\n",
      "[110/318] Loss: 0.1952 Train Acc: 0.9361\n",
      "[120/318] Loss: 0.1919 Train Acc: 0.9369\n",
      "[130/318] Loss: 0.1958 Train Acc: 0.9346\n",
      "[140/318] Loss: 0.1732 Train Acc: 0.9431\n",
      "[150/318] Loss: 0.1718 Train Acc: 0.9427\n",
      "[160/318] Loss: 0.1907 Train Acc: 0.9364\n",
      "[170/318] Loss: 0.1832 Train Acc: 0.9382\n",
      "[180/318] Loss: 0.1711 Train Acc: 0.9433\n",
      "[190/318] Loss: 0.1648 Train Acc: 0.9440\n",
      "[200/318] Loss: 0.1540 Train Acc: 0.9503\n",
      "[210/318] Loss: 0.1394 Train Acc: 0.9533\n",
      "[220/318] Loss: 0.1463 Train Acc: 0.9499\n",
      "[230/318] Loss: 0.1529 Train Acc: 0.9493\n",
      "[240/318] Loss: 0.1520 Train Acc: 0.9486\n",
      "[250/318] Loss: 0.1410 Train Acc: 0.9537\n",
      "[260/318] Loss: 0.1507 Train Acc: 0.9489\n",
      "[270/318] Loss: 0.1455 Train Acc: 0.9514\n",
      "[280/318] Loss: 0.1293 Train Acc: 0.9570\n",
      "[290/318] Loss: 0.1314 Train Acc: 0.9556\n",
      "[300/318] Loss: 0.1365 Train Acc: 0.9533\n",
      "[310/318] Loss: 0.1286 Train Acc: 0.9566\n",
      "Epoch: 26, Test IoU: 0.7104, Time: 102.34s\n",
      "[10/318] Loss: 0.2897 Train Acc: 0.9097\n",
      "[20/318] Loss: 0.2600 Train Acc: 0.9158\n",
      "[30/318] Loss: 0.2213 Train Acc: 0.9290\n",
      "[40/318] Loss: 0.1857 Train Acc: 0.9400\n",
      "[50/318] Loss: 0.1864 Train Acc: 0.9411\n",
      "[60/318] Loss: 0.1788 Train Acc: 0.9429\n",
      "[70/318] Loss: 0.1724 Train Acc: 0.9455\n",
      "[80/318] Loss: 0.1545 Train Acc: 0.9511\n",
      "[90/318] Loss: 0.1572 Train Acc: 0.9497\n",
      "[100/318] Loss: 0.1470 Train Acc: 0.9523\n",
      "[110/318] Loss: 0.1546 Train Acc: 0.9485\n",
      "[120/318] Loss: 0.1461 Train Acc: 0.9516\n",
      "[130/318] Loss: 0.1463 Train Acc: 0.9526\n",
      "[140/318] Loss: 0.1459 Train Acc: 0.9505\n",
      "[150/318] Loss: 0.1505 Train Acc: 0.9501\n",
      "[160/318] Loss: 0.1403 Train Acc: 0.9525\n",
      "[170/318] Loss: 0.1386 Train Acc: 0.9534\n",
      "[180/318] Loss: 0.1292 Train Acc: 0.9567\n",
      "[190/318] Loss: 0.1272 Train Acc: 0.9573\n",
      "[200/318] Loss: 0.1298 Train Acc: 0.9570\n",
      "[210/318] Loss: 0.1238 Train Acc: 0.9586\n",
      "[220/318] Loss: 0.1303 Train Acc: 0.9564\n",
      "[230/318] Loss: 0.1356 Train Acc: 0.9544\n",
      "[240/318] Loss: 0.1280 Train Acc: 0.9562\n",
      "[250/318] Loss: 0.1316 Train Acc: 0.9548\n",
      "[260/318] Loss: 0.1349 Train Acc: 0.9544\n",
      "[270/318] Loss: 0.1212 Train Acc: 0.9583\n",
      "[280/318] Loss: 0.1201 Train Acc: 0.9593\n",
      "[290/318] Loss: 0.1213 Train Acc: 0.9591\n",
      "[300/318] Loss: 0.1211 Train Acc: 0.9597\n",
      "[310/318] Loss: 0.1246 Train Acc: 0.9589\n",
      "Epoch: 27, Test IoU: 0.7061, Time: 102.71s\n",
      "[10/318] Loss: 0.2522 Train Acc: 0.9165\n",
      "[20/318] Loss: 0.2536 Train Acc: 0.9163\n",
      "[30/318] Loss: 0.1963 Train Acc: 0.9365\n",
      "[40/318] Loss: 0.1669 Train Acc: 0.9450\n",
      "[50/318] Loss: 0.1439 Train Acc: 0.9539\n",
      "[60/318] Loss: 0.1452 Train Acc: 0.9508\n",
      "[70/318] Loss: 0.1327 Train Acc: 0.9555\n",
      "[80/318] Loss: 0.1367 Train Acc: 0.9540\n",
      "[90/318] Loss: 0.1417 Train Acc: 0.9528\n",
      "[100/318] Loss: 0.1303 Train Acc: 0.9558\n",
      "[110/318] Loss: 0.1272 Train Acc: 0.9579\n",
      "[120/318] Loss: 0.1309 Train Acc: 0.9549\n",
      "[130/318] Loss: 0.1278 Train Acc: 0.9571\n",
      "[140/318] Loss: 0.1215 Train Acc: 0.9602\n",
      "[150/318] Loss: 0.1256 Train Acc: 0.9578\n",
      "[160/318] Loss: 0.1288 Train Acc: 0.9557\n",
      "[170/318] Loss: 0.1180 Train Acc: 0.9600\n",
      "[180/318] Loss: 0.1222 Train Acc: 0.9590\n",
      "[190/318] Loss: 0.1270 Train Acc: 0.9577\n",
      "[200/318] Loss: 0.1171 Train Acc: 0.9609\n",
      "[210/318] Loss: 0.1261 Train Acc: 0.9562\n",
      "[220/318] Loss: 0.1317 Train Acc: 0.9561\n",
      "[230/318] Loss: 0.1288 Train Acc: 0.9556\n",
      "[240/318] Loss: 0.1212 Train Acc: 0.9580\n",
      "[250/318] Loss: 0.1102 Train Acc: 0.9624\n",
      "[260/318] Loss: 0.1299 Train Acc: 0.9556\n",
      "[270/318] Loss: 0.1259 Train Acc: 0.9566\n",
      "[280/318] Loss: 0.1202 Train Acc: 0.9583\n",
      "[290/318] Loss: 0.1227 Train Acc: 0.9582\n",
      "[300/318] Loss: 0.1278 Train Acc: 0.9570\n",
      "[310/318] Loss: 0.1314 Train Acc: 0.9563\n",
      "Epoch: 28, Test IoU: 0.7315, Time: 102.43s\n",
      "[10/318] Loss: 0.2101 Train Acc: 0.9299\n",
      "[20/318] Loss: 0.1770 Train Acc: 0.9376\n",
      "[30/318] Loss: 0.1569 Train Acc: 0.9476\n",
      "[40/318] Loss: 0.1457 Train Acc: 0.9509\n",
      "[50/318] Loss: 0.1495 Train Acc: 0.9502\n",
      "[60/318] Loss: 0.1322 Train Acc: 0.9554\n",
      "[70/318] Loss: 0.1380 Train Acc: 0.9545\n",
      "[80/318] Loss: 0.1399 Train Acc: 0.9521\n",
      "[90/318] Loss: 0.1244 Train Acc: 0.9572\n",
      "[100/318] Loss: 0.1378 Train Acc: 0.9526\n",
      "[110/318] Loss: 0.1203 Train Acc: 0.9593\n",
      "[120/318] Loss: 0.1256 Train Acc: 0.9591\n",
      "[130/318] Loss: 0.1056 Train Acc: 0.9649\n",
      "[140/318] Loss: 0.1209 Train Acc: 0.9582\n",
      "[150/318] Loss: 0.1162 Train Acc: 0.9603\n",
      "[160/318] Loss: 0.1097 Train Acc: 0.9630\n",
      "[170/318] Loss: 0.1242 Train Acc: 0.9571\n",
      "[180/318] Loss: 0.1189 Train Acc: 0.9597\n",
      "[190/318] Loss: 0.1234 Train Acc: 0.9580\n",
      "[200/318] Loss: 0.1114 Train Acc: 0.9620\n",
      "[210/318] Loss: 0.1167 Train Acc: 0.9605\n",
      "[220/318] Loss: 0.1088 Train Acc: 0.9627\n",
      "[230/318] Loss: 0.1182 Train Acc: 0.9598\n",
      "[240/318] Loss: 0.1225 Train Acc: 0.9584\n",
      "[250/318] Loss: 0.1153 Train Acc: 0.9608\n",
      "[260/318] Loss: 0.1090 Train Acc: 0.9639\n",
      "[270/318] Loss: 0.1091 Train Acc: 0.9619\n",
      "[280/318] Loss: 0.1085 Train Acc: 0.9632\n",
      "[290/318] Loss: 0.1124 Train Acc: 0.9617\n",
      "[300/318] Loss: 0.1164 Train Acc: 0.9606\n",
      "[310/318] Loss: 0.1144 Train Acc: 0.9602\n",
      "Epoch: 29, Test IoU: 0.7077, Time: 102.49s\n",
      "[10/318] Loss: 0.1650 Train Acc: 0.9460\n",
      "[20/318] Loss: 0.1493 Train Acc: 0.9506\n",
      "[30/318] Loss: 0.1355 Train Acc: 0.9536\n",
      "[40/318] Loss: 0.1363 Train Acc: 0.9540\n",
      "[50/318] Loss: 0.1189 Train Acc: 0.9600\n",
      "[60/318] Loss: 0.1213 Train Acc: 0.9580\n",
      "[70/318] Loss: 0.1265 Train Acc: 0.9563\n",
      "[80/318] Loss: 0.1249 Train Acc: 0.9567\n",
      "[90/318] Loss: 0.1230 Train Acc: 0.9586\n",
      "[100/318] Loss: 0.1145 Train Acc: 0.9619\n",
      "[110/318] Loss: 0.1113 Train Acc: 0.9614\n",
      "[120/318] Loss: 0.1035 Train Acc: 0.9646\n",
      "[130/318] Loss: 0.1121 Train Acc: 0.9617\n",
      "[140/318] Loss: 0.1201 Train Acc: 0.9599\n",
      "[150/318] Loss: 0.1310 Train Acc: 0.9563\n",
      "[160/318] Loss: 0.1032 Train Acc: 0.9642\n",
      "[170/318] Loss: 0.1116 Train Acc: 0.9620\n",
      "[180/318] Loss: 0.1124 Train Acc: 0.9616\n",
      "[190/318] Loss: 0.1067 Train Acc: 0.9631\n",
      "[200/318] Loss: 0.0999 Train Acc: 0.9656\n",
      "[210/318] Loss: 0.1061 Train Acc: 0.9634\n",
      "[220/318] Loss: 0.1155 Train Acc: 0.9612\n",
      "[230/318] Loss: 0.1009 Train Acc: 0.9651\n",
      "[240/318] Loss: 0.1068 Train Acc: 0.9642\n",
      "[250/318] Loss: 0.1081 Train Acc: 0.9629\n",
      "[260/318] Loss: 0.1232 Train Acc: 0.9606\n",
      "[270/318] Loss: 0.1161 Train Acc: 0.9605\n",
      "[280/318] Loss: 0.1331 Train Acc: 0.9558\n",
      "[290/318] Loss: 0.1117 Train Acc: 0.9624\n",
      "[300/318] Loss: 0.1148 Train Acc: 0.9614\n",
      "[310/318] Loss: 0.1036 Train Acc: 0.9650\n",
      "Epoch: 30, Test IoU: 0.6944, Time: 102.91s\n",
      "[10/318] Loss: 0.2294 Train Acc: 0.9336\n",
      "[20/318] Loss: 0.1894 Train Acc: 0.9381\n",
      "[30/318] Loss: 0.1842 Train Acc: 0.9385\n",
      "[40/318] Loss: 0.1556 Train Acc: 0.9498\n",
      "[50/318] Loss: 0.1487 Train Acc: 0.9503\n",
      "[60/318] Loss: 0.1232 Train Acc: 0.9585\n",
      "[70/318] Loss: 0.1345 Train Acc: 0.9551\n",
      "[80/318] Loss: 0.1200 Train Acc: 0.9599\n",
      "[90/318] Loss: 0.1260 Train Acc: 0.9564\n",
      "[100/318] Loss: 0.1208 Train Acc: 0.9589\n",
      "[110/318] Loss: 0.1226 Train Acc: 0.9584\n",
      "[120/318] Loss: 0.1111 Train Acc: 0.9623\n",
      "[130/318] Loss: 0.1284 Train Acc: 0.9563\n",
      "[140/318] Loss: 0.1137 Train Acc: 0.9604\n",
      "[150/318] Loss: 0.1283 Train Acc: 0.9583\n",
      "[160/318] Loss: 0.1265 Train Acc: 0.9575\n",
      "[170/318] Loss: 0.1133 Train Acc: 0.9613\n",
      "[180/318] Loss: 0.1245 Train Acc: 0.9571\n",
      "[190/318] Loss: 0.1092 Train Acc: 0.9628\n",
      "[200/318] Loss: 0.1179 Train Acc: 0.9589\n",
      "[210/318] Loss: 0.1300 Train Acc: 0.9566\n",
      "[220/318] Loss: 0.1211 Train Acc: 0.9593\n",
      "[230/318] Loss: 0.1273 Train Acc: 0.9567\n",
      "[240/318] Loss: 0.1251 Train Acc: 0.9568\n",
      "[250/318] Loss: 0.1171 Train Acc: 0.9609\n",
      "[260/318] Loss: 0.1205 Train Acc: 0.9595\n",
      "[270/318] Loss: 0.1148 Train Acc: 0.9604\n",
      "[280/318] Loss: 0.1144 Train Acc: 0.9610\n",
      "[290/318] Loss: 0.1144 Train Acc: 0.9617\n",
      "[300/318] Loss: 0.1200 Train Acc: 0.9590\n",
      "[310/318] Loss: 0.1023 Train Acc: 0.9658\n",
      "Epoch: 31, Test IoU: 0.6987, Time: 102.86s\n",
      "[10/318] Loss: 0.1877 Train Acc: 0.9377\n",
      "[20/318] Loss: 0.1575 Train Acc: 0.9471\n",
      "[30/318] Loss: 0.1446 Train Acc: 0.9519\n",
      "[40/318] Loss: 0.1338 Train Acc: 0.9558\n",
      "[50/318] Loss: 0.1187 Train Acc: 0.9587\n",
      "[60/318] Loss: 0.1224 Train Acc: 0.9572\n",
      "[70/318] Loss: 0.1210 Train Acc: 0.9583\n",
      "[80/318] Loss: 0.1083 Train Acc: 0.9620\n",
      "[90/318] Loss: 0.1106 Train Acc: 0.9608\n",
      "[100/318] Loss: 0.1335 Train Acc: 0.9591\n",
      "[110/318] Loss: 0.1217 Train Acc: 0.9588\n",
      "[120/318] Loss: 0.1197 Train Acc: 0.9592\n",
      "[130/318] Loss: 0.1239 Train Acc: 0.9583\n",
      "[140/318] Loss: 0.1084 Train Acc: 0.9628\n",
      "[150/318] Loss: 0.1190 Train Acc: 0.9593\n",
      "[160/318] Loss: 0.1187 Train Acc: 0.9594\n",
      "[170/318] Loss: 0.1126 Train Acc: 0.9615\n",
      "[180/318] Loss: 0.1055 Train Acc: 0.9637\n",
      "[190/318] Loss: 0.1115 Train Acc: 0.9630\n",
      "[200/318] Loss: 0.1198 Train Acc: 0.9592\n",
      "[210/318] Loss: 0.1185 Train Acc: 0.9594\n",
      "[220/318] Loss: 0.1026 Train Acc: 0.9649\n",
      "[230/318] Loss: 0.1074 Train Acc: 0.9622\n",
      "[240/318] Loss: 0.1100 Train Acc: 0.9620\n",
      "[250/318] Loss: 0.1151 Train Acc: 0.9593\n",
      "[260/318] Loss: 0.1099 Train Acc: 0.9621\n",
      "[270/318] Loss: 0.1134 Train Acc: 0.9625\n",
      "[280/318] Loss: 0.1243 Train Acc: 0.9565\n",
      "[290/318] Loss: 0.1278 Train Acc: 0.9570\n",
      "[300/318] Loss: 0.1152 Train Acc: 0.9602\n",
      "[310/318] Loss: 0.1179 Train Acc: 0.9588\n",
      "Epoch: 32, Test IoU: 0.7139, Time: 102.52s\n",
      "[10/318] Loss: 0.1323 Train Acc: 0.9552\n",
      "[20/318] Loss: 0.1413 Train Acc: 0.9531\n",
      "[30/318] Loss: 0.1316 Train Acc: 0.9564\n",
      "[40/318] Loss: 0.1157 Train Acc: 0.9604\n",
      "[50/318] Loss: 0.1154 Train Acc: 0.9603\n",
      "[60/318] Loss: 0.1090 Train Acc: 0.9630\n",
      "[70/318] Loss: 0.1081 Train Acc: 0.9632\n",
      "[80/318] Loss: 0.1104 Train Acc: 0.9626\n",
      "[90/318] Loss: 0.1283 Train Acc: 0.9550\n",
      "[100/318] Loss: 0.1095 Train Acc: 0.9627\n",
      "[110/318] Loss: 0.0984 Train Acc: 0.9661\n",
      "[120/318] Loss: 0.1024 Train Acc: 0.9646\n",
      "[130/318] Loss: 0.1019 Train Acc: 0.9651\n",
      "[140/318] Loss: 0.1091 Train Acc: 0.9621\n",
      "[150/318] Loss: 0.1045 Train Acc: 0.9643\n",
      "[160/318] Loss: 0.0929 Train Acc: 0.9683\n",
      "[170/318] Loss: 0.0982 Train Acc: 0.9651\n",
      "[180/318] Loss: 0.0917 Train Acc: 0.9684\n",
      "[190/318] Loss: 0.1067 Train Acc: 0.9642\n",
      "[200/318] Loss: 0.0899 Train Acc: 0.9690\n",
      "[210/318] Loss: 0.1039 Train Acc: 0.9638\n",
      "[220/318] Loss: 0.1040 Train Acc: 0.9639\n",
      "[230/318] Loss: 0.1023 Train Acc: 0.9656\n",
      "[240/318] Loss: 0.1029 Train Acc: 0.9640\n",
      "[250/318] Loss: 0.1015 Train Acc: 0.9649\n",
      "[260/318] Loss: 0.1003 Train Acc: 0.9660\n",
      "[270/318] Loss: 0.1114 Train Acc: 0.9609\n",
      "[280/318] Loss: 0.1097 Train Acc: 0.9621\n",
      "[290/318] Loss: 0.1060 Train Acc: 0.9633\n",
      "[300/318] Loss: 0.1039 Train Acc: 0.9636\n",
      "[310/318] Loss: 0.0934 Train Acc: 0.9678\n",
      "Epoch: 33, Test IoU: 0.7297, Time: 102.75s\n",
      "[10/318] Loss: 0.0967 Train Acc: 0.9665\n",
      "[20/318] Loss: 0.1052 Train Acc: 0.9632\n",
      "[30/318] Loss: 0.0975 Train Acc: 0.9667\n",
      "[40/318] Loss: 0.0940 Train Acc: 0.9668\n",
      "[50/318] Loss: 0.0931 Train Acc: 0.9678\n",
      "[60/318] Loss: 0.0829 Train Acc: 0.9711\n",
      "[70/318] Loss: 0.0965 Train Acc: 0.9667\n",
      "[80/318] Loss: 0.1050 Train Acc: 0.9634\n",
      "[90/318] Loss: 0.0992 Train Acc: 0.9655\n",
      "[100/318] Loss: 0.0888 Train Acc: 0.9692\n",
      "[110/318] Loss: 0.1076 Train Acc: 0.9619\n",
      "[120/318] Loss: 0.1011 Train Acc: 0.9642\n",
      "[130/318] Loss: 0.1022 Train Acc: 0.9653\n",
      "[140/318] Loss: 0.0973 Train Acc: 0.9661\n",
      "[150/318] Loss: 0.0941 Train Acc: 0.9679\n",
      "[160/318] Loss: 0.1025 Train Acc: 0.9642\n",
      "[170/318] Loss: 0.0999 Train Acc: 0.9654\n",
      "[180/318] Loss: 0.0976 Train Acc: 0.9666\n",
      "[190/318] Loss: 0.0977 Train Acc: 0.9661\n",
      "[200/318] Loss: 0.0996 Train Acc: 0.9655\n",
      "[210/318] Loss: 0.0975 Train Acc: 0.9669\n",
      "[220/318] Loss: 0.0951 Train Acc: 0.9674\n",
      "[230/318] Loss: 0.0947 Train Acc: 0.9671\n",
      "[240/318] Loss: 0.1003 Train Acc: 0.9652\n",
      "[250/318] Loss: 0.0924 Train Acc: 0.9685\n",
      "[260/318] Loss: 0.0978 Train Acc: 0.9656\n",
      "[270/318] Loss: 0.1038 Train Acc: 0.9646\n",
      "[280/318] Loss: 0.0968 Train Acc: 0.9661\n",
      "[290/318] Loss: 0.1005 Train Acc: 0.9656\n",
      "[300/318] Loss: 0.1006 Train Acc: 0.9651\n",
      "[310/318] Loss: 0.1014 Train Acc: 0.9644\n",
      "Epoch: 34, Test IoU: 0.7076, Time: 102.44s\n",
      "[10/318] Loss: 0.2195 Train Acc: 0.9323\n",
      "[20/318] Loss: 0.2074 Train Acc: 0.9317\n",
      "[30/318] Loss: 0.1808 Train Acc: 0.9400\n",
      "[40/318] Loss: 0.1640 Train Acc: 0.9462\n",
      "[50/318] Loss: 0.1461 Train Acc: 0.9525\n",
      "[60/318] Loss: 0.1415 Train Acc: 0.9526\n",
      "[70/318] Loss: 0.1284 Train Acc: 0.9570\n",
      "[80/318] Loss: 0.1236 Train Acc: 0.9590\n",
      "[90/318] Loss: 0.1259 Train Acc: 0.9580\n",
      "[100/318] Loss: 0.1297 Train Acc: 0.9551\n",
      "[110/318] Loss: 0.1202 Train Acc: 0.9617\n",
      "[120/318] Loss: 0.1170 Train Acc: 0.9601\n",
      "[130/318] Loss: 0.1235 Train Acc: 0.9572\n",
      "[140/318] Loss: 0.1076 Train Acc: 0.9631\n",
      "[150/318] Loss: 0.1155 Train Acc: 0.9607\n",
      "[160/318] Loss: 0.1146 Train Acc: 0.9604\n",
      "[170/318] Loss: 0.1061 Train Acc: 0.9632\n",
      "[180/318] Loss: 0.1177 Train Acc: 0.9599\n",
      "[190/318] Loss: 0.1049 Train Acc: 0.9634\n",
      "[200/318] Loss: 0.1136 Train Acc: 0.9616\n",
      "[210/318] Loss: 0.1146 Train Acc: 0.9594\n",
      "[220/318] Loss: 0.1147 Train Acc: 0.9595\n",
      "[230/318] Loss: 0.1130 Train Acc: 0.9622\n",
      "[240/318] Loss: 0.1065 Train Acc: 0.9627\n",
      "[250/318] Loss: 0.1207 Train Acc: 0.9582\n",
      "[260/318] Loss: 0.1225 Train Acc: 0.9574\n",
      "[270/318] Loss: 0.1052 Train Acc: 0.9640\n",
      "[280/318] Loss: 0.1260 Train Acc: 0.9572\n",
      "[290/318] Loss: 0.1073 Train Acc: 0.9633\n",
      "[300/318] Loss: 0.1110 Train Acc: 0.9624\n",
      "[310/318] Loss: 0.1166 Train Acc: 0.9595\n",
      "Epoch: 35, Test IoU: 0.7218, Time: 102.78s\n",
      "[10/318] Loss: 0.1036 Train Acc: 0.9640\n",
      "[20/318] Loss: 0.1091 Train Acc: 0.9620\n",
      "[30/318] Loss: 0.1030 Train Acc: 0.9646\n",
      "[40/318] Loss: 0.0957 Train Acc: 0.9669\n",
      "[50/318] Loss: 0.1000 Train Acc: 0.9648\n",
      "[60/318] Loss: 0.0978 Train Acc: 0.9661\n",
      "[70/318] Loss: 0.1103 Train Acc: 0.9613\n",
      "[80/318] Loss: 0.1094 Train Acc: 0.9608\n",
      "[90/318] Loss: 0.1078 Train Acc: 0.9614\n",
      "[100/318] Loss: 0.1049 Train Acc: 0.9639\n",
      "[110/318] Loss: 0.1068 Train Acc: 0.9642\n",
      "[120/318] Loss: 0.1069 Train Acc: 0.9630\n",
      "[130/318] Loss: 0.0918 Train Acc: 0.9675\n",
      "[140/318] Loss: 0.1091 Train Acc: 0.9620\n",
      "[150/318] Loss: 0.1021 Train Acc: 0.9644\n",
      "[160/318] Loss: 0.1120 Train Acc: 0.9623\n",
      "[170/318] Loss: 0.1082 Train Acc: 0.9635\n",
      "[180/318] Loss: 0.1126 Train Acc: 0.9597\n",
      "[190/318] Loss: 0.1140 Train Acc: 0.9623\n",
      "[200/318] Loss: 0.1154 Train Acc: 0.9607\n",
      "[210/318] Loss: 0.1079 Train Acc: 0.9621\n",
      "[220/318] Loss: 0.0980 Train Acc: 0.9660\n",
      "[230/318] Loss: 0.1046 Train Acc: 0.9639\n",
      "[240/318] Loss: 0.1044 Train Acc: 0.9634\n",
      "[250/318] Loss: 0.1009 Train Acc: 0.9643\n",
      "[260/318] Loss: 0.1033 Train Acc: 0.9655\n",
      "[270/318] Loss: 0.1056 Train Acc: 0.9636\n",
      "[280/318] Loss: 0.0936 Train Acc: 0.9676\n",
      "[290/318] Loss: 0.1029 Train Acc: 0.9635\n",
      "[300/318] Loss: 0.1009 Train Acc: 0.9656\n",
      "[310/318] Loss: 0.1012 Train Acc: 0.9648\n",
      "Epoch: 36, Test IoU: 0.7276, Time: 102.32s\n",
      "[10/318] Loss: 0.3008 Train Acc: 0.9036\n",
      "[20/318] Loss: 0.3236 Train Acc: 0.8979\n",
      "[30/318] Loss: 0.2380 Train Acc: 0.9255\n",
      "[40/318] Loss: 0.2215 Train Acc: 0.9299\n",
      "[50/318] Loss: 0.2171 Train Acc: 0.9297\n",
      "[60/318] Loss: 0.1866 Train Acc: 0.9400\n",
      "[70/318] Loss: 0.1670 Train Acc: 0.9436\n",
      "[80/318] Loss: 0.1636 Train Acc: 0.9450\n",
      "[90/318] Loss: 0.1559 Train Acc: 0.9470\n",
      "[100/318] Loss: 0.1647 Train Acc: 0.9428\n",
      "[110/318] Loss: 0.1313 Train Acc: 0.9559\n",
      "[120/318] Loss: 0.1453 Train Acc: 0.9498\n",
      "[130/318] Loss: 0.1347 Train Acc: 0.9536\n",
      "[140/318] Loss: 0.1316 Train Acc: 0.9552\n",
      "[150/318] Loss: 0.1241 Train Acc: 0.9578\n",
      "[160/318] Loss: 0.1316 Train Acc: 0.9549\n",
      "[170/318] Loss: 0.1372 Train Acc: 0.9542\n",
      "[180/318] Loss: 0.1269 Train Acc: 0.9567\n",
      "[190/318] Loss: 0.1255 Train Acc: 0.9569\n",
      "[200/318] Loss: 0.1228 Train Acc: 0.9574\n",
      "[210/318] Loss: 0.1227 Train Acc: 0.9580\n",
      "[220/318] Loss: 0.1214 Train Acc: 0.9587\n",
      "[230/318] Loss: 0.1263 Train Acc: 0.9583\n",
      "[240/318] Loss: 0.1225 Train Acc: 0.9579\n",
      "[250/318] Loss: 0.1123 Train Acc: 0.9607\n",
      "[260/318] Loss: 0.1139 Train Acc: 0.9605\n",
      "[270/318] Loss: 0.1117 Train Acc: 0.9623\n",
      "[280/318] Loss: 0.1144 Train Acc: 0.9598\n",
      "[290/318] Loss: 0.1108 Train Acc: 0.9613\n",
      "[300/318] Loss: 0.1125 Train Acc: 0.9615\n",
      "[310/318] Loss: 0.1000 Train Acc: 0.9661\n",
      "Epoch: 37, Test IoU: 0.7206, Time: 102.48s\n",
      "[10/318] Loss: 0.1618 Train Acc: 0.9504\n",
      "[20/318] Loss: 0.1888 Train Acc: 0.9405\n",
      "[30/318] Loss: 0.1441 Train Acc: 0.9553\n",
      "[40/318] Loss: 0.1245 Train Acc: 0.9591\n",
      "[50/318] Loss: 0.1389 Train Acc: 0.9548\n",
      "[60/318] Loss: 0.1334 Train Acc: 0.9547\n",
      "[70/318] Loss: 0.1249 Train Acc: 0.9575\n",
      "[80/318] Loss: 0.1202 Train Acc: 0.9586\n",
      "[90/318] Loss: 0.1183 Train Acc: 0.9604\n",
      "[100/318] Loss: 0.1147 Train Acc: 0.9605\n",
      "[110/318] Loss: 0.1060 Train Acc: 0.9636\n",
      "[120/318] Loss: 0.1081 Train Acc: 0.9637\n",
      "[130/318] Loss: 0.0992 Train Acc: 0.9660\n",
      "[140/318] Loss: 0.1015 Train Acc: 0.9648\n",
      "[150/318] Loss: 0.1056 Train Acc: 0.9638\n",
      "[160/318] Loss: 0.1097 Train Acc: 0.9629\n",
      "[170/318] Loss: 0.1039 Train Acc: 0.9633\n",
      "[180/318] Loss: 0.1107 Train Acc: 0.9614\n",
      "[190/318] Loss: 0.0969 Train Acc: 0.9660\n",
      "[200/318] Loss: 0.0943 Train Acc: 0.9672\n",
      "[210/318] Loss: 0.1048 Train Acc: 0.9648\n",
      "[220/318] Loss: 0.0959 Train Acc: 0.9668\n",
      "[230/318] Loss: 0.1086 Train Acc: 0.9622\n",
      "[240/318] Loss: 0.0945 Train Acc: 0.9675\n",
      "[250/318] Loss: 0.1006 Train Acc: 0.9652\n",
      "[260/318] Loss: 0.1142 Train Acc: 0.9633\n",
      "[270/318] Loss: 0.1062 Train Acc: 0.9634\n",
      "[280/318] Loss: 0.1017 Train Acc: 0.9666\n",
      "[290/318] Loss: 0.1107 Train Acc: 0.9622\n",
      "[300/318] Loss: 0.0987 Train Acc: 0.9660\n",
      "[310/318] Loss: 0.1021 Train Acc: 0.9644\n",
      "Epoch: 38, Test IoU: 0.7044, Time: 102.59s\n",
      "[10/318] Loss: 0.2267 Train Acc: 0.9269\n",
      "[20/318] Loss: 0.2304 Train Acc: 0.9265\n",
      "[30/318] Loss: 0.1839 Train Acc: 0.9406\n",
      "[40/318] Loss: 0.1733 Train Acc: 0.9411\n",
      "[50/318] Loss: 0.1493 Train Acc: 0.9488\n",
      "[60/318] Loss: 0.1449 Train Acc: 0.9518\n",
      "[70/318] Loss: 0.1367 Train Acc: 0.9551\n",
      "[80/318] Loss: 0.1316 Train Acc: 0.9557\n",
      "[90/318] Loss: 0.1204 Train Acc: 0.9608\n",
      "[100/318] Loss: 0.1285 Train Acc: 0.9568\n",
      "[110/318] Loss: 0.1308 Train Acc: 0.9545\n",
      "[120/318] Loss: 0.1118 Train Acc: 0.9615\n",
      "[130/318] Loss: 0.1233 Train Acc: 0.9582\n",
      "[140/318] Loss: 0.0995 Train Acc: 0.9663\n",
      "[150/318] Loss: 0.1074 Train Acc: 0.9634\n",
      "[160/318] Loss: 0.1059 Train Acc: 0.9633\n",
      "[170/318] Loss: 0.1017 Train Acc: 0.9653\n",
      "[180/318] Loss: 0.1073 Train Acc: 0.9621\n",
      "[190/318] Loss: 0.0973 Train Acc: 0.9667\n",
      "[200/318] Loss: 0.1038 Train Acc: 0.9645\n",
      "[210/318] Loss: 0.1090 Train Acc: 0.9631\n",
      "[220/318] Loss: 0.1138 Train Acc: 0.9609\n",
      "[230/318] Loss: 0.1066 Train Acc: 0.9619\n",
      "[240/318] Loss: 0.1032 Train Acc: 0.9641\n",
      "[250/318] Loss: 0.0990 Train Acc: 0.9649\n",
      "[260/318] Loss: 0.0996 Train Acc: 0.9655\n",
      "[270/318] Loss: 0.1000 Train Acc: 0.9657\n",
      "[280/318] Loss: 0.1019 Train Acc: 0.9644\n",
      "[290/318] Loss: 0.0974 Train Acc: 0.9665\n",
      "[300/318] Loss: 0.1038 Train Acc: 0.9640\n",
      "[310/318] Loss: 0.0997 Train Acc: 0.9656\n",
      "Epoch: 39, Test IoU: 0.7036, Time: 102.30s\n",
      "[10/318] Loss: 0.1829 Train Acc: 0.9420\n",
      "[20/318] Loss: 0.1961 Train Acc: 0.9356\n",
      "[30/318] Loss: 0.1526 Train Acc: 0.9506\n",
      "[40/318] Loss: 0.1393 Train Acc: 0.9541\n",
      "[50/318] Loss: 0.1293 Train Acc: 0.9562\n",
      "[60/318] Loss: 0.1186 Train Acc: 0.9592\n",
      "[70/318] Loss: 0.1116 Train Acc: 0.9626\n",
      "[80/318] Loss: 0.1246 Train Acc: 0.9564\n",
      "[90/318] Loss: 0.1130 Train Acc: 0.9613\n",
      "[100/318] Loss: 0.1034 Train Acc: 0.9649\n",
      "[110/318] Loss: 0.1065 Train Acc: 0.9625\n",
      "[120/318] Loss: 0.1033 Train Acc: 0.9640\n",
      "[130/318] Loss: 0.1050 Train Acc: 0.9632\n",
      "[140/318] Loss: 0.0985 Train Acc: 0.9661\n",
      "[150/318] Loss: 0.0954 Train Acc: 0.9673\n",
      "[160/318] Loss: 0.1089 Train Acc: 0.9620\n",
      "[170/318] Loss: 0.0996 Train Acc: 0.9658\n",
      "[180/318] Loss: 0.1057 Train Acc: 0.9638\n",
      "[190/318] Loss: 0.1138 Train Acc: 0.9622\n",
      "[200/318] Loss: 0.1240 Train Acc: 0.9604\n",
      "[210/318] Loss: 0.1283 Train Acc: 0.9570\n",
      "[220/318] Loss: 0.1206 Train Acc: 0.9583\n",
      "[230/318] Loss: 0.1126 Train Acc: 0.9622\n",
      "[240/318] Loss: 0.0984 Train Acc: 0.9659\n",
      "[250/318] Loss: 0.1020 Train Acc: 0.9646\n",
      "[260/318] Loss: 0.0987 Train Acc: 0.9664\n",
      "[270/318] Loss: 0.1044 Train Acc: 0.9639\n",
      "[280/318] Loss: 0.0950 Train Acc: 0.9676\n",
      "[290/318] Loss: 0.0952 Train Acc: 0.9665\n",
      "[300/318] Loss: 0.0981 Train Acc: 0.9662\n",
      "[310/318] Loss: 0.0979 Train Acc: 0.9658\n",
      "Epoch: 40, Test IoU: 0.7399, Time: 102.60s\n",
      "[10/318] Loss: 0.1304 Train Acc: 0.9561\n",
      "[20/318] Loss: 0.1161 Train Acc: 0.9599\n",
      "[30/318] Loss: 0.1217 Train Acc: 0.9578\n",
      "[40/318] Loss: 0.1155 Train Acc: 0.9605\n",
      "[50/318] Loss: 0.1183 Train Acc: 0.9598\n",
      "[60/318] Loss: 0.1018 Train Acc: 0.9658\n",
      "[70/318] Loss: 0.0969 Train Acc: 0.9667\n",
      "[80/318] Loss: 0.1049 Train Acc: 0.9630\n",
      "[90/318] Loss: 0.0969 Train Acc: 0.9667\n",
      "[100/318] Loss: 0.1013 Train Acc: 0.9649\n",
      "[110/318] Loss: 0.0994 Train Acc: 0.9653\n",
      "[120/318] Loss: 0.0981 Train Acc: 0.9656\n",
      "[130/318] Loss: 0.0864 Train Acc: 0.9698\n",
      "[140/318] Loss: 0.0967 Train Acc: 0.9660\n",
      "[150/318] Loss: 0.0913 Train Acc: 0.9680\n",
      "[160/318] Loss: 0.0904 Train Acc: 0.9683\n",
      "[170/318] Loss: 0.0916 Train Acc: 0.9680\n",
      "[180/318] Loss: 0.0954 Train Acc: 0.9669\n",
      "[190/318] Loss: 0.0933 Train Acc: 0.9676\n",
      "[200/318] Loss: 0.0890 Train Acc: 0.9691\n",
      "[210/318] Loss: 0.0898 Train Acc: 0.9682\n",
      "[220/318] Loss: 0.0906 Train Acc: 0.9682\n",
      "[230/318] Loss: 0.0909 Train Acc: 0.9680\n",
      "[240/318] Loss: 0.0896 Train Acc: 0.9687\n",
      "[250/318] Loss: 0.0870 Train Acc: 0.9694\n",
      "[260/318] Loss: 0.0906 Train Acc: 0.9688\n",
      "[270/318] Loss: 0.1042 Train Acc: 0.9642\n",
      "[280/318] Loss: 0.0980 Train Acc: 0.9658\n",
      "[290/318] Loss: 0.0957 Train Acc: 0.9667\n",
      "[300/318] Loss: 0.0945 Train Acc: 0.9665\n",
      "[310/318] Loss: 0.0939 Train Acc: 0.9669\n",
      "Epoch: 41, Test IoU: 0.7097, Time: 102.77s\n",
      "[10/318] Loss: 0.4483 Train Acc: 0.8669\n",
      "[20/318] Loss: 0.4366 Train Acc: 0.8686\n",
      "[30/318] Loss: 0.3240 Train Acc: 0.9027\n",
      "[40/318] Loss: 0.2526 Train Acc: 0.9188\n",
      "[50/318] Loss: 0.2140 Train Acc: 0.9287\n",
      "[60/318] Loss: 0.1775 Train Acc: 0.9415\n",
      "[70/318] Loss: 0.1772 Train Acc: 0.9430\n",
      "[80/318] Loss: 0.1670 Train Acc: 0.9442\n",
      "[90/318] Loss: 0.1590 Train Acc: 0.9477\n",
      "[100/318] Loss: 0.1473 Train Acc: 0.9508\n",
      "[110/318] Loss: 0.1382 Train Acc: 0.9535\n",
      "[120/318] Loss: 0.1575 Train Acc: 0.9456\n",
      "[130/318] Loss: 0.1415 Train Acc: 0.9525\n",
      "[140/318] Loss: 0.1473 Train Acc: 0.9507\n",
      "[150/318] Loss: 0.1330 Train Acc: 0.9548\n",
      "[160/318] Loss: 0.1299 Train Acc: 0.9549\n",
      "[170/318] Loss: 0.1186 Train Acc: 0.9602\n",
      "[180/318] Loss: 0.1232 Train Acc: 0.9581\n",
      "[190/318] Loss: 0.1126 Train Acc: 0.9611\n",
      "[200/318] Loss: 0.1097 Train Acc: 0.9629\n",
      "[210/318] Loss: 0.1129 Train Acc: 0.9611\n",
      "[220/318] Loss: 0.1138 Train Acc: 0.9621\n",
      "[230/318] Loss: 0.1080 Train Acc: 0.9621\n",
      "[240/318] Loss: 0.1117 Train Acc: 0.9617\n",
      "[250/318] Loss: 0.1117 Train Acc: 0.9613\n",
      "[260/318] Loss: 0.1060 Train Acc: 0.9640\n",
      "[270/318] Loss: 0.1096 Train Acc: 0.9628\n",
      "[280/318] Loss: 0.1045 Train Acc: 0.9637\n",
      "[290/318] Loss: 0.1046 Train Acc: 0.9640\n",
      "[300/318] Loss: 0.1131 Train Acc: 0.9623\n",
      "[310/318] Loss: 0.1014 Train Acc: 0.9656\n",
      "Epoch: 42, Test IoU: 0.6872, Time: 102.45s\n",
      "[10/318] Loss: 0.1623 Train Acc: 0.9470\n",
      "[20/318] Loss: 0.1628 Train Acc: 0.9441\n",
      "[30/318] Loss: 0.1280 Train Acc: 0.9572\n",
      "[40/318] Loss: 0.1310 Train Acc: 0.9554\n",
      "[50/318] Loss: 0.1126 Train Acc: 0.9618\n",
      "[60/318] Loss: 0.1145 Train Acc: 0.9610\n",
      "[70/318] Loss: 0.1087 Train Acc: 0.9623\n",
      "[80/318] Loss: 0.1174 Train Acc: 0.9599\n",
      "[90/318] Loss: 0.1159 Train Acc: 0.9593\n",
      "[100/318] Loss: 0.1129 Train Acc: 0.9612\n",
      "[110/318] Loss: 0.1154 Train Acc: 0.9609\n",
      "[120/318] Loss: 0.0965 Train Acc: 0.9672\n",
      "[130/318] Loss: 0.1075 Train Acc: 0.9637\n",
      "[140/318] Loss: 0.1003 Train Acc: 0.9653\n",
      "[150/318] Loss: 0.1008 Train Acc: 0.9653\n",
      "[160/318] Loss: 0.1040 Train Acc: 0.9640\n",
      "[170/318] Loss: 0.0967 Train Acc: 0.9669\n",
      "[180/318] Loss: 0.1036 Train Acc: 0.9636\n",
      "[190/318] Loss: 0.0976 Train Acc: 0.9662\n",
      "[200/318] Loss: 0.0941 Train Acc: 0.9678\n",
      "[210/318] Loss: 0.0940 Train Acc: 0.9679\n",
      "[220/318] Loss: 0.1031 Train Acc: 0.9639\n",
      "[230/318] Loss: 0.0968 Train Acc: 0.9667\n",
      "[240/318] Loss: 0.0935 Train Acc: 0.9671\n",
      "[250/318] Loss: 0.0960 Train Acc: 0.9667\n",
      "[260/318] Loss: 0.1023 Train Acc: 0.9645\n",
      "[270/318] Loss: 0.1055 Train Acc: 0.9635\n",
      "[280/318] Loss: 0.0957 Train Acc: 0.9669\n",
      "[290/318] Loss: 0.1131 Train Acc: 0.9607\n",
      "[300/318] Loss: 0.1125 Train Acc: 0.9607\n",
      "[310/318] Loss: 0.0986 Train Acc: 0.9657\n",
      "Epoch: 43, Test IoU: 0.7122, Time: 102.47s\n",
      "[10/318] Loss: 0.2359 Train Acc: 0.9233\n",
      "[20/318] Loss: 0.2619 Train Acc: 0.9232\n",
      "[30/318] Loss: 0.2061 Train Acc: 0.9345\n",
      "[40/318] Loss: 0.1767 Train Acc: 0.9424\n",
      "[50/318] Loss: 0.1478 Train Acc: 0.9527\n",
      "[60/318] Loss: 0.1462 Train Acc: 0.9517\n",
      "[70/318] Loss: 0.1394 Train Acc: 0.9521\n",
      "[80/318] Loss: 0.1270 Train Acc: 0.9552\n",
      "[90/318] Loss: 0.1246 Train Acc: 0.9571\n",
      "[100/318] Loss: 0.1158 Train Acc: 0.9604\n",
      "[110/318] Loss: 0.1118 Train Acc: 0.9615\n",
      "[120/318] Loss: 0.1138 Train Acc: 0.9606\n",
      "[130/318] Loss: 0.1132 Train Acc: 0.9611\n",
      "[140/318] Loss: 0.1092 Train Acc: 0.9628\n",
      "[150/318] Loss: 0.1047 Train Acc: 0.9645\n",
      "[160/318] Loss: 0.1078 Train Acc: 0.9632\n",
      "[170/318] Loss: 0.1048 Train Acc: 0.9640\n",
      "[180/318] Loss: 0.1154 Train Acc: 0.9597\n",
      "[190/318] Loss: 0.1149 Train Acc: 0.9591\n",
      "[200/318] Loss: 0.1006 Train Acc: 0.9656\n",
      "[210/318] Loss: 0.1031 Train Acc: 0.9655\n",
      "[220/318] Loss: 0.1029 Train Acc: 0.9641\n",
      "[230/318] Loss: 0.0964 Train Acc: 0.9676\n",
      "[240/318] Loss: 0.0977 Train Acc: 0.9668\n",
      "[250/318] Loss: 0.1027 Train Acc: 0.9641\n",
      "[260/318] Loss: 0.0961 Train Acc: 0.9662\n",
      "[270/318] Loss: 0.0928 Train Acc: 0.9675\n",
      "[280/318] Loss: 0.0993 Train Acc: 0.9655\n",
      "[290/318] Loss: 0.0977 Train Acc: 0.9655\n",
      "[300/318] Loss: 0.0981 Train Acc: 0.9665\n",
      "[310/318] Loss: 0.0961 Train Acc: 0.9662\n",
      "Epoch: 44, Test IoU: 0.7286, Time: 102.53s\n",
      "[10/318] Loss: 0.1061 Train Acc: 0.9633\n",
      "[20/318] Loss: 0.0943 Train Acc: 0.9672\n",
      "[30/318] Loss: 0.0972 Train Acc: 0.9662\n",
      "[40/318] Loss: 0.1010 Train Acc: 0.9645\n",
      "[50/318] Loss: 0.0902 Train Acc: 0.9687\n",
      "[60/318] Loss: 0.0972 Train Acc: 0.9662\n",
      "[70/318] Loss: 0.0933 Train Acc: 0.9674\n",
      "[80/318] Loss: 0.0930 Train Acc: 0.9674\n",
      "[90/318] Loss: 0.0879 Train Acc: 0.9689\n",
      "[100/318] Loss: 0.0927 Train Acc: 0.9679\n",
      "[110/318] Loss: 0.0904 Train Acc: 0.9682\n",
      "[120/318] Loss: 0.0856 Train Acc: 0.9698\n",
      "[130/318] Loss: 0.0922 Train Acc: 0.9682\n",
      "[140/318] Loss: 0.0949 Train Acc: 0.9664\n",
      "[150/318] Loss: 0.0898 Train Acc: 0.9683\n",
      "[160/318] Loss: 0.0902 Train Acc: 0.9685\n",
      "[170/318] Loss: 0.0929 Train Acc: 0.9671\n",
      "[180/318] Loss: 0.0874 Train Acc: 0.9694\n",
      "[190/318] Loss: 0.0900 Train Acc: 0.9681\n",
      "[200/318] Loss: 0.0920 Train Acc: 0.9671\n",
      "[210/318] Loss: 0.0963 Train Acc: 0.9663\n",
      "[220/318] Loss: 0.0973 Train Acc: 0.9662\n",
      "[230/318] Loss: 0.0918 Train Acc: 0.9682\n",
      "[240/318] Loss: 0.0971 Train Acc: 0.9658\n",
      "[250/318] Loss: 0.0973 Train Acc: 0.9678\n",
      "[260/318] Loss: 0.0973 Train Acc: 0.9663\n",
      "[270/318] Loss: 0.0979 Train Acc: 0.9668\n",
      "[280/318] Loss: 0.0886 Train Acc: 0.9690\n",
      "[290/318] Loss: 0.0965 Train Acc: 0.9664\n",
      "[300/318] Loss: 0.0950 Train Acc: 0.9674\n",
      "[310/318] Loss: 0.0938 Train Acc: 0.9672\n",
      "Epoch: 45, Test IoU: 0.7324, Time: 102.40s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for epoch in range(1, 46):\n",
    "    # Track epoch start time\n",
    "    start_time = time.perf_counter()\n",
    "    train()\n",
    "    iou = test(test_loader)\n",
    "    # Calculate epoch duration\n",
    "    epoch_time = time.perf_counter() - start_time\n",
    "    \n",
    "    # Print results with time\n",
    "    print(f'Epoch: {epoch:02d}, Test IoU: {iou:.4f}, Time: {epoch_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint_path = \"/scratch/project_2013104/checkpoints/pointnet2_s3dis_transform_seg_x6_45_checkpoint.pth\"\n",
    "\n",
    "# Save model, optimizer state, and any other info needed\n",
    "torch.save({\n",
    "    'epoch': 45,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #'loss': loss,\n",
    "    #'test_accuracy': test_acc\n",
    "}, checkpoint_path)\n",
    "\n",
    "print(\"Checkpoint saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

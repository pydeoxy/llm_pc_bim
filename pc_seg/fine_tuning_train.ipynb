{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\python312.zip',\n",
       " 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\DLLs',\n",
       " 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\Lib',\n",
       " 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0',\n",
       " '',\n",
       " 'C:\\\\Users\\\\yanpe\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages',\n",
       " 'C:\\\\Users\\\\yanpe\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\yanpe\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\yanpe\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\Lib\\\\site-packages',\n",
       " 'c:\\\\projappl\\\\project_2013104\\\\pengyan1\\\\venv\\\\lib\\\\python3.10\\\\site-packages']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "folder_path = os.path.abspath(\"/projappl/project_2013104/pengyan1/venv/lib/python3.10/site-packages\")\n",
    "if folder_path not in sys.path:\n",
    "    sys.path.append(folder_path)\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import loralib as lora\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import JaccardIndex\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import MLP\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.typing import WITH_TORCH_CLUSTER\n",
    "\n",
    "from pyg_pointnet2 import PyGPointNet2NoColor\n",
    "from pc_dataset import H5PCDataset\n",
    "\n",
    "if not WITH_TORCH_CLUSTER:\n",
    "    quit(\"This example requires 'torch-cluster'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the CUDA cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out colors\n",
    "class SelectLast3Features:\n",
    "    def __call__(self, data):\n",
    "        # If data.x is defined, select only its last 3 features.\n",
    "        if data.x is not None:\n",
    "            data.x = data.x[:, -3:]\n",
    "        return data\n",
    "\n",
    "# transform and pre_transform\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.RandomJitter(0.01),\n",
    "    T.RandomRotate(15, axis=0),\n",
    "    T.RandomRotate(15, axis=1),\n",
    "    T.RandomRotate(15, axis=2),\n",
    "    SelectLast3Features()\n",
    "])\n",
    "\n",
    "#transform = SelectLast3Features()\n",
    "\n",
    "h5_file_path = \"../docs/sim_pc_dataset.h5\" # local file path\n",
    "#h5_file_path ='/scratch/project_2013104/datasets/sim_pc_dataset.h5' # csc file path\n",
    "\n",
    "full_dataset = H5PCDataset(file_path=h5_file_path, transform=transform)\n",
    "\n",
    "# Define split sizes (e.g., 80% training and 20% validation)\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "\n",
    "# Randomly split the dataset\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[4096, 3], y=[4096], pos=[4096, 3])\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])\n",
    "print(train_dataset.dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "num_workers=0\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                          num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PyGPointNet2NoColor(num_classes=13).to(device)\n",
    "\n",
    "model_file_path = \"checkpoints/pointnet2_s3dis_colorless_seg_x3_45_checkpoint.pth\"\n",
    "# Load the checkpoint dictionary\n",
    "checkpoint = torch.load(model_file_path, map_location=device)\n",
    "# Extract the model state dictionary\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "model.load_state_dict(model_state_dict, strict=True)  \n",
    "\n",
    "# Replace the final classification layer\n",
    "#new_num_classes = 13\n",
    "#model.lin3 = torch.nn.Linear(128, new_num_classes)\n",
    "#model.mlp = MLP([128, 128, 128, new_num_classes], dropout=0.5, norm=None)\n",
    "\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyGPointNet2NoColor(\n",
       "  (sa1_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=MLP(6, 64, 64, 128), global_nn=None)\n",
       "  )\n",
       "  (sa2_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=MLP(131, 128, 128, 256), global_nn=None)\n",
       "  )\n",
       "  (sa3_module): GlobalSAModule(\n",
       "    (nn): MLP(259, 256, 512, 1024)\n",
       "  )\n",
       "  (fp3_module): FPModule(\n",
       "    (nn): MLP(1280, 256, 256)\n",
       "  )\n",
       "  (fp2_module): FPModule(\n",
       "    (nn): MLP(384, 256, 128)\n",
       "  )\n",
       "  (fp1_module): FPModule(\n",
       "    (nn): MLP(131, 128, 128, 128)\n",
       "  )\n",
       "  (mlp): MLP(128, 128, 128, 13)\n",
       "  (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin3): Linear(in_features=128, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),  # All parameters are trainable\n",
    "    lr=1e-4,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = correct_nodes = total_nodes = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        data = data.to(device)        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out.view(-1, 13), data.y.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct_nodes += out.argmax(dim=1).eq(data.y).sum().item()\n",
    "        total_nodes += data.num_nodes\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'[{i+1}/{len(train_loader)}] Loss: {total_loss / 10:.4f} '\n",
    "                  f'Train Acc: {correct_nodes / total_nodes:.4f}')\n",
    "            total_loss = correct_nodes = total_nodes = 0\n",
    "    # If there are remaining batches that were not printed (i.e., i+1 not divisible by 10)\n",
    "    if total_nodes > 0:\n",
    "        num_remaining = (i + 1) % 10  # Number of batches in the leftover segment\n",
    "        print(f'[{i+1}/{len(train_loader)}] Loss: {total_loss / num_remaining:.4f} '\n",
    "              f'Train Acc: {correct_nodes / total_nodes:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    jaccard = JaccardIndex(num_classes=loader.dataset.dataset.num_classes, task=\"multiclass\").to(device)\n",
    "    \n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        outs = model(data)\n",
    "        preds = outs.argmax(dim=-1)\n",
    "        jaccard.update(preds, data.y)\n",
    "    \n",
    "    return jaccard.compute().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/13] Loss: 2.2460 Train Acc: 0.6304\n",
      "[13/13] Loss: 2.3479 Train Acc: 0.6206\n",
      "Epoch: 01, Test IoU: 0.2045, Time: 4.01s\n",
      "[10/13] Loss: 1.6790 Train Acc: 0.6683\n",
      "[13/13] Loss: 2.2711 Train Acc: 0.6954\n",
      "Epoch: 02, Test IoU: 0.2153, Time: 3.42s\n",
      "[10/13] Loss: 1.1986 Train Acc: 0.7354\n",
      "[13/13] Loss: 1.3693 Train Acc: 0.7661\n",
      "Epoch: 03, Test IoU: 0.2248, Time: 3.40s\n",
      "[10/13] Loss: 1.1143 Train Acc: 0.7424\n",
      "[13/13] Loss: 2.5613 Train Acc: 0.7415\n",
      "Epoch: 04, Test IoU: 0.2284, Time: 3.43s\n",
      "[10/13] Loss: 1.0327 Train Acc: 0.7602\n",
      "[13/13] Loss: 1.0048 Train Acc: 0.8033\n",
      "Epoch: 05, Test IoU: 0.2369, Time: 3.59s\n",
      "[10/13] Loss: 0.9334 Train Acc: 0.7646\n",
      "[13/13] Loss: 0.7464 Train Acc: 0.8045\n",
      "Epoch: 06, Test IoU: 0.2320, Time: 3.33s\n",
      "[10/13] Loss: 0.8291 Train Acc: 0.7854\n",
      "[13/13] Loss: 0.6948 Train Acc: 0.8026\n",
      "Epoch: 07, Test IoU: 0.2290, Time: 3.50s\n",
      "[10/13] Loss: 0.7432 Train Acc: 0.8001\n",
      "[13/13] Loss: 1.0559 Train Acc: 0.7446\n",
      "Epoch: 08, Test IoU: 0.2324, Time: 3.42s\n",
      "[10/13] Loss: 0.7598 Train Acc: 0.7937\n",
      "[13/13] Loss: 1.1222 Train Acc: 0.7936\n",
      "Epoch: 09, Test IoU: 0.2195, Time: 3.38s\n",
      "[10/13] Loss: 0.7401 Train Acc: 0.7905\n",
      "[13/13] Loss: 1.0415 Train Acc: 0.7923\n",
      "Epoch: 10, Test IoU: 0.2380, Time: 3.38s\n",
      "[10/13] Loss: 0.7289 Train Acc: 0.7920\n",
      "[13/13] Loss: 1.3525 Train Acc: 0.8174\n",
      "Epoch: 11, Test IoU: 0.2396, Time: 3.44s\n",
      "[10/13] Loss: 0.7207 Train Acc: 0.8018\n",
      "[13/13] Loss: 0.8525 Train Acc: 0.7582\n",
      "Epoch: 12, Test IoU: 0.2389, Time: 3.42s\n",
      "[10/13] Loss: 0.6744 Train Acc: 0.8016\n",
      "[13/13] Loss: 0.5549 Train Acc: 0.8220\n",
      "Epoch: 13, Test IoU: 0.2463, Time: 3.51s\n",
      "[10/13] Loss: 0.6980 Train Acc: 0.7984\n",
      "[13/13] Loss: 0.6731 Train Acc: 0.8333\n",
      "Epoch: 14, Test IoU: 0.2541, Time: 3.51s\n",
      "[10/13] Loss: 0.6404 Train Acc: 0.8137\n",
      "[13/13] Loss: 0.6249 Train Acc: 0.7791\n",
      "Epoch: 15, Test IoU: 0.2442, Time: 3.43s\n",
      "[10/13] Loss: 0.6573 Train Acc: 0.8094\n",
      "[13/13] Loss: 0.5608 Train Acc: 0.8163\n",
      "Epoch: 16, Test IoU: 0.2368, Time: 3.40s\n",
      "[10/13] Loss: 0.6270 Train Acc: 0.8176\n",
      "[13/13] Loss: 1.2396 Train Acc: 0.7651\n",
      "Epoch: 17, Test IoU: 0.2602, Time: 3.38s\n",
      "[10/13] Loss: 0.5919 Train Acc: 0.8217\n",
      "[13/13] Loss: 0.8343 Train Acc: 0.7737\n",
      "Epoch: 18, Test IoU: 0.2587, Time: 3.42s\n",
      "[10/13] Loss: 0.6275 Train Acc: 0.8068\n",
      "[13/13] Loss: 0.5065 Train Acc: 0.8243\n",
      "Epoch: 19, Test IoU: 0.2572, Time: 3.51s\n",
      "[10/13] Loss: 0.6116 Train Acc: 0.8142\n",
      "[13/13] Loss: 0.8077 Train Acc: 0.7797\n",
      "Epoch: 20, Test IoU: 0.2665, Time: 3.40s\n",
      "[10/13] Loss: 0.5737 Train Acc: 0.8261\n",
      "[13/13] Loss: 0.7716 Train Acc: 0.7840\n",
      "Epoch: 21, Test IoU: 0.2688, Time: 3.39s\n",
      "[10/13] Loss: 0.5846 Train Acc: 0.8190\n",
      "[13/13] Loss: 0.8732 Train Acc: 0.7757\n",
      "Epoch: 22, Test IoU: 0.2764, Time: 3.40s\n",
      "[10/13] Loss: 0.5902 Train Acc: 0.8188\n",
      "[13/13] Loss: 0.6951 Train Acc: 0.8035\n",
      "Epoch: 23, Test IoU: 0.2633, Time: 3.43s\n",
      "[10/13] Loss: 0.5560 Train Acc: 0.8254\n",
      "[13/13] Loss: 0.6676 Train Acc: 0.8202\n",
      "Epoch: 24, Test IoU: 0.2669, Time: 3.45s\n",
      "[10/13] Loss: 0.5507 Train Acc: 0.8223\n",
      "[13/13] Loss: 1.0070 Train Acc: 0.8174\n",
      "Epoch: 25, Test IoU: 0.2888, Time: 3.45s\n",
      "[10/13] Loss: 0.5709 Train Acc: 0.8178\n",
      "[13/13] Loss: 0.7141 Train Acc: 0.8183\n",
      "Epoch: 26, Test IoU: 0.2790, Time: 3.58s\n",
      "[10/13] Loss: 0.5591 Train Acc: 0.8259\n",
      "[13/13] Loss: 0.5440 Train Acc: 0.8419\n",
      "Epoch: 27, Test IoU: 0.2836, Time: 3.59s\n",
      "[10/13] Loss: 0.5647 Train Acc: 0.8240\n",
      "[13/13] Loss: 0.8067 Train Acc: 0.8238\n",
      "Epoch: 28, Test IoU: 0.2748, Time: 3.44s\n",
      "[10/13] Loss: 0.5415 Train Acc: 0.8286\n",
      "[13/13] Loss: 0.8810 Train Acc: 0.8143\n",
      "Epoch: 29, Test IoU: 0.2793, Time: 3.60s\n",
      "[10/13] Loss: 0.5574 Train Acc: 0.8240\n",
      "[13/13] Loss: 0.6724 Train Acc: 0.8460\n",
      "Epoch: 30, Test IoU: 0.2980, Time: 3.46s\n",
      "[10/13] Loss: 0.4961 Train Acc: 0.8428\n",
      "[13/13] Loss: 0.6903 Train Acc: 0.7688\n",
      "Epoch: 31, Test IoU: 0.2827, Time: 3.48s\n",
      "[10/13] Loss: 0.5105 Train Acc: 0.8372\n",
      "[13/13] Loss: 1.2117 Train Acc: 0.7859\n",
      "Epoch: 32, Test IoU: 0.2921, Time: 3.51s\n",
      "[10/13] Loss: 0.5130 Train Acc: 0.8375\n",
      "[13/13] Loss: 0.7660 Train Acc: 0.8008\n",
      "Epoch: 33, Test IoU: 0.2927, Time: 3.56s\n",
      "[10/13] Loss: 0.5160 Train Acc: 0.8304\n",
      "[13/13] Loss: 1.1395 Train Acc: 0.8002\n",
      "Epoch: 34, Test IoU: 0.2836, Time: 3.48s\n",
      "[10/13] Loss: 0.5423 Train Acc: 0.8290\n",
      "[13/13] Loss: 0.5321 Train Acc: 0.8635\n",
      "Epoch: 35, Test IoU: 0.2802, Time: 3.48s\n",
      "[10/13] Loss: 0.5444 Train Acc: 0.8229\n",
      "[13/13] Loss: 0.3446 Train Acc: 0.8770\n",
      "Epoch: 36, Test IoU: 0.3218, Time: 3.57s\n",
      "[10/13] Loss: 0.5081 Train Acc: 0.8399\n",
      "[13/13] Loss: 0.8126 Train Acc: 0.8192\n",
      "Epoch: 37, Test IoU: 0.2975, Time: 3.46s\n",
      "[10/13] Loss: 0.5038 Train Acc: 0.8357\n",
      "[13/13] Loss: 1.7267 Train Acc: 0.8245\n",
      "Epoch: 38, Test IoU: 0.2900, Time: 3.43s\n",
      "[10/13] Loss: 0.5223 Train Acc: 0.8320\n",
      "[13/13] Loss: 0.8954 Train Acc: 0.8394\n",
      "Epoch: 39, Test IoU: 0.2963, Time: 3.47s\n",
      "[10/13] Loss: 0.4802 Train Acc: 0.8467\n",
      "[13/13] Loss: 0.8014 Train Acc: 0.7991\n",
      "Epoch: 40, Test IoU: 0.3039, Time: 3.45s\n",
      "[10/13] Loss: 0.5212 Train Acc: 0.8328\n",
      "[13/13] Loss: 1.0920 Train Acc: 0.8328\n",
      "Epoch: 41, Test IoU: 0.2865, Time: 3.59s\n",
      "[10/13] Loss: 0.5163 Train Acc: 0.8310\n",
      "[13/13] Loss: 0.6518 Train Acc: 0.8548\n",
      "Epoch: 42, Test IoU: 0.3082, Time: 3.45s\n",
      "[10/13] Loss: 0.4755 Train Acc: 0.8487\n",
      "[13/13] Loss: 1.3474 Train Acc: 0.7873\n",
      "Epoch: 43, Test IoU: 0.3138, Time: 3.47s\n",
      "[10/13] Loss: 0.4920 Train Acc: 0.8442\n",
      "[13/13] Loss: 0.5077 Train Acc: 0.8000\n",
      "Epoch: 44, Test IoU: 0.3222, Time: 3.46s\n",
      "[10/13] Loss: 0.4887 Train Acc: 0.8397\n",
      "[13/13] Loss: 0.5422 Train Acc: 0.8269\n",
      "Epoch: 45, Test IoU: 0.2978, Time: 3.50s\n",
      "[10/13] Loss: 0.4733 Train Acc: 0.8456\n",
      "[13/13] Loss: 0.8638 Train Acc: 0.8331\n",
      "Epoch: 46, Test IoU: 0.3105, Time: 3.46s\n",
      "[10/13] Loss: 0.4906 Train Acc: 0.8377\n",
      "[13/13] Loss: 0.6228 Train Acc: 0.8509\n",
      "Epoch: 47, Test IoU: 0.3224, Time: 3.46s\n",
      "[10/13] Loss: 0.5059 Train Acc: 0.8364\n",
      "[13/13] Loss: 0.5523 Train Acc: 0.8520\n",
      "Epoch: 48, Test IoU: 0.3059, Time: 3.48s\n",
      "[10/13] Loss: 0.4673 Train Acc: 0.8444\n",
      "[13/13] Loss: 0.9335 Train Acc: 0.8237\n",
      "Epoch: 49, Test IoU: 0.3012, Time: 3.48s\n",
      "[10/13] Loss: 0.5206 Train Acc: 0.8340\n",
      "[13/13] Loss: 0.9543 Train Acc: 0.8159\n",
      "Epoch: 50, Test IoU: 0.3022, Time: 3.49s\n",
      "Training time: 2.90m\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "import time\n",
    "begin_time = time.perf_counter()\n",
    "for epoch in range(1, 51):\n",
    "    start_time = time.perf_counter()\n",
    "    train()\n",
    "    iou = test(test_loader)\n",
    "    epoch_time = time.perf_counter() - start_time    \n",
    "    print(f'Epoch: {epoch:02d}, Test IoU: {iou:.4f}, Time: {epoch_time:.2f}s')\n",
    "total_time = time.perf_counter() - begin_time\n",
    "print(f'Training time: {total_time/60:.2f}m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved successfully!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"checkpoints/smartlab_fine_tuning_norandomtransform_x3_50_20250416.pth\"\n",
    "\n",
    "# Save model, optimizer state, and any other info needed\n",
    "torch.save({\n",
    "    'epoch': 50,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #'loss': loss,\n",
    "    #'test_accuracy': test_acc\n",
    "}, checkpoint_path)\n",
    "\n",
    "print(\"Checkpoint saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

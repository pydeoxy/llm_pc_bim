{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalized coordinates are calculated in each 1m x 1m block.**\n",
    "\n",
    "**NOT WORKING WELL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\python312.zip', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\DLLs', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\Lib', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0', '', 'C:\\\\Users\\\\yanpe\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages', 'C:\\\\Users\\\\yanpe\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\win32', 'C:\\\\Users\\\\yanpe\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\yanpe\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python312\\\\site-packages\\\\Pythonwin', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\yanpe\\\\.env\\\\Lib\\\\site-packages', 'C:\\\\Users\\\\yanpe\\\\.env\\\\Lib\\\\site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.append(r\"C:\\Users\\yanpe\\.env\\Lib\\site-packages\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MLP, PointNetConv, fps, global_max_pool, radius\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MLP, knn_interpolate\n",
    "from torch_geometric.typing import WITH_TORCH_CLUSTER\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "if not WITH_TORCH_CLUSTER:\n",
    "    quit(\"This example requires 'torch-cluster'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty the CUDA cache\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAModule(torch.nn.Module):\n",
    "    def __init__(self, ratio, r, nn):\n",
    "        super().__init__()\n",
    "        self.ratio = ratio\n",
    "        self.r = r\n",
    "        self.conv = PointNetConv(nn, add_self_loops=False)\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        idx = fps(pos, batch, ratio=self.ratio)\n",
    "        row, col = radius(pos, pos[idx], self.r, batch, batch[idx],\n",
    "                          max_num_neighbors=64)\n",
    "        edge_index = torch.stack([col, row], dim=0)\n",
    "        x_dst = None if x is None else x[idx]\n",
    "        x = self.conv((x, x_dst), (pos, pos[idx]), edge_index)\n",
    "        pos, batch = pos[idx], batch[idx]\n",
    "        return x, pos, batch\n",
    "\n",
    "\n",
    "class GlobalSAModule(torch.nn.Module):\n",
    "    def __init__(self, nn):\n",
    "        super().__init__()\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch):\n",
    "        x = self.nn(torch.cat([x, pos], dim=1))\n",
    "        x = global_max_pool(x, batch)\n",
    "        pos = pos.new_zeros((x.size(0), 3))\n",
    "        batch = torch.arange(x.size(0), device=batch.device)\n",
    "        return x, pos, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPModule(torch.nn.Module):\n",
    "    def __init__(self, k, nn):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.nn = nn\n",
    "\n",
    "    def forward(self, x, pos, batch, x_skip, pos_skip, batch_skip):\n",
    "        x = knn_interpolate(x, pos, pos_skip, batch, batch_skip, k=self.k)\n",
    "        if x_skip is not None:\n",
    "            x = torch.cat([x, x_skip], dim=1)\n",
    "        x = self.nn(x)\n",
    "        return x, pos_skip, batch_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input channels account for both `pos` and node features.\n",
    "        self.sa1_module = SAModule(0.2, 0.2, MLP([3 + 6, 64, 64, 128])) # 3 (pos) + 6 (x)\n",
    "        self.sa2_module = SAModule(0.25, 0.4, MLP([128 + 3, 128, 128, 256]))\n",
    "        self.sa3_module = GlobalSAModule(MLP([256 + 3, 256, 512, 1024]))\n",
    "\n",
    "        self.fp3_module = FPModule(1, MLP([1024 + 256, 256, 256]))\n",
    "        self.fp2_module = FPModule(3, MLP([256 + 128, 256, 128]))\n",
    "        self.fp1_module = FPModule(3, MLP([128 + 6, 128, 128, 128]))\n",
    "\n",
    "        self.mlp = MLP([128, 128, 128, num_classes], dropout=0.5, norm=None)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(128, 128)\n",
    "        self.lin2 = torch.nn.Linear(128, 128)\n",
    "        self.lin3 = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        sa0_out = (data.x, data.pos, data.batch)\n",
    "        sa1_out = self.sa1_module(*sa0_out)\n",
    "        sa2_out = self.sa2_module(*sa1_out)\n",
    "        sa3_out = self.sa3_module(*sa2_out)\n",
    "\n",
    "        fp3_out = self.fp3_module(*sa3_out, *sa2_out)\n",
    "        fp2_out = self.fp2_module(*fp3_out, *sa1_out)\n",
    "        x, _, _ = self.fp1_module(*fp2_out, *sa0_out)\n",
    "\n",
    "        return self.mlp(x).log_softmax(dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(num_classes=13).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to the pre-trained model\n",
    "script_dir = os.path.dirname(os.getcwd())\n",
    "model_file_path= os.path.join(script_dir, '.', 'docs', 'pointnet2_s3dis_transform_seg_x6_27_checkpoint.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint dictionary\n",
    "checkpoint = torch.load(model_file_path, map_location=device)\n",
    "# Extract the model state dictionary\n",
    "model_state_dict = checkpoint['model_state_dict']\n",
    "\n",
    "# print(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (sa1_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=MLP(9, 64, 64, 128), global_nn=None)\n",
       "  )\n",
       "  (sa2_module): SAModule(\n",
       "    (conv): PointNetConv(local_nn=MLP(131, 128, 128, 256), global_nn=None)\n",
       "  )\n",
       "  (sa3_module): GlobalSAModule(\n",
       "    (nn): MLP(259, 256, 512, 1024)\n",
       "  )\n",
       "  (fp3_module): FPModule(\n",
       "    (nn): MLP(1280, 256, 256)\n",
       "  )\n",
       "  (fp2_module): FPModule(\n",
       "    (nn): MLP(384, 256, 128)\n",
       "  )\n",
       "  (fp1_module): FPModule(\n",
       "    (nn): MLP(134, 128, 128, 128)\n",
       "  )\n",
       "  (mlp): MLP(128, 128, 128, 13)\n",
       "  (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (lin3): Linear(in_features=128, out_features=13, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pcd files\n",
    "#pcd_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/Smartlab-2024-04-05_10-58-26_colour_cleaned.pcd\"\n",
    "pcd_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/SmartLab_2024_E57_Single_5mm.pcd\"\n",
    "#pcd_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/SmartLab_2024_E57_Single_5mm.ply\"\n",
    "pcd = o3d.io.read_point_cloud(pcd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_point_cloud(pcd, block_size=1.0):\n",
    "    \"\"\"\n",
    "    Process a point cloud file and append block-wise normalized coordinates.\n",
    "    \n",
    "    Assumptions:\n",
    "      - The point cloud file (e.g., .npy) contains an Nx6 array where each row is\n",
    "        (x, y, z, r, g, b).\n",
    "      - The function computes normalized coordinates per block. A block is defined\n",
    "        as a cube of side `block_size` covering the extent of the point cloud.\n",
    "      - The output array has shape (N, 9) where the extra 3 features (nx, ny, nz) are \n",
    "        the normalized coordinates within each block.\n",
    "    \n",
    "    Parameters:\n",
    "      file_path (str): Path to the point cloud file.\n",
    "      block_size (float): Side length for each block (in same units as the point coordinates).\n",
    "    \n",
    "    Returns:\n",
    "      numpy.ndarray: Processed point cloud of shape (N, 9).\n",
    "    \"\"\"\n",
    "    # Load the point cloud.\n",
    "    \n",
    "    points = np.array(pcd.points)  \n",
    "    colors = np.array(pcd.colors)    \n",
    "    \n",
    "    # Compute the overall minimum bound for x, y, z\n",
    "    min_bound = np.min(points, axis=0)\n",
    "    \n",
    "    # Compute block index for each point (each dimension)\n",
    "    block_idx = np.floor((points - min_bound) / block_size).astype(np.int32)\n",
    "    \n",
    "    # Compute the lower bound for the block each point belongs to\n",
    "    block_lower_bound = min_bound + block_idx * block_size\n",
    "    \n",
    "    # Calculate normalized coordinates within the block\n",
    "    normalized_coords = (points - block_lower_bound) / block_size\n",
    "    \n",
    "    # Concatenate the original 6 features with the normalized coordinates (nx, ny, nz)\n",
    "    processed_points = np.concatenate([points, colors, normalized_coords], axis=1)\n",
    "    \n",
    "    return processed_points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35966772\n",
      "35966772\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(pcd.points))\n",
    "print(len(pcd.colors))\n",
    "print(len(pcd.normals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866885\n"
     ]
    }
   ],
   "source": [
    "# Downsample the point cloud with a voxel of 0.03\n",
    "downpcd = pcd.voxel_down_sample(voxel_size=0.03)\n",
    "\n",
    "print(len(downpcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([downpcd], point_show_normal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_downpcd = process_point_cloud(downpcd, block_size=1.0)\n",
    "\n",
    "# Convert the NumPy array to a PyTorch tensor.\n",
    "processed_downpcd_tensor = torch.from_numpy(processed_downpcd)\n",
    "processed_downpcd_tensor = processed_downpcd_tensor.float()\n",
    "\n",
    "# Extract the first 3 features (e.g., x, y, z).\n",
    "pos = processed_downpcd_tensor[:, :3]\n",
    "\n",
    "# Extract the last 6 features (e.g., r, g, b, and the 3 normalized coordinates).\n",
    "x = processed_downpcd_tensor[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data object with x (6 features) and pos (coordinates)\n",
    "data = Data(x=x, pos=pos)\n",
    "\n",
    "#pre_transform = T.NormalizeScale()\n",
    "#data = pre_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have only one point cloud\n",
    "dataset = [data]  # List of Data objects\n",
    "\n",
    "num_workers = 20\n",
    "batch_size = 32\n",
    "\n",
    "# Create a DataLoader (batch_size can be adjusted as needed)\n",
    "custom_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n",
    "                         num_workers=num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts:\n",
      "[[     0   6153]\n",
      " [     1  87202]\n",
      " [     2 189940]\n",
      " [     3  17127]\n",
      " [     4  12160]\n",
      " [     5     27]\n",
      " [     6  38937]\n",
      " [     7  17977]\n",
      " [     8   3727]\n",
      " [     9     46]\n",
      " [    10 415402]\n",
      " [    12  78187]]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in custom_loader:\n",
    "        data = data.to(device)\n",
    "        predictions = model(data)\n",
    "        labels = predictions.argmax(dim=-1)\n",
    "        # Process the labels as needed\n",
    "        labels_arr = labels.cpu().numpy()\n",
    "        # Count occurrences of labels\n",
    "        unique_labels, label_counts = np.unique(labels_arr, return_counts=True)\n",
    "        # Combine and print\n",
    "        result_labels = np.array(list(zip(unique_labels, label_counts)))\n",
    "        print(\"Label counts:\")\n",
    "        print(result_labels)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size 32, num_workers 16: prediction 7min\n",
    "\n",
    "batch_size = 64, num_workers 16: prediction 5.5min\n",
    "\n",
    "batch_size = 32, num_workers 20: prediction 5min\n",
    "\n",
    "batch_size = 128, num_workers 20: prediction 7.5min\n",
    "\n",
    "batch_size = 48, num_workers 20: prediction 7min\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the number of classes in your model's predictions\n",
    "num_classes = 13  # Adjust based on your number of classes\n",
    "\n",
    "\n",
    "# Define a fixed color map for 13 labels\n",
    "color_map = np.array([\n",
    "    [1.0, 0.0, 0.0],  # Label 0: Red,  'ceiling'\n",
    "    [0.0, 1.0, 0.0],  # Label 1: Green, 'floor'\n",
    "    [0.0, 0.0, 1.0],  # Label 2: Blue,  'wall'\n",
    "    [1.0, 1.0, 0.0],  # Label 3: Yellow, 'beam'\n",
    "    [1.0, 0.0, 1.0],  # Label 4: Magenta, 'column'\n",
    "    [0.0, 1.0, 1.0],  # Label 5: Cyan, 'window'\n",
    "    [0.5, 0.5, 0.5],  # Label 6: Gray, 'door'\n",
    "    [1.0, 0.5, 0.0],  # Label 7: Orange, 'chair'\n",
    "    [0.5, 0.0, 1.0],  # Label 8: Purple, 'table'\n",
    "    [0.5, 1.0, 0.5],  # Label 9: Light Green, 'bookcase'\n",
    "    [0.5, 0.5, 1.0],  # Label 10: Light Blue, 'sofa'\n",
    "    [1.0, 0.5, 0.5],  # Label 11: Pink, 'board'\n",
    "    [0.0, 0.0, 0.0]   # Label 12: Black, 'clutter'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `labels` is the tensor containing predicted labels for each point\n",
    "predicted_colors = color_map[labels.cpu().numpy()]  # Shape: [num_points, 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "866885\n"
     ]
    }
   ],
   "source": [
    "print(len(predicted_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `pcd` is your Open3D point cloud object\n",
    "downpcd.colors = o3d.utility.Vector3dVector(predicted_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the point cloud with colored labels\n",
    "o3d.visualization.draw_geometries([downpcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the point cloud to a file\n",
    "save_path = \"C:/Users/yanpe/OneDrive - Metropolia Ammattikorkeakoulu Oy/Research/data/smartlab/labelled/Smartlab_aalto_pcd_ifctrained_bw_label_pointnet2_x6_0.02_20250412.ply\"\n",
    "o3d.io.write_point_cloud(save_path, downpcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del down_points\n",
    "del down_colors\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

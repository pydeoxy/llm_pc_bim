{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read .ply file of point cloud**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_dir = os.path.dirname(os.getcwd())\n",
    "sim_pc_path = os.path.join(script_dir, '.', 'docs', 'smartLab_simulated.ply')\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(sim_pc_path)\n",
    "points = np.asarray(pcd.points)          # Shape: [N, 3]\n",
    "colors = np.asarray(pcd.colors)           # Shape: [N, 3]\n",
    "\n",
    "#o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features of dataset (9):\n",
    "coordinates(3), colors(3), normalized coordinates(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_points(points):\n",
    "    # Step 1: Center the points around the origin\n",
    "    centroid = np.mean(points, axis=0)\n",
    "    centered_points = points - centroid\n",
    "\n",
    "    # Step 2: Scale to fit within the [0, 1] interval\n",
    "    min_vals = np.min(centered_points, axis=0)\n",
    "    max_vals = np.max(centered_points, axis=0)\n",
    "    scale = max_vals - min_vals\n",
    "\n",
    "    # Avoid division by zero in case of flat dimension\n",
    "    scale[scale == 0] = 1  # Set zero scales to 1 to keep that dimension as 0.5 after normalization\n",
    "\n",
    "    normalized_points = (centered_points - min_vals) / scale\n",
    "\n",
    "    return normalized_points\n",
    "\n",
    "normalized = normalize_points(np.array(pcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate to get features of shape (N, 9)\n",
    "features = np.concatenate([points, colors, normalized], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = np.array([\n",
    "    [1.0, 0.0, 0.0],  # Label 0: Red,  'ceiling'\n",
    "    [0.0, 1.0, 0.0],  # Label 1: Green, 'floor'\n",
    "    [0.0, 0.0, 1.0],  # Label 2: Blue,  'wall'\n",
    "    [1.0, 1.0, 0.0],  # Label 3: Yellow, 'beam'\n",
    "    [1.0, 0.0, 1.0],  # Label 4: Magenta, 'column'\n",
    "    [0.0, 1.0, 1.0],  # Label 5: Cyan, 'window'\n",
    "    [0.5, 0.5, 0.5],  # Label 6: Gray, 'door'\n",
    "    [1.0, 0.5, 0.0],  # Label 7: Orange, 'chair'\n",
    "    [0.5, 0.0, 1.0],  # Label 8: Purple, 'table'\n",
    "    [0.5, 1.0, 0.5],  # Label 9: Light Green, 'bookcase'\n",
    "    [0.5, 0.5, 1.0],  # Label 10: Light Blue, 'sofa'\n",
    "    [1.0, 0.5, 0.5],  # Label 11: Pink, 'board'\n",
    "    [0.0, 0.0, 0.0]   # Label 12: Black, 'clutter'\n",
    "    ])\n",
    "\n",
    "# Find closest color in color_map for each point\n",
    "#labels = np.argmin(np.linalg.norm(colors[:, None] - color_map, axis=2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Blocks of 1m x 1m x 1m with 4096 points in each like S3DIS dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bound = np.min(points, axis=0)\n",
    "max_bound = np.max(points, axis=0)\n",
    "\n",
    "block_size = 1.0  # in meters\n",
    "num_blocks_x = int(np.ceil((max_bound[0] - min_bound[0]) / block_size))\n",
    "num_blocks_y = int(np.ceil((max_bound[1] - min_bound[1]) / block_size))\n",
    "num_blocks_z = int(np.ceil((max_bound[2] - min_bound[2]) / block_size))\n",
    "\n",
    "block_features_list = []\n",
    "block_labels_list  = []\n",
    "\n",
    "for ix in range(num_blocks_x):\n",
    "    for iy in range(num_blocks_y):\n",
    "        for iz in range(num_blocks_z):\n",
    "            # Define the spatial boundaries for this block\n",
    "            x_min = min_bound[0] + ix * block_size\n",
    "            x_max = x_min + block_size\n",
    "            y_min = min_bound[1] + iy * block_size\n",
    "            y_max = y_min + block_size\n",
    "            z_min = min_bound[2] + iz * block_size\n",
    "            z_max = z_min + block_size\n",
    "\n",
    "            # Find indices of points within the block\n",
    "            in_block = np.where(\n",
    "                (points[:, 0] >= x_min) & (points[:, 0] < x_max) &\n",
    "                (points[:, 1] >= y_min) & (points[:, 1] < y_max) &\n",
    "                (points[:, 2] >= z_min) & (points[:, 2] < z_max)\n",
    "            )[0]\n",
    "\n",
    "            if len(in_block) == 0:\n",
    "                continue  # Skip empty blocks\n",
    "\n",
    "            block_features = features[in_block, :]\n",
    "            # If label is directly extractable, substitute here. If not, infer from color.\n",
    "            block_colors = colors[in_block]\n",
    "            block_labels = np.argmin(np.linalg.norm(colors[in_block][:, None] - color_map, axis=2), axis=1)\n",
    "\n",
    "            # --- Handling Block Size (4096 points) ---\n",
    "            # If there are more than 4096 points, randomly sample 4096.\n",
    "            # If there are fewer, perform random duplication (or padding with zeros) to reach 4096.\n",
    "            num_points = block_features.shape[0]\n",
    "            target_points = 4096\n",
    "\n",
    "            if num_points >= target_points:\n",
    "                idx = np.random.choice(num_points, target_points, replace=False)\n",
    "            else:\n",
    "                # Duplicate some points\n",
    "                idx = np.concatenate([\n",
    "                    np.arange(num_points),\n",
    "                    np.random.choice(num_points, target_points - num_points, replace=True)\n",
    "                ])\n",
    "            block_features = block_features[idx, :]\n",
    "            block_labels = block_labels[idx]\n",
    "\n",
    "            block_features_list.append(block_features)\n",
    "            block_labels_list.append(block_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.6099239  -5.96243998  0.34489385  0.          0.          0.\n",
      "  0.01828092  0.0707432   0.17926242]\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "data_array = np.stack(block_features_list, axis=0)  # Shape: (B, 4096, 9)\n",
    "label_array = np.stack(block_labels_list, axis=0)     # Shape: (B, 4096)\n",
    "\n",
    "print(data_array[0][0])\n",
    "print(label_array[0][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pc_data_path = os.path.join(script_dir, '.', 'docs', 'sim_pc_dataset.h5')\n",
    "\n",
    "# Save to HDF5\n",
    "with h5py.File(sim_pc_data_path, 'w') as f:\n",
    "    f.create_dataset('data', data=data_array, compression='gzip')\n",
    "    f.create_dataset('label', data=label_array, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(485, 4096, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "f = h5py.File(sim_pc_data_path, 'r') #train_pc_path, data_file_path\n",
    "list(f.keys())\n",
    "dset = f['data']\n",
    "dset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.620427605685707,\n",
      " -6.410465555278665,\n",
      " -0.0744237747039048,\n",
      " 0.0,\n",
      " 1.0,\n",
      " 0.0,\n",
      " 0.017368742185738886,\n",
      " 0.030458044305317365,\n",
      " 0.07192523227401235]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(dset[0][2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(485, 4096)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlabel = f['label']\n",
    "dlabel.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

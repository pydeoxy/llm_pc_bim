paths:
  default_docs: "./docs"
  model_cache: "./models"

embedding: "sentence-transformers/all-MiniLM-L6-v2"

llm:
  model_name: "meta-llama/Llama-3.2-3B-Instruct"
              # meta-llama/Llama-3.1-8B-Instruct
              # microsoft/Phi-4-mini-instruct
              # Qwen/Qwen2.5-1.5B-Instruct
              # meta-llama/Llama-3.2-3B-Instruct
              # google/gemma-3-1b-it
  device_map: "auto"
  torch_dtype: "float16"
  generation:
    max_new_tokens: 256
    temperature: 0.7
    repetition_penalty: 1.1
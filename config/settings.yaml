paths:
  default_docs: "./docs"
  model_cache: "./models"

embedding: "sentence-transformers/all-MiniLM-L6-v2"

llm:
  model_name: "meta-llama/Llama-3.2-3B-Instruct"
              #"meta-llama/Llama-3.2-1B-Instruct"
              #"meta-llama/Meta-Llama-3-8B-Instruct"
              #"meta-llama/Llama-3.1-8B-Instruct"
              #"google/gemma-1.1-2b-it" 
              #"google/gemma-2-2b-it" #not working
              #"microsoft/Phi-4-mini-instruct"
              #"Qwen/Qwen2.5-0.5B-Instruct"
              #"Qwen/Qwen2.5-1.5B-Instruct"
              
  device_map: "auto"
  torch_dtype: "float16"
  generation:
    max_new_tokens: 256
    temperature: 0.7
    repetition_penalty: 1.1
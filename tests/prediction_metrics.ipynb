{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from scipy.spatial import cKDTree\n",
    "import open3d as o3d\n",
    "from collections import defaultdict\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from pc_seg.pc_label_map import color_map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert the colormap to get RGB â†’ label index\n",
    "rgb_to_label = {tuple(v[0]): k for k, v in color_map_dict.items()}\n",
    "label_to_name = {k: v[1] for k, v in color_map_dict.items()}\n",
    "\n",
    "def get_label_from_color(color_array):\n",
    "    \"\"\"Match color to closest known semantic color label.\"\"\"\n",
    "    labels = []\n",
    "    for c in color_array:\n",
    "        # Round to 3 decimals to avoid float precision mismatch\n",
    "        key = tuple(np.round(c, 3))\n",
    "        label = rgb_to_label.get(key, -1)  # -1 if unmatched\n",
    "        labels.append(label)\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GT and predicted point clouds\n",
    "gt_pcd = o3d.io.read_point_cloud(\"../docs/SmartLab_2024_E57_Single_5mm_SEG_colors.ply\")   # full resolution\n",
    "pred_pcd = o3d.io.read_point_cloud(\"../docs/Smartlab_s3dis_label_pointnet2_x6_0.03_20250422.ply\")   # downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([gt_pcd], point_show_normal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pred_pcd], point_show_normal=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_label_counts(label_array, name=\"Point Cloud\"):\n",
    "    print(f\"\\nðŸ“¦ Label counts for {name}:\")\n",
    "    unique_labels, counts = np.unique(label_array, return_counts=True)\n",
    "    for label, count in zip(unique_labels, counts):\n",
    "        class_name = label_to_name.get(label, f\"Class {label}\")\n",
    "        print(f\"  {label:2d} ({class_name:10s}): {count} points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the point cloud to its min(x,y,z) corner\n",
    " \n",
    "def move_to_corner(points):    \n",
    "    # Find the minimum x, y, z\n",
    "    min_xyz = points.min(axis=0)\n",
    "    # Translate the point cloud so that the min corner becomes the origin\n",
    "    moved_points = points - min_xyz\n",
    "    \n",
    "    return moved_points\n",
    "\n",
    "moved_points = move_to_corner(np.array(gt_pcd.points))\n",
    "gt_pcd.points = o3d.utility.Vector3dVector(moved_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract point coordinates and colors\n",
    "gt_points = np.asarray(gt_pcd.points)\n",
    "gt_origin_colors = np.asarray(gt_pcd.colors)\n",
    "gt_colors = np.round(gt_origin_colors, 1)\n",
    "\n",
    "pred_points = np.asarray(pred_pcd.points)\n",
    "pred_origin_colors = np.asarray(pred_pcd.colors)\n",
    "pred_colors = np.round(pred_origin_colors, 1)\n",
    "\n",
    "# Convert color to semantic labels\n",
    "gt_labels = get_label_from_color(gt_colors)\n",
    "pred_labels = get_label_from_color(pred_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¦ Label counts for Ground Truth:\n",
      "   0 (ceiling   ): 5701035 points\n",
      "   1 (floor     ): 5167644 points\n",
      "   2 (wall      ): 11348550 points\n",
      "   4 (column    ): 173882 points\n",
      "   5 (window    ): 549543 points\n",
      "   6 (door      ): 1451390 points\n",
      "   7 (table     ): 243330 points\n",
      "   8 (chair     ): 99590 points\n",
      "   9 (sofa      ): 190263 points\n",
      "  11 (board     ): 488769 points\n",
      "  12 (clutter   ): 10552776 points\n",
      "\n",
      "ðŸ“¦ Label counts for Prediction:\n",
      "   0 (ceiling   ): 130218 points\n",
      "   1 (floor     ): 120958 points\n",
      "   2 (wall      ): 277981 points\n",
      "   4 (column    ): 5052 points\n",
      "   5 (window    ): 208 points\n",
      "   6 (door      ): 20088 points\n",
      "   7 (table     ): 114 points\n",
      "   8 (chair     ): 7 points\n",
      "  10 (bookcase  ): 63449 points\n",
      "  11 (board     ): 14 points\n",
      "  12 (clutter   ): 248811 points\n"
     ]
    }
   ],
   "source": [
    "# Ground Truth\n",
    "print_label_counts(gt_labels, name=\"Ground Truth\")\n",
    "\n",
    "# Prediction\n",
    "print_label_counts(pred_labels, name=\"Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Overall Accuracy: 0.662\n",
      "\n",
      "ðŸ“‹ Per-Class Accuracy:\n",
      "   0 (ceiling   ): 0.937 (121952/130218)\n",
      "   1 (floor     ): 0.960 (116098/120958)\n",
      "   2 (wall      ): 0.575 (159789/277981)\n",
      "   4 (column    ): 0.000 (0/5052)\n",
      "   5 (window    ): 0.404 (84/208)\n",
      "   6 (door      ): 0.176 (3526/20088)\n",
      "   7 (table     ): 0.368 (42/114)\n",
      "   8 (chair     ): 0.000 (0/7)\n",
      "  10 (bookcase  ): 0.000 (0/63449)\n",
      "  11 (board     ): 0.000 (0/14)\n",
      "  12 (clutter   ): 0.692 (172196/248811)\n"
     ]
    }
   ],
   "source": [
    "# Filter out unmatched labels (e.g. -1)\n",
    "valid_mask = (gt_labels != -1)\n",
    "gt_points = gt_points[valid_mask]\n",
    "gt_labels = gt_labels[valid_mask]\n",
    "\n",
    "# KDTree nearest neighbor matching\n",
    "tree = cKDTree(gt_points)\n",
    "_, indices = tree.query(pred_points, k=1)\n",
    "matched_pred_labels = gt_labels[indices]\n",
    "\n",
    "# Overall accuracy\n",
    "overall_accuracy = accuracy_score(pred_labels, matched_pred_labels)\n",
    "print(f\"\\nâœ… Overall Accuracy: {overall_accuracy:.3f}\")\n",
    "\n",
    "# Per-class accuracy\n",
    "print(\"\\nðŸ“‹ Per-Class Accuracy:\")\n",
    "class_counts = defaultdict(int)\n",
    "correct_counts = defaultdict(int)\n",
    "\n",
    "for true, pred in zip(pred_labels, matched_pred_labels):\n",
    "    class_counts[true] += 1\n",
    "    if true == pred:\n",
    "        correct_counts[true] += 1\n",
    "\n",
    "for label in sorted(class_counts.keys()):\n",
    "    correct = correct_counts[label]\n",
    "    total = class_counts[label]\n",
    "    acc = correct / total if total > 0 else 0.0\n",
    "    class_name = label_to_name.get(label, f\"Class {label}\")\n",
    "    print(f\"  {label:2d} ({class_name:10s}): {acc:.3f} ({correct}/{total})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanpe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yanpe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     ceiling       0.84      0.94      0.89    130218\n",
      "       floor       0.95      0.96      0.96    120958\n",
      "        wall       0.73      0.57      0.64    277981\n",
      "      column       0.00      0.00      0.00      5052\n",
      "      window       0.01      0.40      0.01       208\n",
      "        door       0.11      0.18      0.13     20088\n",
      "       table       0.01      0.37      0.01       114\n",
      "       chair       0.00      0.00      0.00         7\n",
      "        sofa       0.00      0.00      0.00         0\n",
      "    bookcase       0.00      0.00      0.00     63449\n",
      "       board       0.00      0.00      0.00        14\n",
      "     clutter       0.57      0.69      0.62    248811\n",
      "\n",
      "    accuracy                           0.66    866900\n",
      "   macro avg       0.27      0.34      0.27    866900\n",
      "weighted avg       0.66      0.66      0.66    866900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanpe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yanpe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yanpe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yanpe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Optional: classification report\n",
    "# Ensure all labels used in GT or prediction are covered\n",
    "all_labels = sorted(set(pred_labels) | set(matched_pred_labels))\n",
    "\n",
    "print(classification_report(\n",
    "    pred_labels,\n",
    "    matched_pred_labels,\n",
    "    labels=all_labels,\n",
    "    target_names=[label_to_name.get(i, f\"Class {i}\") for i in all_labels]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(gt_points,gt_labels,pred_file):\n",
    "    results = []\n",
    "    # Extract point coordinates and colors\n",
    "    #gt_points = np.asarray(gt_pcd.points)\n",
    "    #gt_origin_colors = np.asarray(gt_pcd.colors)\n",
    "    #gt_colors = np.round(gt_origin_colors, 1)\n",
    "\n",
    "    pred_pcd = o3d.io.read_point_cloud(pred_file[1])\n",
    "\n",
    "    pred_points = np.asarray(pred_pcd.points)\n",
    "    pred_origin_colors = np.asarray(pred_pcd.colors)\n",
    "    pred_colors = np.round(pred_origin_colors, 1)\n",
    "\n",
    "    # Convert color to semantic labels\n",
    "    #gt_labels = get_label_from_color(gt_colors)\n",
    "    pred_labels = get_label_from_color(pred_colors)\n",
    "    \n",
    "    # Filter out unmatched labels (e.g. -1)\n",
    "    valid_mask = (gt_labels != -1)\n",
    "    gt_points = gt_points[valid_mask]\n",
    "    gt_labels = gt_labels[valid_mask]\n",
    "\n",
    "    # KDTree nearest neighbor matching\n",
    "    tree = cKDTree(gt_points)\n",
    "    _, indices = tree.query(pred_points, k=1)\n",
    "    matched_pred_labels = gt_labels[indices]\n",
    "\n",
    "    # Overall accuracy\n",
    "    #overall_accuracy = accuracy_score(pred_labels, matched_pred_labels)\n",
    "    #print(f\"\\nâœ… Overall Accuracy: {overall_accuracy:.3f}\")\n",
    "\n",
    "    # Per-class accuracy\n",
    "    #print(\"\\nðŸ“‹ Per-Class Accuracy:\")\n",
    "    class_counts = defaultdict(int)\n",
    "    correct_counts = defaultdict(int)\n",
    "\n",
    "    for true, pred in zip(pred_labels, matched_pred_labels):\n",
    "        class_counts[true] += 1\n",
    "        if true == pred:\n",
    "            correct_counts[true] += 1\n",
    "\n",
    "    for label in sorted(class_counts.keys()):\n",
    "        correct = correct_counts[label]\n",
    "        total = class_counts[label]\n",
    "        acc = correct / total if total > 0 else 0.0\n",
    "        class_name = label_to_name.get(label, f\"Class {label}\")\n",
    "        #print(f\"  {label:2d} ({class_name:10s}): {acc:.3f} ({correct}/{total})\")\n",
    "\n",
    "        results.append({\n",
    "            \"Model\": pred_file[0],\n",
    "            \"Class\": class_name,\n",
    "            \"Accuracy\": acc\n",
    "        })\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_files = [\n",
    "    (\"S3DIS_Colors\",\"../docs/Smartlab_s3dis_label_pointnet2_x6_0.03_20250422.ply\"),\n",
    "    #(\"S3DIS_No_Colors\",\"\"),\n",
    "    #(\"Simulated\",\"\"),\n",
    "    #(\"Simulated_finetuned\",\"\")\n",
    "    (\"LoRA_finetuned\",\"../docs/Smartlab_pcd_lora_label_pointnet2_x3_0.03_20250426.ply\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Accuracy': 0.9365218326191463, 'Class': 'ceiling', 'Model': 'S3DIS_Colors'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "\n",
    "file = prediction_files[0]\n",
    "\n",
    "result = accuracy_per_class(gt_points,gt_labels,file)\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m prediction_files:\n\u001b[1;32m----> 3\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(\u001b[43maccuracy_per_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_pcd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[15], line 14\u001b[0m, in \u001b[0;36maccuracy_per_class\u001b[1;34m(gt_pcd, pred_file)\u001b[0m\n\u001b[0;32m     11\u001b[0m pred_colors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(pred_origin_colors, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Convert color to semantic labels\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m gt_labels \u001b[38;5;241m=\u001b[39m \u001b[43mget_label_from_color\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgt_colors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m get_label_from_color(pred_colors)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Filter out unmatched labels (e.g. -1)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m, in \u001b[0;36mget_label_from_color\u001b[1;34m(color_array)\u001b[0m\n\u001b[0;32m      7\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m color_array:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Round to 3 decimals to avoid float precision mismatch\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     11\u001b[0m     label \u001b[38;5;241m=\u001b[39m rgb_to_label\u001b[38;5;241m.\u001b[39mget(key, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# -1 if unmatched\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     labels\u001b[38;5;241m.\u001b[39mappend(label)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for file in prediction_files:\n",
    "    results.append(accuracy_per_class(gt_pcd,file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df, x=\"Class\", y=\"Accuracy\", hue=\"Model\")\n",
    "plt.title(\"Per-Class Accuracy by Model\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.25884302 5.6081679  1.74653798]\n",
      "[5.20587027 5.64833263 1.76726065]\n"
     ]
    }
   ],
   "source": [
    "# Compute the centroid\n",
    "gt_centroid = gt_points.mean(axis=0)\n",
    "pred_centroid = pred_points.mean(axis=0)\n",
    "\n",
    "print(gt_centroid)\n",
    "print(pred_centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.03750002 -4.06758022 -1.56200004]\n",
      "[0.         0.00400019 0.00703452]\n"
     ]
    }
   ],
   "source": [
    "gt_min_xyz = gt_points.min(axis=0)\n",
    "pred_min_xyz = pred_points.min(axis=0)\n",
    "\n",
    "print(gt_min_xyz)\n",
    "print(pred_min_xyz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
